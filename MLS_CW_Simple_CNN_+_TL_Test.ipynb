{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnBQX9MYuao2ktC0hzQSY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IreneJeong/Project-Storage/blob/main/MLS_CW_Simple_CNN_%2B_TL_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD_D02RrXc66"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,Activation\n",
        "from keras import losses\n",
        "from keras.optimizers import Adam, Adagrad, SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras import utils\n",
        "import keras\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10, cifar100\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    '''\n",
        "    Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.\n",
        "    '''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    session_conf = tf.compat.v1.ConfigProto(\n",
        "        intra_op_parallelism_threads=1,\n",
        "        inter_op_parallelism_threads=1)\n",
        "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed()"
      ],
      "metadata": {
        "id": "ia70B0UDXicg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10, cifar100\n",
        "\n",
        "(cifar10_X_train, cifar10_y_train),(cifar10_X_test, cifar10_y_test)=cifar10.load_data()\n",
        "\n",
        "print('input_X_train shape: ', cifar10_X_train.shape)\n",
        "print(cifar10_X_train.shape[0], 'train samples')\n",
        "print(cifar10_X_test.shape[0], 'test samples')\n",
        "\n",
        "cifar10_N_CLASSES = len(np.unique(cifar10_y_train))\n",
        "print(cifar10_N_CLASSES)\n",
        "\n",
        "# output data one-hot encoding \n",
        "cifar10_y_train=utils.to_categorical(cifar10_y_train, cifar10_N_CLASSES)\n",
        "cifar10_y_test=utils.to_categorical(cifar10_y_test, cifar10_N_CLASSES)\n",
        "\n",
        "# To normalize the value in between 0 and 1 (there are 255 kinds)\n",
        "cifar10_X_train=cifar10_X_train.astype('float32')\n",
        "cifar10_X_test=cifar10_X_test.astype('float32')\n",
        "\n",
        "cifar10_X_train /=255\n",
        "cifar10_X_test /=255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBnWLNqCXm7e",
        "outputId": "bac68a11-be98-4106-c4d0-e3dd5ddda17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_X_train shape:  (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple CNN and TL (ResNet50 and EB0)"
      ],
      "metadata": {
        "id": "kXnSqAfNAnMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN - CIFAR 10"
      ],
      "metadata": {
        "id": "sHASnQ3xASFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Get the highest accuracy achieved during training\n",
        "highest_accuracy = max(history.history[\"val_accuracy\"])\n",
        "print(\"Highest accuracy achieved:\", highest_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7XkW-Xru-CF",
        "outputId": "e5d6fce2-b14b-4200-b9c3-2eab6085188b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 63s 50ms/step - loss: 1.5383 - accuracy: 0.4381 - val_loss: 1.2805 - val_accuracy: 0.5392\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 1.1801 - accuracy: 0.5795 - val_loss: 1.1038 - val_accuracy: 0.6079\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 62s 49ms/step - loss: 1.0302 - accuracy: 0.6368 - val_loss: 1.0003 - val_accuracy: 0.6479\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 61s 48ms/step - loss: 0.9263 - accuracy: 0.6745 - val_loss: 0.9748 - val_accuracy: 0.6595\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 0.8488 - accuracy: 0.7041 - val_loss: 0.9249 - val_accuracy: 0.6742\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 0.7776 - accuracy: 0.7270 - val_loss: 0.9045 - val_accuracy: 0.6879\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 63s 50ms/step - loss: 0.7257 - accuracy: 0.7469 - val_loss: 0.8853 - val_accuracy: 0.6976\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 63s 50ms/step - loss: 0.6749 - accuracy: 0.7627 - val_loss: 0.9291 - val_accuracy: 0.6859\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 64s 51ms/step - loss: 0.6313 - accuracy: 0.7789 - val_loss: 0.9018 - val_accuracy: 0.7032\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 64s 51ms/step - loss: 0.5876 - accuracy: 0.7918 - val_loss: 0.9407 - val_accuracy: 0.6944\n",
            "Highest accuracy achieved: 0.7031999826431274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple CNN - CIFAR100"
      ],
      "metadata": {
        "id": "vC3pK7LLAV10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "\n",
        "# Load the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(100),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Get the highest accuracy achieved during training\n",
        "highest_accuracy = max(history.history[\"val_accuracy\"])\n",
        "print(\"Highest accuracy achieved:\", highest_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPh7ro3-5Asx",
        "outputId": "a2d827ce-8457-4599-8457-36a889926468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n",
            "1250/1250 [==============================] - 63s 49ms/step - loss: 4.0557 - accuracy: 0.0777 - val_loss: 3.7026 - val_accuracy: 0.1237\n",
            "Epoch 2/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 3.4322 - accuracy: 0.1779 - val_loss: 3.2796 - val_accuracy: 0.2073\n",
            "Epoch 3/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 3.1234 - accuracy: 0.2365 - val_loss: 3.1071 - val_accuracy: 0.2418\n",
            "Epoch 4/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 2.9164 - accuracy: 0.2764 - val_loss: 2.9702 - val_accuracy: 0.2664\n",
            "Epoch 5/50\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 2.7709 - accuracy: 0.3049 - val_loss: 2.9006 - val_accuracy: 0.2777\n",
            "Epoch 6/50\n",
            "1250/1250 [==============================] - 62s 49ms/step - loss: 2.6489 - accuracy: 0.3294 - val_loss: 2.8944 - val_accuracy: 0.2863\n",
            "Epoch 7/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 2.5498 - accuracy: 0.3473 - val_loss: 2.7689 - val_accuracy: 0.3040\n",
            "Epoch 8/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 2.4632 - accuracy: 0.3665 - val_loss: 2.7186 - val_accuracy: 0.3234\n",
            "Epoch 9/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 2.3900 - accuracy: 0.3811 - val_loss: 2.7094 - val_accuracy: 0.3293\n",
            "Epoch 10/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 2.3167 - accuracy: 0.3987 - val_loss: 2.7188 - val_accuracy: 0.3286\n",
            "Epoch 11/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 2.2578 - accuracy: 0.4081 - val_loss: 2.6704 - val_accuracy: 0.3342\n",
            "Epoch 12/50\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 2.1889 - accuracy: 0.4233 - val_loss: 2.6543 - val_accuracy: 0.3413\n",
            "Epoch 13/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 2.1347 - accuracy: 0.4346 - val_loss: 2.7165 - val_accuracy: 0.3351\n",
            "Epoch 14/50\n",
            "1250/1250 [==============================] - 61s 48ms/step - loss: 2.0769 - accuracy: 0.4440 - val_loss: 2.7587 - val_accuracy: 0.3339\n",
            "Epoch 15/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 2.0207 - accuracy: 0.4580 - val_loss: 2.7145 - val_accuracy: 0.3370\n",
            "Epoch 16/50\n",
            "1250/1250 [==============================] - 62s 49ms/step - loss: 1.9702 - accuracy: 0.4675 - val_loss: 2.7380 - val_accuracy: 0.3366\n",
            "Epoch 17/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.9305 - accuracy: 0.4780 - val_loss: 2.7871 - val_accuracy: 0.3383\n",
            "Epoch 18/50\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 1.8781 - accuracy: 0.4879 - val_loss: 2.7967 - val_accuracy: 0.3400\n",
            "Epoch 19/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.8375 - accuracy: 0.5016 - val_loss: 2.8898 - val_accuracy: 0.3236\n",
            "Epoch 20/50\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 1.7919 - accuracy: 0.5095 - val_loss: 2.8623 - val_accuracy: 0.3315\n",
            "Epoch 21/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.7547 - accuracy: 0.5173 - val_loss: 2.9145 - val_accuracy: 0.3246\n",
            "Epoch 22/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.7093 - accuracy: 0.5277 - val_loss: 2.9406 - val_accuracy: 0.3318\n",
            "Epoch 23/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.6817 - accuracy: 0.5347 - val_loss: 3.0391 - val_accuracy: 0.3243\n",
            "Epoch 24/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.6428 - accuracy: 0.5440 - val_loss: 3.0962 - val_accuracy: 0.3203\n",
            "Epoch 25/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.6080 - accuracy: 0.5518 - val_loss: 3.1177 - val_accuracy: 0.3151\n",
            "Epoch 26/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.5756 - accuracy: 0.5596 - val_loss: 3.1560 - val_accuracy: 0.3206\n",
            "Epoch 27/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.5546 - accuracy: 0.5609 - val_loss: 3.2133 - val_accuracy: 0.3188\n",
            "Epoch 28/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.5181 - accuracy: 0.5699 - val_loss: 3.3028 - val_accuracy: 0.3117\n",
            "Epoch 29/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.4875 - accuracy: 0.5783 - val_loss: 3.3286 - val_accuracy: 0.3121\n",
            "Epoch 30/50\n",
            "1250/1250 [==============================] - 59s 47ms/step - loss: 1.4579 - accuracy: 0.5829 - val_loss: 3.3844 - val_accuracy: 0.3099\n",
            "Epoch 31/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.4361 - accuracy: 0.5926 - val_loss: 3.4342 - val_accuracy: 0.3058\n",
            "Epoch 32/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.4049 - accuracy: 0.5972 - val_loss: 3.4945 - val_accuracy: 0.3098\n",
            "Epoch 33/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.3854 - accuracy: 0.5999 - val_loss: 3.5395 - val_accuracy: 0.3112\n",
            "Epoch 34/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.3586 - accuracy: 0.6083 - val_loss: 3.5343 - val_accuracy: 0.3076\n",
            "Epoch 35/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.3338 - accuracy: 0.6155 - val_loss: 3.6975 - val_accuracy: 0.3076\n",
            "Epoch 36/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.3129 - accuracy: 0.6213 - val_loss: 3.5869 - val_accuracy: 0.3037\n",
            "Epoch 37/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.2868 - accuracy: 0.6273 - val_loss: 3.7722 - val_accuracy: 0.2984\n",
            "Epoch 38/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.2723 - accuracy: 0.6303 - val_loss: 3.8500 - val_accuracy: 0.2910\n",
            "Epoch 39/50\n",
            "1250/1250 [==============================] - 58s 47ms/step - loss: 1.2452 - accuracy: 0.6372 - val_loss: 3.8816 - val_accuracy: 0.3001\n",
            "Epoch 40/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.2229 - accuracy: 0.6445 - val_loss: 3.9800 - val_accuracy: 0.2957\n",
            "Epoch 41/50\n",
            "1250/1250 [==============================] - 61s 49ms/step - loss: 1.2033 - accuracy: 0.6486 - val_loss: 4.0406 - val_accuracy: 0.2949\n",
            "Epoch 42/50\n",
            "1250/1250 [==============================] - 60s 48ms/step - loss: 1.1881 - accuracy: 0.6510 - val_loss: 4.1553 - val_accuracy: 0.2931\n",
            "Epoch 43/50\n",
            "1250/1250 [==============================] - 62s 49ms/step - loss: 1.1687 - accuracy: 0.6558 - val_loss: 4.1566 - val_accuracy: 0.2888\n",
            "Epoch 44/50\n",
            "1250/1250 [==============================] - 62s 50ms/step - loss: 1.1473 - accuracy: 0.6606 - val_loss: 4.2782 - val_accuracy: 0.2899\n",
            "Epoch 45/50\n",
            "1250/1250 [==============================] - 62s 50ms/step - loss: 1.1361 - accuracy: 0.6625 - val_loss: 4.3738 - val_accuracy: 0.2888\n",
            "Epoch 46/50\n",
            "1250/1250 [==============================] - 61s 48ms/step - loss: 1.1129 - accuracy: 0.6691 - val_loss: 4.3778 - val_accuracy: 0.2912\n",
            "Epoch 47/50\n",
            "1250/1250 [==============================] - 62s 50ms/step - loss: 1.1057 - accuracy: 0.6709 - val_loss: 4.4522 - val_accuracy: 0.2823\n",
            "Epoch 48/50\n",
            "1250/1250 [==============================] - 62s 49ms/step - loss: 1.0847 - accuracy: 0.6763 - val_loss: 4.4430 - val_accuracy: 0.2884\n",
            "Epoch 49/50\n",
            "1250/1250 [==============================] - 62s 50ms/step - loss: 1.0758 - accuracy: 0.6783 - val_loss: 4.5912 - val_accuracy: 0.2854\n",
            "Epoch 50/50\n",
            "1250/1250 [==============================] - 62s 50ms/step - loss: 1.0656 - accuracy: 0.6806 - val_loss: 4.6998 - val_accuracy: 0.2853\n",
            "Highest accuracy achieved: 0.34130001068115234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TL ResNet50 - CIFAR100"
      ],
      "metadata": {
        "id": "rdnxk3ZiAbR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# Load the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new trainable layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(100, activation=\"softmax\")(x)\n",
        "\n",
        "# Compile the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=Adam(lr=0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "dv5jSKuZ5laC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9e1c6c-d20b-480b-ea1a-08d398ea6406"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 11s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 228s 714ms/step - loss: 4.5634 - accuracy: 0.0244 - val_loss: 4.4492 - val_accuracy: 0.0336\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 214s 685ms/step - loss: 4.3519 - accuracy: 0.0483 - val_loss: 4.2763 - val_accuracy: 0.0587\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 218s 695ms/step - loss: 4.2281 - accuracy: 0.0683 - val_loss: 4.2339 - val_accuracy: 0.0628\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 216s 691ms/step - loss: 4.1559 - accuracy: 0.0781 - val_loss: 4.1652 - val_accuracy: 0.0728\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 215s 688ms/step - loss: 4.1019 - accuracy: 0.0844 - val_loss: 4.0984 - val_accuracy: 0.0865\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 214s 686ms/step - loss: 4.0597 - accuracy: 0.0920 - val_loss: 4.0510 - val_accuracy: 0.0931\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 216s 689ms/step - loss: 4.0234 - accuracy: 0.0968 - val_loss: 4.0440 - val_accuracy: 0.0929\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 215s 688ms/step - loss: 3.9929 - accuracy: 0.1011 - val_loss: 3.9875 - val_accuracy: 0.1005\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 215s 688ms/step - loss: 3.9605 - accuracy: 0.1060 - val_loss: 3.9798 - val_accuracy: 0.1020\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 216s 691ms/step - loss: 3.9290 - accuracy: 0.1109 - val_loss: 3.9319 - val_accuracy: 0.1151\n",
            "313/313 - 50s - loss: 3.9286 - accuracy: 0.1171 - 50s/epoch - 160ms/step\n",
            "Test accuracy: 0.11710000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TL - EB0 Cifar100"
      ],
      "metadata": {
        "id": "_KBnwFS0AgnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3RT-DqOAF2o",
        "outputId": "0290804b-598f-448a-8ac2-ed63dd74664b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from efficientnet) (0.19.3)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (2023.3.21)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet) (23.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from efficientnet.tfkeras import EfficientNetB0\n",
        "\n",
        "# Load the CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Use data augmentation to reduce overfitting\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        ")\n",
        "\n",
        "# Load the pre-trained EfficientNetB0 model\n",
        "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add new layers on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation=\"relu\")(x)\n",
        "predictions = Dense(100, activation=\"softmax\")(x)\n",
        "\n",
        "# Define the new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Train the model with transfer learning\n",
        "history = model.fit(\n",
        "    data_augmentation.flow(x_train, y_train, batch_size=32),\n",
        "    steps_per_epoch=len(x_train) // 32,\n",
        "    epochs=50,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[EarlyStopping(patience=5)],\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "id": "KU6O5-by5_bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff1f9da-a4cb-456b-fde6-e87885885a8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16804768/16804768 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1562/1562 [==============================] - 194s 114ms/step - loss: 3.7608 - accuracy: 0.0150 - val_loss: 3.3131 - val_accuracy: 0.0108\n",
            "Epoch 2/50\n",
            "1562/1562 [==============================] - 158s 101ms/step - loss: 3.3659 - accuracy: 0.0133 - val_loss: 3.1443 - val_accuracy: 0.0184\n",
            "Epoch 3/50\n",
            "1562/1562 [==============================] - 154s 99ms/step - loss: 3.2495 - accuracy: 0.0129 - val_loss: 3.0856 - val_accuracy: 0.0140\n",
            "Epoch 4/50\n",
            "1562/1562 [==============================] - 155s 99ms/step - loss: 3.1729 - accuracy: 0.0123 - val_loss: 3.0399 - val_accuracy: 0.0053\n",
            "Epoch 5/50\n",
            "1562/1562 [==============================] - 156s 100ms/step - loss: 3.1226 - accuracy: 0.0117 - val_loss: 2.9608 - val_accuracy: 0.0125\n",
            "Epoch 6/50\n",
            "1562/1562 [==============================] - 156s 100ms/step - loss: 3.0803 - accuracy: 0.0121 - val_loss: 2.9696 - val_accuracy: 0.0071\n",
            "Epoch 7/50\n",
            "1562/1562 [==============================] - 152s 97ms/step - loss: 3.0547 - accuracy: 0.0120 - val_loss: 2.9327 - val_accuracy: 0.0127\n",
            "Epoch 8/50\n",
            "1562/1562 [==============================] - 155s 99ms/step - loss: 3.0269 - accuracy: 0.0110 - val_loss: 2.8741 - val_accuracy: 0.0118\n",
            "Epoch 9/50\n",
            "1562/1562 [==============================] - 155s 99ms/step - loss: 2.9990 - accuracy: 0.0113 - val_loss: 2.8783 - val_accuracy: 0.0097\n",
            "Epoch 10/50\n",
            "1562/1562 [==============================] - 155s 99ms/step - loss: 2.9808 - accuracy: 0.0115 - val_loss: 2.8899 - val_accuracy: 0.0070\n",
            "Epoch 11/50\n",
            "1562/1562 [==============================] - 154s 99ms/step - loss: 2.9557 - accuracy: 0.0110 - val_loss: 2.8793 - val_accuracy: 0.0095\n",
            "Epoch 12/50\n",
            "1562/1562 [==============================] - 155s 99ms/step - loss: 2.9464 - accuracy: 0.0114 - val_loss: 2.8746 - val_accuracy: 0.0078\n",
            "Epoch 13/50\n",
            "1562/1562 [==============================] - 152s 97ms/step - loss: 2.9328 - accuracy: 0.0109 - val_loss: 2.8880 - val_accuracy: 0.0134\n",
            "313/313 [==============================] - 20s 64ms/step - loss: 2.8880 - accuracy: 0.0134\n",
            "Test accuracy: 0.013399999588727951\n"
          ]
        }
      ]
    }
  ]
}