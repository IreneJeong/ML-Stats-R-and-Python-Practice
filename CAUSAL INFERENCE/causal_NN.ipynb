{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Intervention           X1           X2           X3      Outcome\n",
      "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000\n",
      "mean       0.072945     0.039285    -0.043098     0.056684     3.277777\n",
      "std        1.129431     0.976380     1.026010     1.010051     3.909194\n",
      "min       -2.966933    -3.263536    -2.907249    -2.935927    -8.012574\n",
      "25%       -0.689157    -0.622772    -0.735416    -0.654613     0.544598\n",
      "50%        0.055784     0.058927    -0.100769     0.120415     3.113335\n",
      "75%        0.796871     0.702324     0.635221     0.713646     5.821561\n",
      "max        4.099311     3.443985     4.347555     3.328893    18.845722\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_data(data_type, n_samples):\n",
    "    n_samples = n_samples\n",
    "    \n",
    "    alpha = 3 \n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.6\n",
    "    beta3 = 0.7\n",
    "    gamma1 = 2\n",
    "    gamma2 = 3\n",
    "    \n",
    "    # Generate confounders\n",
    "    X1 = np.random.normal(0, 1, size=n_samples)\n",
    "    X2 = np.random.normal(0, 1, size=n_samples)\n",
    "    X3 = np.random.normal(0, 1, size=n_samples)\n",
    "    \n",
    "    if data_type == \"data1\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta2 * X2 + np.random.normal(loc=0, scale=0.5, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha +  gamma2* T + gamma1 * M + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data2\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, confounders, and noise\n",
    "        Y = alpha  + gamma2* T + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data3\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta1 * X1 - beta2 * X2 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcomee affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha + gamma2* T + gamma1 * M + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "    \n",
    "    elif data_type == \"data4\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Continuous Outcome influenced by intervention, confounders\n",
    "        Y = alpha + gamma2 * T + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data type\")\n",
    "\n",
    "# Use the function in a loop\n",
    "datasets = {}\n",
    "for data_name in [\"data1\", \"data2\", \"data3\", \"data4\"]:\n",
    "    datasets[data_name] = generate_data(data_name, 1000)\n",
    "\n",
    "print(datasets[\"data2\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 17:12:52.768130: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def neural_network_estimate(data):\n",
    "    # Split data into training and test sets\n",
    "    X = data.drop(columns='Outcome')\n",
    "    y = data['Outcome']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a simple neural network model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    # Calculate MAPE\n",
    "    mape = 100 * np.mean(np.abs((y_test - y_pred) / y_test))\n",
    "\n",
    "    return mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8665 - val_loss: 1.0356\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0342 - val_loss: 1.0999\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0316 - val_loss: 1.1223\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0280 - val_loss: 1.0081\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0382\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0201 - val_loss: 1.0024\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0239 - val_loss: 1.0248\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0213 - val_loss: 1.0372\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0197 - val_loss: 1.0181\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0185 - val_loss: 1.0616\n",
      "625/625 [==============================] - 1s 728us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9532 - val_loss: 1.0382\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0443 - val_loss: 1.0416\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0371 - val_loss: 1.0316\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0355 - val_loss: 1.0332\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0348 - val_loss: 1.0606\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0218\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0289 - val_loss: 1.0102\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0279 - val_loss: 1.0223\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0293 - val_loss: 1.0339\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0269 - val_loss: 1.0183\n",
      "625/625 [==============================] - 1s 940us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8129 - val_loss: 1.0526\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0340 - val_loss: 1.0614\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0311 - val_loss: 1.0307\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0469\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0507\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0229 - val_loss: 1.0891\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0447\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0185 - val_loss: 1.0252\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0193 - val_loss: 1.0300\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0415\n",
      "625/625 [==============================] - 1s 875us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8974 - val_loss: 1.0458\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0470 - val_loss: 1.0443\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0455 - val_loss: 1.0291\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0344 - val_loss: 1.0053\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0388 - val_loss: 1.0016\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0336 - val_loss: 1.0374\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0341 - val_loss: 1.0041\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0040\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0301 - val_loss: 1.0118\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0301 - val_loss: 1.0048\n",
      "625/625 [==============================] - 0s 702us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9589 - val_loss: 1.0755\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0423 - val_loss: 1.0653\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0432 - val_loss: 1.0462\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0375 - val_loss: 1.0190\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0319 - val_loss: 1.0538\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0114\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0320 - val_loss: 1.0212\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0218\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0121\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0252 - val_loss: 1.0198\n",
      "625/625 [==============================] - 1s 805us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7791 - val_loss: 1.0399\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0386 - val_loss: 1.0185\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 0.9972\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0278 - val_loss: 1.0327\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0280 - val_loss: 1.0469\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0140\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0240\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 1.0135\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0207 - val_loss: 1.0082\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0174 - val_loss: 1.0133\n",
      "625/625 [==============================] - 1s 797us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.0390 - val_loss: 1.0822\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0405 - val_loss: 1.0388\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0368 - val_loss: 1.0292\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0247\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0279 - val_loss: 1.0371\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0299 - val_loss: 1.0595\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0188\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0466\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0238 - val_loss: 1.0524\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0229 - val_loss: 1.0235\n",
      "625/625 [==============================] - 1s 741us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8978 - val_loss: 1.0959\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0543 - val_loss: 1.0472\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0458 - val_loss: 1.0506\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0434 - val_loss: 1.0311\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0416 - val_loss: 1.0484\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0392 - val_loss: 1.0228\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0377 - val_loss: 1.0401\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0231\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0346 - val_loss: 1.0137\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0359 - val_loss: 1.0539\n",
      "625/625 [==============================] - 1s 875us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8407 - val_loss: 1.0300\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0307 - val_loss: 1.0875\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0262 - val_loss: 1.0270\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0510\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0225 - val_loss: 1.0263\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 1.0142\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0189 - val_loss: 1.0335\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0151 - val_loss: 1.0064\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0158 - val_loss: 1.0093\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0171 - val_loss: 1.0057\n",
      "625/625 [==============================] - 1s 880us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.0083 - val_loss: 1.0158\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 1.0394\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0277 - val_loss: 1.0520\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0245 - val_loss: 1.0558\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0425\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0212 - val_loss: 1.0634\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0170 - val_loss: 1.0412\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0145 - val_loss: 1.0200\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0138 - val_loss: 1.0694\n",
      "625/625 [==============================] - 1s 845us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0597 - val_loss: 1.0187\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0322 - val_loss: 1.0604\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0288 - val_loss: 1.0729\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0239 - val_loss: 1.0149\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0656\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0172\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0224 - val_loss: 1.0320\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0165\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0193 - val_loss: 1.0279\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0562\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 2.0395 - val_loss: 1.0506\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0457 - val_loss: 1.0642\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0431 - val_loss: 1.0983\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0394 - val_loss: 1.0772\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0376 - val_loss: 1.0285\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0347 - val_loss: 1.0511\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0337 - val_loss: 1.0605\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0337 - val_loss: 1.0465\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0314 - val_loss: 1.0200\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0312 - val_loss: 1.0246\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8882 - val_loss: 1.0230\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0375 - val_loss: 1.0204\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0331 - val_loss: 1.0457\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0316 - val_loss: 1.0145\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0274 - val_loss: 1.0502\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0224 - val_loss: 0.9891\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0225 - val_loss: 0.9988\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0200 - val_loss: 0.9999\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0176 - val_loss: 0.9959\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0189 - val_loss: 0.9894\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.9549 - val_loss: 1.0295\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0375 - val_loss: 1.1959\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0328 - val_loss: 1.0425\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0282 - val_loss: 1.0253\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0273 - val_loss: 1.0481\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0255 - val_loss: 1.0743\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0253 - val_loss: 1.0241\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0211 - val_loss: 1.0107\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0228 - val_loss: 1.0167\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0195 - val_loss: 1.0020\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.9896 - val_loss: 1.0371\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0350 - val_loss: 1.0449\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0241 - val_loss: 1.0645\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0244 - val_loss: 1.0271\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0220 - val_loss: 1.1037\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0182 - val_loss: 1.0409\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0182 - val_loss: 1.0960\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0207 - val_loss: 1.0163\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0158 - val_loss: 1.0171\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0148 - val_loss: 1.0412\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.9861 - val_loss: 1.0162\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0428 - val_loss: 1.0191\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0368 - val_loss: 1.0446\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.0340 - val_loss: 1.0248\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0325 - val_loss: 1.0203\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0284 - val_loss: 1.0012\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0297 - val_loss: 1.0076\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0273 - val_loss: 1.0109\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0231 - val_loss: 1.0111\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 1.0252 - val_loss: 1.0194\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.7426 - val_loss: 1.0197\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0477 - val_loss: 1.0295\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0414 - val_loss: 1.0635\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0394 - val_loss: 1.0098\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0376 - val_loss: 1.0141\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0349 - val_loss: 1.0066\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0349 - val_loss: 0.9983\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0323 - val_loss: 1.0011\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0132\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0274\n",
      "625/625 [==============================] - 1s 812us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9008 - val_loss: 1.1010\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0482 - val_loss: 1.0448\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0402 - val_loss: 1.0312\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0364 - val_loss: 1.0541\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0639\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0319 - val_loss: 1.0109\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0289 - val_loss: 1.0115\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0279 - val_loss: 1.0568\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0280 - val_loss: 1.0344\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0149\n",
      "625/625 [==============================] - 0s 704us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8094 - val_loss: 1.0233\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0465 - val_loss: 1.0670\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0456 - val_loss: 1.0274\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0396 - val_loss: 1.0554\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0338 - val_loss: 1.0556\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0391\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0332 - val_loss: 1.0200\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0264\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0134\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0283\n",
      "625/625 [==============================] - 0s 706us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9298 - val_loss: 1.0478\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0474 - val_loss: 1.0288\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0377 - val_loss: 1.0436\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0374 - val_loss: 1.0349\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0339 - val_loss: 1.0229\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0302 - val_loss: 1.0196\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0310 - val_loss: 1.0237\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0287 - val_loss: 1.0068\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0116\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0245 - val_loss: 1.0280\n",
      "625/625 [==============================] - 1s 778us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9312 - val_loss: 0.9958\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0411 - val_loss: 1.0345\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0351 - val_loss: 1.0147\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0328 - val_loss: 1.0013\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0338 - val_loss: 1.0204\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 0.9911\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0274\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0240 - val_loss: 1.0296\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0255\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0210\n",
      "625/625 [==============================] - 0s 709us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8752 - val_loss: 1.0507\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0402 - val_loss: 1.0336\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0334\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0114\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0275 - val_loss: 1.0288\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0144\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0230 - val_loss: 1.0142\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0282\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0068\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0174\n",
      "625/625 [==============================] - 1s 747us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.0695 - val_loss: 1.1099\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0400 - val_loss: 1.0151\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0386 - val_loss: 1.0087\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0063\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0313 - val_loss: 1.0517\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0294 - val_loss: 1.0187\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.0050\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0239 - val_loss: 1.0012\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0257 - val_loss: 1.0038\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 0.9999\n",
      "625/625 [==============================] - 1s 730us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9303 - val_loss: 1.0521\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0349 - val_loss: 1.0354\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0325 - val_loss: 1.0385\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0632\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0258 - val_loss: 1.0557\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0192\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0180 - val_loss: 1.0112\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0185 - val_loss: 1.0224\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0171 - val_loss: 1.0839\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0166 - val_loss: 1.0466\n",
      "625/625 [==============================] - 1s 733us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9655 - val_loss: 1.0309\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0403 - val_loss: 1.0184\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0402 - val_loss: 1.0441\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0373 - val_loss: 1.0146\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0233\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0240\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0312 - val_loss: 1.0217\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 1.0187\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0234\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0112\n",
      "625/625 [==============================] - 1s 734us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.7981 - val_loss: 1.0406\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0500 - val_loss: 1.0614\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0413 - val_loss: 1.0923\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0399 - val_loss: 1.0278\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0363 - val_loss: 1.0483\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0373 - val_loss: 1.0284\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0334 - val_loss: 1.0363\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0307 - val_loss: 1.0522\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0309 - val_loss: 1.0436\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0216\n",
      "625/625 [==============================] - 1s 738us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8612 - val_loss: 1.0072\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0375 - val_loss: 1.0179\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0359 - val_loss: 1.0349\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0407\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0232 - val_loss: 1.0085\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0118\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0226 - val_loss: 1.0119\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0242 - val_loss: 1.0288\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 1.0011\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0187\n",
      "625/625 [==============================] - 1s 790us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7894 - val_loss: 1.0204\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0515 - val_loss: 1.0617\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0431 - val_loss: 1.0177\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0387 - val_loss: 1.0290\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 1.0146\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0338 - val_loss: 1.0662\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0322 - val_loss: 1.0191\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0310 - val_loss: 1.0344\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0290 - val_loss: 1.0271\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0288 - val_loss: 1.0167\n",
      "625/625 [==============================] - 1s 755us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9153 - val_loss: 1.1228\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0511 - val_loss: 1.0101\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0444 - val_loss: 1.0064\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0416 - val_loss: 1.0367\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0391 - val_loss: 0.9998\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0336 - val_loss: 1.0063\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0351 - val_loss: 1.1019\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0047\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0309 - val_loss: 0.9953\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0276 - val_loss: 0.9924\n",
      "625/625 [==============================] - 1s 743us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8833 - val_loss: 1.0149\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0421 - val_loss: 1.0021\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0377 - val_loss: 1.0024\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0195\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 1.0445\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0311 - val_loss: 1.0400\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0263 - val_loss: 1.0073\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0251 - val_loss: 1.0087\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0225 - val_loss: 1.0398\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0223 - val_loss: 1.0482\n",
      "625/625 [==============================] - 1s 796us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9575 - val_loss: 1.0681\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0577 - val_loss: 1.1670\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0510 - val_loss: 1.0329\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0455 - val_loss: 1.0330\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0451 - val_loss: 1.0432\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0455 - val_loss: 1.0119\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0395 - val_loss: 1.0529\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0375 - val_loss: 1.0369\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0383 - val_loss: 1.0161\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0407 - val_loss: 1.0002\n",
      "625/625 [==============================] - 1s 735us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9774 - val_loss: 1.0172\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0375 - val_loss: 1.0188\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0312 - val_loss: 1.0410\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0299 - val_loss: 1.0260\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0235 - val_loss: 1.0317\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0517\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0227 - val_loss: 1.0304\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0224 - val_loss: 1.0256\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0181 - val_loss: 1.0189\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0214 - val_loss: 1.0252\n",
      "625/625 [==============================] - 1s 740us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8450 - val_loss: 1.0416\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0478 - val_loss: 1.0370\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0382 - val_loss: 1.0465\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0407 - val_loss: 1.0449\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0357 - val_loss: 1.0258\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0359 - val_loss: 1.0505\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0325\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0328 - val_loss: 1.0772\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0315 - val_loss: 1.0280\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0320 - val_loss: 1.0408\n",
      "625/625 [==============================] - 1s 762us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8805 - val_loss: 1.0443\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0430 - val_loss: 1.0282\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0409 - val_loss: 1.0315\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0404 - val_loss: 1.0161\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0342 - val_loss: 1.0309\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0313 - val_loss: 1.0238\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0288 - val_loss: 1.0272\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0282 - val_loss: 1.0197\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0266 - val_loss: 1.0271\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0259 - val_loss: 1.0458\n",
      "625/625 [==============================] - 1s 726us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9309 - val_loss: 1.0658\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0510 - val_loss: 1.0534\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0476 - val_loss: 1.0248\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0435 - val_loss: 1.0198\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0389 - val_loss: 1.0228\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0374 - val_loss: 1.0220\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0371 - val_loss: 1.0295\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0163\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0331 - val_loss: 1.0313\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0448\n",
      "625/625 [==============================] - 1s 787us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8445 - val_loss: 1.0455\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0475 - val_loss: 1.0104\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0418 - val_loss: 1.0232\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0372 - val_loss: 1.0363\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0347 - val_loss: 1.0125\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0348 - val_loss: 0.9993\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0340 - val_loss: 1.0448\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0031\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0374\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0277 - val_loss: 0.9920\n",
      "625/625 [==============================] - 1s 793us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0981 - val_loss: 1.0062\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0422 - val_loss: 1.0365\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0380 - val_loss: 1.0199\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0346 - val_loss: 1.0076\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0354 - val_loss: 1.0276\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0345 - val_loss: 1.0003\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0095\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0076\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0565\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0291\n",
      "625/625 [==============================] - 1s 862us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8259 - val_loss: 1.0250\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0449 - val_loss: 1.0602\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0410 - val_loss: 1.0242\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0369 - val_loss: 1.0176\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0365 - val_loss: 1.0258\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0340 - val_loss: 1.0306\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0293 - val_loss: 1.0748\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0247\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0316\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0129\n",
      "625/625 [==============================] - 1s 774us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8247 - val_loss: 1.0454\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0458 - val_loss: 1.0223\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0428 - val_loss: 1.0840\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0376 - val_loss: 1.0191\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0377 - val_loss: 1.0159\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0315 - val_loss: 1.0425\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0286 - val_loss: 1.0376\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0350\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0276 - val_loss: 1.0129\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0277 - val_loss: 1.0197\n",
      "625/625 [==============================] - 1s 862us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9673 - val_loss: 1.0135\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0467 - val_loss: 1.0482\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0366 - val_loss: 1.0271\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0338 - val_loss: 1.0333\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0319 - val_loss: 1.0719\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0301 - val_loss: 1.0243\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0524\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0271 - val_loss: 1.0487\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0248 - val_loss: 1.0065\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0173\n",
      "625/625 [==============================] - 1s 753us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8810 - val_loss: 0.9930\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0490 - val_loss: 1.0136\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0428 - val_loss: 0.9970\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0363 - val_loss: 1.0022\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0050\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0351 - val_loss: 1.0192\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0062\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0282 - val_loss: 1.0242\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0294 - val_loss: 0.9961\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0126\n",
      "625/625 [==============================] - 1s 741us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.7625 - val_loss: 1.0057\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0450 - val_loss: 1.0059\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0426 - val_loss: 1.0203\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0373 - val_loss: 1.0324\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 1.0003\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0316 - val_loss: 0.9913\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0307 - val_loss: 1.0010\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0299 - val_loss: 1.0024\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0269 - val_loss: 1.0051\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0261 - val_loss: 0.9970\n",
      "625/625 [==============================] - 1s 787us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7718 - val_loss: 1.0224\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0350 - val_loss: 1.0253\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0142\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0242 - val_loss: 1.0514\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0248 - val_loss: 1.0492\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0231 - val_loss: 1.0850\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0207 - val_loss: 0.9998\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0202 - val_loss: 1.0151\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0176 - val_loss: 1.0335\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0173 - val_loss: 1.0623\n",
      "625/625 [==============================] - 1s 805us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8190 - val_loss: 1.0443\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0415 - val_loss: 1.0062\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0355 - val_loss: 1.0027\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 1.0019\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0325 - val_loss: 1.0695\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0655\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0275 - val_loss: 1.0007\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0834\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0159\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0246 - val_loss: 1.0069\n",
      "625/625 [==============================] - 1s 802us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8294 - val_loss: 1.0216\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0447 - val_loss: 1.0372\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0382 - val_loss: 1.0215\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0340 - val_loss: 1.0794\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0573\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0293 - val_loss: 1.0488\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 1.2079\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.1089\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0246\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0273\n",
      "625/625 [==============================] - 1s 777us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8978 - val_loss: 1.0274\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0339 - val_loss: 1.0167\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0209\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0280 - val_loss: 1.0210\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0751\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0063\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0613\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0204 - val_loss: 1.0906\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0175 - val_loss: 1.0182\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0195 - val_loss: 1.0193\n",
      "625/625 [==============================] - 1s 739us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.7498 - val_loss: 1.0430\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0404 - val_loss: 1.1894\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0345 - val_loss: 1.0161\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0258\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0228\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0326\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0170\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0243 - val_loss: 1.0169\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0223 - val_loss: 1.0235\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0228 - val_loss: 1.0439\n",
      "625/625 [==============================] - 1s 740us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9598 - val_loss: 1.0811\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0491 - val_loss: 1.1072\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0442 - val_loss: 1.0400\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0413 - val_loss: 1.0421\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0369 - val_loss: 1.0420\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0382 - val_loss: 1.0192\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0286\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0327 - val_loss: 1.0205\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0324 - val_loss: 1.0851\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0312 - val_loss: 1.0177\n",
      "625/625 [==============================] - 1s 879us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.0560 - val_loss: 1.0083\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0418 - val_loss: 1.0181\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0405 - val_loss: 1.0564\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 1.0272\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0345 - val_loss: 1.0342\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0302 - val_loss: 1.0242\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0239\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0443\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0185\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 1.0109\n",
      "625/625 [==============================] - 1s 820us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.1395 - val_loss: 1.0546\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0500 - val_loss: 1.0324\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0438 - val_loss: 1.0088\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0397 - val_loss: 1.0212\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0381 - val_loss: 1.0286\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0359 - val_loss: 1.0182\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0665\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0316 - val_loss: 1.0162\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0302 - val_loss: 1.0299\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0668\n",
      "625/625 [==============================] - 1s 790us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8473 - val_loss: 1.0882\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0400 - val_loss: 1.0440\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0247\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0183\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0236\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0259\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0220 - val_loss: 1.0231\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0202 - val_loss: 1.0361\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0198 - val_loss: 1.0190\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0173 - val_loss: 1.0166\n",
      "625/625 [==============================] - 1s 769us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.6952 - val_loss: 1.0350\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0464 - val_loss: 1.0043\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0348 - val_loss: 1.0303\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0277\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0012\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0046\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0264\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0056\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0075\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0224 - val_loss: 1.0043\n",
      "625/625 [==============================] - 1s 767us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0721 - val_loss: 1.0348\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0494 - val_loss: 1.0469\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0457 - val_loss: 1.0273\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0432 - val_loss: 1.0765\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0421 - val_loss: 1.0119\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0390 - val_loss: 1.0292\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0359 - val_loss: 1.1083\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0360 - val_loss: 1.0242\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0314\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0215\n",
      "625/625 [==============================] - 1s 734us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9381 - val_loss: 1.0550\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0484 - val_loss: 1.0332\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0404 - val_loss: 1.0883\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0387 - val_loss: 1.0209\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0355 - val_loss: 1.0796\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0319 - val_loss: 1.1112\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0325 - val_loss: 1.0608\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0517\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0309 - val_loss: 1.0327\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0300 - val_loss: 1.0563\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.8925 - val_loss: 1.0180\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0359 - val_loss: 1.0261\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0316 - val_loss: 1.0541\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0327 - val_loss: 1.1199\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0259 - val_loss: 1.0379\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0092\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0158\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0094\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0216 - val_loss: 1.0548\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0211 - val_loss: 1.0159\n",
      "625/625 [==============================] - 0s 715us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8566 - val_loss: 1.0540\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0341 - val_loss: 1.0690\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0349 - val_loss: 1.0458\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0296 - val_loss: 1.0161\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0461\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 1.0236\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0208 - val_loss: 1.0401\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0207 - val_loss: 1.0294\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0204 - val_loss: 1.0231\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0207 - val_loss: 1.0187\n",
      "625/625 [==============================] - 1s 739us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9886 - val_loss: 1.0823\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0418 - val_loss: 1.0223\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0380 - val_loss: 1.0348\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0373 - val_loss: 1.0502\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0080\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0345\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0244 - val_loss: 1.0544\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0279 - val_loss: 1.0181\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0372\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0242 - val_loss: 1.0131\n",
      "625/625 [==============================] - 1s 834us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8098 - val_loss: 1.1159\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0389 - val_loss: 1.0612\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0333 - val_loss: 1.0074\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0395\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0536\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0271 - val_loss: 1.0034\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0097\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0304\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0273 - val_loss: 1.0081\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0137\n",
      "625/625 [==============================] - 1s 765us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8928 - val_loss: 1.0176\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0475 - val_loss: 1.0347\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0427 - val_loss: 1.0224\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0365 - val_loss: 1.0683\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0356 - val_loss: 1.0634\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0343 - val_loss: 1.0181\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0609\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0166\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0294 - val_loss: 1.0479\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0121\n",
      "625/625 [==============================] - 1s 821us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 2.0462 - val_loss: 1.0001\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0474 - val_loss: 1.0155\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0415 - val_loss: 1.0004\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0354 - val_loss: 1.0041\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0357 - val_loss: 0.9919\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0338 - val_loss: 1.0660\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0316 - val_loss: 0.9868\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0078\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 0.9918\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0328 - val_loss: 1.0158\n",
      "625/625 [==============================] - 1s 738us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.7884 - val_loss: 1.0376\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0465 - val_loss: 1.0103\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0389 - val_loss: 1.0112\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0352 - val_loss: 1.0203\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0368 - val_loss: 1.0303\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0331 - val_loss: 1.0595\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0312 - val_loss: 1.0518\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0286 - val_loss: 1.0349\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0495\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0275 - val_loss: 1.0680\n",
      "625/625 [==============================] - 1s 873us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0138 - val_loss: 1.0503\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0382 - val_loss: 1.0175\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0324 - val_loss: 1.0148\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0348 - val_loss: 1.0407\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0152\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0275 - val_loss: 1.0830\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0548\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 1.0631\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0098\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0182\n",
      "625/625 [==============================] - 1s 843us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8715 - val_loss: 1.0234\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0424 - val_loss: 1.0199\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0371 - val_loss: 1.0106\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0201\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0289 - val_loss: 1.0163\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0307 - val_loss: 1.0333\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0135\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0242 - val_loss: 1.0217\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0243 - val_loss: 1.0170\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0238 - val_loss: 1.0195\n",
      "625/625 [==============================] - 1s 824us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8305 - val_loss: 1.0460\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0409 - val_loss: 1.0178\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0353 - val_loss: 1.0279\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0604\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0288 - val_loss: 1.0063\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0155\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.0118\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0262 - val_loss: 1.0181\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0235 - val_loss: 1.0372\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0220 - val_loss: 1.0259\n",
      "625/625 [==============================] - 1s 766us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8036 - val_loss: 1.0265\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0478 - val_loss: 1.0131\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0398 - val_loss: 1.0010\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0387 - val_loss: 1.0392\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0080\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0315 - val_loss: 1.0079\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0280 - val_loss: 1.0441\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0277 - val_loss: 1.0105\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0246 - val_loss: 1.0014\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.0339\n",
      "625/625 [==============================] - 1s 781us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8734 - val_loss: 1.0706\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0470 - val_loss: 1.0599\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0391 - val_loss: 1.0208\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0376 - val_loss: 1.0364\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0315 - val_loss: 1.2016\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0327 - val_loss: 1.0727\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0222\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0283 - val_loss: 1.0243\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0272\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0273\n",
      "625/625 [==============================] - 1s 878us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9604 - val_loss: 1.0001\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0365 - val_loss: 1.0059\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0397\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0280 - val_loss: 1.0633\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.1178\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0262 - val_loss: 1.0008\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0041\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0347\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0224 - val_loss: 1.0090\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0048\n",
      "625/625 [==============================] - 1s 910us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7806 - val_loss: 1.0343\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0471 - val_loss: 1.1154\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0394 - val_loss: 1.0794\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0383 - val_loss: 1.0950\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0346 - val_loss: 1.1004\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0346 - val_loss: 1.0617\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0352\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0338\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0299 - val_loss: 1.0316\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0279 - val_loss: 1.0257\n",
      "625/625 [==============================] - 1s 760us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8190 - val_loss: 1.0213\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0470 - val_loss: 1.0197\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0413 - val_loss: 1.0161\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0350 - val_loss: 1.0366\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0343 - val_loss: 1.0783\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0342 - val_loss: 1.0228\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0111\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0297 - val_loss: 1.0283\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0224\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0266 - val_loss: 1.0128\n",
      "625/625 [==============================] - 1s 842us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8641 - val_loss: 1.0143\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0411 - val_loss: 1.0218\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0374 - val_loss: 1.0221\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0109\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0364 - val_loss: 1.0325\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 0.9921\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0260 - val_loss: 1.0078\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0266 - val_loss: 1.0016\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0282 - val_loss: 1.0220\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 0.9978\n",
      "625/625 [==============================] - 1s 787us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9662 - val_loss: 1.0411\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0302 - val_loss: 1.0208\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0219\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0245 - val_loss: 1.0566\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0471\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0224 - val_loss: 1.0276\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0231 - val_loss: 1.0425\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0195 - val_loss: 1.0148\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0179 - val_loss: 1.0608\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0177 - val_loss: 1.0460\n",
      "625/625 [==============================] - 1s 854us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7681 - val_loss: 1.0190\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0375 - val_loss: 1.0227\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0344 - val_loss: 1.0522\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0310 - val_loss: 1.0236\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0266 - val_loss: 1.0094\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0134\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0259 - val_loss: 1.0630\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0225 - val_loss: 1.0180\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0217 - val_loss: 1.0141\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0218 - val_loss: 1.0520\n",
      "625/625 [==============================] - 1s 745us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.9507 - val_loss: 1.0406\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0435 - val_loss: 1.0158\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0387 - val_loss: 1.0243\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0343 - val_loss: 1.0151\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0332 - val_loss: 1.0261\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0325 - val_loss: 1.0769\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0428\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0282 - val_loss: 1.0135\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0108\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0269 - val_loss: 1.0199\n",
      "625/625 [==============================] - 1s 792us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9034 - val_loss: 1.0250\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0465 - val_loss: 1.0513\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0452 - val_loss: 1.0339\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0395 - val_loss: 1.1600\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0360 - val_loss: 1.0336\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0362 - val_loss: 1.0385\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0340 - val_loss: 1.0234\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0368\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0342 - val_loss: 1.0715\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0313 - val_loss: 1.0306\n",
      "625/625 [==============================] - 1s 844us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8717 - val_loss: 1.0132\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0420 - val_loss: 1.0406\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0383 - val_loss: 1.0271\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0380 - val_loss: 1.0503\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0419\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0292 - val_loss: 1.0394\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0293 - val_loss: 1.0293\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0185\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0251 - val_loss: 1.0217\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0002\n",
      "625/625 [==============================] - 1s 848us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8274 - val_loss: 1.0292\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0488 - val_loss: 1.0156\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0434 - val_loss: 1.1574\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0381 - val_loss: 1.0278\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0393 - val_loss: 1.0207\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0363 - val_loss: 1.0183\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0323 - val_loss: 1.0161\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0321 - val_loss: 1.0177\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0313 - val_loss: 1.0191\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0290 - val_loss: 1.0018\n",
      "625/625 [==============================] - 1s 852us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8567 - val_loss: 1.0255\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0425 - val_loss: 1.0298\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0389 - val_loss: 1.0423\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0358 - val_loss: 1.0327\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0162\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0199\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0260 - val_loss: 1.0226\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0240 - val_loss: 1.0244\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0260 - val_loss: 1.0183\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0274\n",
      "625/625 [==============================] - 1s 812us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.8805 - val_loss: 1.0164\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0494 - val_loss: 1.0001\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0458 - val_loss: 1.0697\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0409 - val_loss: 1.0205\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0371 - val_loss: 1.0249\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0326 - val_loss: 1.0065\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 0.9982\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0304 - val_loss: 1.0059\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0319 - val_loss: 0.9963\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0275 - val_loss: 0.9904\n",
      "625/625 [==============================] - 1s 791us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.1486 - val_loss: 1.0166\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0539 - val_loss: 1.0195\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0484 - val_loss: 1.0181\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0430 - val_loss: 1.0218\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0426 - val_loss: 1.0192\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0416 - val_loss: 1.0658\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0393 - val_loss: 1.0189\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0369 - val_loss: 1.0143\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0347 - val_loss: 1.0229\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0357 - val_loss: 1.0133\n",
      "625/625 [==============================] - 1s 859us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8312 - val_loss: 1.0432\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0438 - val_loss: 1.1703\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0367 - val_loss: 1.0286\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0288 - val_loss: 1.0154\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0313 - val_loss: 1.0013\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0288 - val_loss: 1.0619\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0245 - val_loss: 1.0587\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0247 - val_loss: 1.0078\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0175\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0478\n",
      "625/625 [==============================] - 1s 800us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.7906 - val_loss: 1.0478\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0492 - val_loss: 1.0403\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0424 - val_loss: 1.0233\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0348 - val_loss: 1.0257\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0351 - val_loss: 1.0373\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0161\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0289 - val_loss: 1.0249\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0295 - val_loss: 1.0413\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0298 - val_loss: 1.0406\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0248\n",
      "625/625 [==============================] - 1s 872us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9627 - val_loss: 1.0296\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0436 - val_loss: 1.0381\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0399 - val_loss: 1.0277\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0355 - val_loss: 1.0554\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0350 - val_loss: 1.0208\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0314 - val_loss: 1.0186\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0322 - val_loss: 1.0416\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0670\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0514\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0175\n",
      "625/625 [==============================] - 1s 792us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8726 - val_loss: 1.0595\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0513 - val_loss: 1.0183\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0460 - val_loss: 1.0372\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0432 - val_loss: 1.0107\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0385 - val_loss: 1.0038\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0367 - val_loss: 1.0113\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0358 - val_loss: 1.0062\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0350 - val_loss: 1.0022\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0344 - val_loss: 1.0167\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0309 - val_loss: 1.0091\n",
      "625/625 [==============================] - 1s 762us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8756 - val_loss: 1.0639\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0361 - val_loss: 1.0072\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0247 - val_loss: 1.0119\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0059\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0220 - val_loss: 1.0052\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0209 - val_loss: 0.9981\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0199 - val_loss: 1.0707\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0180 - val_loss: 1.0066\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0142 - val_loss: 1.0060\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0159 - val_loss: 1.0026\n",
      "625/625 [==============================] - 1s 806us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9336 - val_loss: 1.0482\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0468 - val_loss: 1.0324\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0378 - val_loss: 1.0174\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0357 - val_loss: 1.0242\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0324 - val_loss: 1.0435\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0320 - val_loss: 1.0244\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0057\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0072\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0266 - val_loss: 1.0350\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0277 - val_loss: 1.0218\n",
      "625/625 [==============================] - 1s 850us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9655 - val_loss: 1.0764\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0333 - val_loss: 1.0265\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0281 - val_loss: 1.0366\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0278 - val_loss: 1.0370\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0199\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0209 - val_loss: 1.0142\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0188 - val_loss: 1.0293\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0208 - val_loss: 1.0165\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0190 - val_loss: 1.0116\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0141 - val_loss: 1.0232\n",
      "625/625 [==============================] - 1s 779us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9162 - val_loss: 1.1924\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0483 - val_loss: 1.0649\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0439 - val_loss: 1.0302\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0327 - val_loss: 1.0307\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0342 - val_loss: 1.0401\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0325 - val_loss: 1.0684\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0323 - val_loss: 1.0119\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0294 - val_loss: 1.0238\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0164\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0278\n",
      "625/625 [==============================] - 1s 837us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8674 - val_loss: 1.0503\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0463 - val_loss: 1.0900\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0394 - val_loss: 1.0273\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0368 - val_loss: 1.0260\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0361 - val_loss: 1.0484\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0330 - val_loss: 1.0409\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0317\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0281 - val_loss: 1.0814\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0296 - val_loss: 1.0204\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0286 - val_loss: 1.0504\n",
      "625/625 [==============================] - 1s 791us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8673 - val_loss: 1.1226\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0500 - val_loss: 1.0181\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0402 - val_loss: 1.0073\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0370 - val_loss: 1.0516\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0356 - val_loss: 1.0269\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0309 - val_loss: 1.0276\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0291 - val_loss: 1.0100\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0316 - val_loss: 1.0134\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0293 - val_loss: 1.0149\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0239 - val_loss: 1.0152\n",
      "625/625 [==============================] - 1s 947us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8200 - val_loss: 1.0274\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0487 - val_loss: 1.0575\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0390 - val_loss: 1.0764\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0361 - val_loss: 1.0373\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0317 - val_loss: 1.0662\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0276\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0296 - val_loss: 1.0205\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0279 - val_loss: 1.0180\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0271 - val_loss: 1.0199\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0266 - val_loss: 1.0340\n",
      "625/625 [==============================] - 1s 853us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8749 - val_loss: 1.0491\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0461 - val_loss: 1.0678\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0392 - val_loss: 1.0406\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0370 - val_loss: 1.0433\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0344 - val_loss: 1.0290\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0332 - val_loss: 1.1029\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0312 - val_loss: 1.0543\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0309 - val_loss: 1.0866\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0998\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0285 - val_loss: 1.0256\n",
      "625/625 [==============================] - 1s 821us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9502 - val_loss: 1.0676\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0422 - val_loss: 1.0729\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0411 - val_loss: 1.0104\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0336 - val_loss: 1.0484\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0172\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 1.0005\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0262\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0260 - val_loss: 1.0001\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0196\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0348\n",
      "625/625 [==============================] - 1s 845us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7116 - val_loss: 1.0333\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0402 - val_loss: 1.0079\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0333 - val_loss: 1.0989\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0308 - val_loss: 1.0137\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0262 - val_loss: 1.0129\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0253 - val_loss: 1.0318\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 1.0062\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0273\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0210 - val_loss: 1.0064\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0175 - val_loss: 1.0019\n",
      "625/625 [==============================] - 1s 835us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.1565 - val_loss: 1.0309\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0388 - val_loss: 1.0668\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0355 - val_loss: 1.0653\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0317 - val_loss: 1.0483\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0282 - val_loss: 1.0220\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0255\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0554\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0230\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0235 - val_loss: 1.0465\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0235\n",
      "625/625 [==============================] - 1s 804us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 2.0977 - val_loss: 1.0248\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0373 - val_loss: 1.0062\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0331 - val_loss: 1.1025\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0324 - val_loss: 1.0067\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0265 - val_loss: 1.0703\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0255 - val_loss: 1.0679\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0231 - val_loss: 1.0216\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 1.0091\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0210 - val_loss: 1.0160\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0220 - val_loss: 1.0082\n",
      "625/625 [==============================] - 1s 783us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7832 - val_loss: 1.0138\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0539 - val_loss: 1.0180\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0407 - val_loss: 1.0154\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0400 - val_loss: 1.0135\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0343 - val_loss: 1.0251\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0349 - val_loss: 1.0055\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0066\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0293 - val_loss: 1.0115\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0271 - val_loss: 1.0122\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0056\n",
      "625/625 [==============================] - 1s 883us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.7811 - val_loss: 1.0316\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0388 - val_loss: 1.0170\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0380 - val_loss: 1.0766\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0352 - val_loss: 1.0163\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0303 - val_loss: 1.0152\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0306 - val_loss: 1.0388\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0281 - val_loss: 1.0213\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0261 - val_loss: 1.0182\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0106\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 1.0140\n",
      "625/625 [==============================] - 1s 899us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8570 - val_loss: 1.0328\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0292 - val_loss: 1.0253\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0254 - val_loss: 1.0294\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0671\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0185 - val_loss: 1.0116\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0184 - val_loss: 0.9977\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0148 - val_loss: 1.0393\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0163 - val_loss: 1.0004\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0137 - val_loss: 1.0100\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0095 - val_loss: 1.0071\n",
      "625/625 [==============================] - 1s 884us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.9311 - val_loss: 1.0751\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0346 - val_loss: 1.0175\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0323 - val_loss: 1.0121\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0237\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0238 - val_loss: 1.0235\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0249 - val_loss: 1.0528\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 1.0163\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0152\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0270\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0199 - val_loss: 1.0200\n",
      "625/625 [==============================] - 1s 823us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.8322 - val_loss: 1.0257\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0464 - val_loss: 1.0137\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0450 - val_loss: 1.0100\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0393 - val_loss: 1.0360\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0037\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0362 - val_loss: 1.0156\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0302 - val_loss: 1.0108\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0313 - val_loss: 1.0046\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0283 - val_loss: 1.0459\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0287 - val_loss: 1.0521\n",
      "625/625 [==============================] - 1s 873us/step\n",
      "Results for data1:\n",
      "Iteration 1: MAPE: 59.70%\n",
      "Iteration 2: MAPE: 158.95%\n",
      "Iteration 3: MAPE: 76.24%\n",
      "Iteration 4: MAPE: 979.77%\n",
      "Iteration 5: MAPE: 131.57%\n",
      "Iteration 6: MAPE: 115.39%\n",
      "Iteration 7: MAPE: 67.21%\n",
      "Iteration 8: MAPE: 105.01%\n",
      "Iteration 9: MAPE: 96.06%\n",
      "Iteration 10: MAPE: 69.78%\n",
      "Iteration 11: MAPE: 68.51%\n",
      "Iteration 12: MAPE: 80.53%\n",
      "Iteration 13: MAPE: 687.51%\n",
      "Iteration 14: MAPE: 67.74%\n",
      "Iteration 15: MAPE: 71.83%\n",
      "Iteration 16: MAPE: 74.38%\n",
      "Iteration 17: MAPE: 71.53%\n",
      "Iteration 18: MAPE: 65.63%\n",
      "Iteration 19: MAPE: 64.17%\n",
      "Iteration 20: MAPE: 63.39%\n",
      "Iteration 21: MAPE: 89.77%\n",
      "Iteration 22: MAPE: 65.71%\n",
      "Iteration 23: MAPE: 131.65%\n",
      "Iteration 24: MAPE: 84.73%\n",
      "Iteration 25: MAPE: 68.22%\n",
      "Iteration 26: MAPE: 70.34%\n",
      "Iteration 27: MAPE: 56.72%\n",
      "Iteration 28: MAPE: 72.99%\n",
      "Iteration 29: MAPE: 80.79%\n",
      "Iteration 30: MAPE: 74.92%\n",
      "Iteration 31: MAPE: 75.07%\n",
      "Iteration 32: MAPE: 81.87%\n",
      "Iteration 33: MAPE: 64.98%\n",
      "Iteration 34: MAPE: 72.15%\n",
      "Iteration 35: MAPE: 141.66%\n",
      "Iteration 36: MAPE: 78.09%\n",
      "Iteration 37: MAPE: 69.31%\n",
      "Iteration 38: MAPE: 58.16%\n",
      "Iteration 39: MAPE: 152.54%\n",
      "Iteration 40: MAPE: 60.17%\n",
      "Iteration 41: MAPE: 111.82%\n",
      "Iteration 42: MAPE: 77.75%\n",
      "Iteration 43: MAPE: 580.71%\n",
      "Iteration 44: MAPE: 172.25%\n",
      "Iteration 45: MAPE: 71.11%\n",
      "Iteration 46: MAPE: 164.52%\n",
      "Iteration 47: MAPE: 57.82%\n",
      "Iteration 48: MAPE: 86.96%\n",
      "Iteration 49: MAPE: 76.18%\n",
      "Iteration 50: MAPE: 67.66%\n",
      "Iteration 51: MAPE: 77.26%\n",
      "Iteration 52: MAPE: 87.31%\n",
      "Iteration 53: MAPE: 100.75%\n",
      "Iteration 54: MAPE: 4213.58%\n",
      "Iteration 55: MAPE: 78.92%\n",
      "Iteration 56: MAPE: 53.58%\n",
      "Iteration 57: MAPE: 143.10%\n",
      "Iteration 58: MAPE: 107.05%\n",
      "Iteration 59: MAPE: 127.08%\n",
      "Iteration 60: MAPE: 56.60%\n",
      "Iteration 61: MAPE: 85.29%\n",
      "Iteration 62: MAPE: 106.30%\n",
      "Iteration 63: MAPE: 87.93%\n",
      "Iteration 64: MAPE: 80.99%\n",
      "Iteration 65: MAPE: 84.14%\n",
      "Iteration 66: MAPE: 179.73%\n",
      "Iteration 67: MAPE: 80.93%\n",
      "Iteration 68: MAPE: 387.64%\n",
      "Iteration 69: MAPE: 64.51%\n",
      "Iteration 70: MAPE: 88.51%\n",
      "Iteration 71: MAPE: 62.74%\n",
      "Iteration 72: MAPE: 74.50%\n",
      "Iteration 73: MAPE: 73.75%\n",
      "Iteration 74: MAPE: 80.62%\n",
      "Iteration 75: MAPE: 72.23%\n",
      "Iteration 76: MAPE: 80.35%\n",
      "Iteration 77: MAPE: 74.81%\n",
      "Iteration 78: MAPE: 67.75%\n",
      "Iteration 79: MAPE: 54.66%\n",
      "Iteration 80: MAPE: 87.20%\n",
      "Iteration 81: MAPE: 121.24%\n",
      "Iteration 82: MAPE: 61.73%\n",
      "Iteration 83: MAPE: 73.52%\n",
      "Iteration 84: MAPE: 59.65%\n",
      "Iteration 85: MAPE: 77.13%\n",
      "Iteration 86: MAPE: 99.15%\n",
      "Iteration 87: MAPE: 78.45%\n",
      "Iteration 88: MAPE: 130.53%\n",
      "Iteration 89: MAPE: 201.45%\n",
      "Iteration 90: MAPE: 152.52%\n",
      "Iteration 91: MAPE: 76.02%\n",
      "Iteration 92: MAPE: 276.07%\n",
      "Iteration 93: MAPE: 64.59%\n",
      "Iteration 94: MAPE: 78.40%\n",
      "Iteration 95: MAPE: 83.12%\n",
      "Iteration 96: MAPE: 78.60%\n",
      "Iteration 97: MAPE: 80.39%\n",
      "Iteration 98: MAPE: 72.81%\n",
      "Iteration 99: MAPE: 75.57%\n",
      "Iteration 100: MAPE: 248.31%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2456 - val_loss: 1.0252\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0356 - val_loss: 0.9963\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0274 - val_loss: 1.0089\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0225 - val_loss: 1.0351\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0237 - val_loss: 0.9998\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0216 - val_loss: 0.9915\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 0.9954\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0199 - val_loss: 0.9933\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0477\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 0.9943\n",
      "625/625 [==============================] - 1s 808us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2431 - val_loss: 1.0163\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0337\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0212 - val_loss: 1.0041\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0149 - val_loss: 1.0345\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0168 - val_loss: 1.0283\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0115 - val_loss: 1.0219\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0098 - val_loss: 1.0060\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0092 - val_loss: 1.0066\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0096 - val_loss: 1.0170\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0090 - val_loss: 1.0002\n",
      "625/625 [==============================] - 1s 875us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2873 - val_loss: 1.0274\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0258 - val_loss: 1.0172\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0201 - val_loss: 1.0465\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0181\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0155 - val_loss: 1.0191\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0146 - val_loss: 1.0325\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0135 - val_loss: 1.0255\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0120 - val_loss: 1.0158\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0103 - val_loss: 1.0254\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0121 - val_loss: 1.0125\n",
      "625/625 [==============================] - 1s 829us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3229 - val_loss: 1.0202\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0335 - val_loss: 1.0523\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0303 - val_loss: 1.0246\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.0175\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0259 - val_loss: 1.0108\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0241 - val_loss: 1.0185\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0230 - val_loss: 1.0163\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0228 - val_loss: 1.0098\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0207 - val_loss: 1.0140\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0201 - val_loss: 1.0079\n",
      "625/625 [==============================] - 1s 864us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3016 - val_loss: 1.0526\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0312\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0416\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0227 - val_loss: 1.0320\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0354\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0521\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0179 - val_loss: 1.0286\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0166 - val_loss: 1.0429\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0153 - val_loss: 1.0553\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0164 - val_loss: 1.0375\n",
      "625/625 [==============================] - 1s 805us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3239 - val_loss: 1.0422\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0314 - val_loss: 1.0296\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0049\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0253\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0209 - val_loss: 1.0090\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0187 - val_loss: 1.0326\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0199 - val_loss: 0.9992\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0186 - val_loss: 1.0140\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0163 - val_loss: 1.0062\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0178 - val_loss: 1.0065\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2939 - val_loss: 1.0416\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0349 - val_loss: 1.0083\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0250\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0267 - val_loss: 1.0146\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0119\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.0115\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 1.0092\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 1.0266\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0191 - val_loss: 1.0160\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0191 - val_loss: 1.0193\n",
      "625/625 [==============================] - 1s 953us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3017 - val_loss: 1.0093\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0255 - val_loss: 1.0026\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0218 - val_loss: 1.0535\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0204 - val_loss: 1.0278\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0190 - val_loss: 1.0033\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0149 - val_loss: 1.0480\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0147 - val_loss: 1.0090\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0145 - val_loss: 1.0082\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0138 - val_loss: 1.0029\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0133 - val_loss: 1.0036\n",
      "625/625 [==============================] - 1s 833us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2494 - val_loss: 1.0460\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0260 - val_loss: 1.0286\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0210 - val_loss: 1.0215\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0197 - val_loss: 1.0278\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0266\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0158 - val_loss: 1.0217\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0156 - val_loss: 1.0176\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0141 - val_loss: 1.0270\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0143 - val_loss: 1.0322\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0126 - val_loss: 1.0131\n",
      "625/625 [==============================] - 1s 872us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2933 - val_loss: 1.0516\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0227\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0221 - val_loss: 1.0091\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0196 - val_loss: 1.0228\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0179 - val_loss: 1.0086\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0168 - val_loss: 1.0086\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0179 - val_loss: 1.0173\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0152 - val_loss: 1.0080\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0131 - val_loss: 1.0170\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0140 - val_loss: 1.0142\n",
      "625/625 [==============================] - 1s 845us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2867 - val_loss: 1.0290\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0349\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0143\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0232 - val_loss: 1.0139\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0213 - val_loss: 1.0105\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0190 - val_loss: 1.0126\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0177 - val_loss: 1.0700\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0155 - val_loss: 1.0138\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0156 - val_loss: 1.0112\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0157 - val_loss: 1.0134\n",
      "625/625 [==============================] - 1s 899us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2811 - val_loss: 1.0372\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0298 - val_loss: 1.0432\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0178\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0221 - val_loss: 1.0349\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0196\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0180 - val_loss: 1.0498\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0177 - val_loss: 1.0304\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 1.0131\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0158 - val_loss: 1.0275\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0153 - val_loss: 1.0145\n",
      "625/625 [==============================] - 1s 812us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2870 - val_loss: 1.0445\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0363 - val_loss: 1.0318\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0311 - val_loss: 1.0313\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0105\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0258 - val_loss: 1.0279\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0264 - val_loss: 1.0285\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0233 - val_loss: 1.0306\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0235 - val_loss: 1.0227\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 1.0196\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0226 - val_loss: 1.0249\n",
      "625/625 [==============================] - 1s 840us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2762 - val_loss: 1.0325\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0318 - val_loss: 1.0430\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0278 - val_loss: 1.0541\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0234 - val_loss: 1.0276\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0223 - val_loss: 1.0245\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0212 - val_loss: 1.0253\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0203 - val_loss: 1.0332\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0199\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0194 - val_loss: 1.0184\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0197 - val_loss: 1.0236\n",
      "625/625 [==============================] - 1s 840us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2689 - val_loss: 1.0199\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0300 - val_loss: 1.0338\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0258 - val_loss: 1.0189\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0247 - val_loss: 1.0160\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0221 - val_loss: 1.0290\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 1.0376\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0186 - val_loss: 1.0134\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0175 - val_loss: 1.0133\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0169 - val_loss: 1.0069\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0154 - val_loss: 1.0056\n",
      "625/625 [==============================] - 1s 999us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2754 - val_loss: 1.0148\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0267 - val_loss: 1.0221\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0239 - val_loss: 1.0285\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0179 - val_loss: 1.0208\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0172 - val_loss: 1.0101\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0176 - val_loss: 1.0162\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.0143 - val_loss: 1.0289\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0156 - val_loss: 1.0076\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.0145 - val_loss: 1.0006\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.0128 - val_loss: 1.0114\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2958 - val_loss: 1.0180\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0232 - val_loss: 1.0195\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0168 - val_loss: 1.0195\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0165 - val_loss: 1.0188\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 1.0526\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0554\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0130 - val_loss: 1.0169\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0112 - val_loss: 1.0071\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0107 - val_loss: 1.0128\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0109\n",
      "625/625 [==============================] - 1s 899us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2616 - val_loss: 1.0298\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0273 - val_loss: 1.0193\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0228 - val_loss: 1.0098\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0211 - val_loss: 1.0172\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0175 - val_loss: 1.0152\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0172 - val_loss: 1.0198\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0169 - val_loss: 1.0232\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 1.0138\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0142 - val_loss: 1.0318\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0149 - val_loss: 1.0134\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3000 - val_loss: 1.0318\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0228\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0418\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0155 - val_loss: 1.0206\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0141 - val_loss: 1.0418\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0103 - val_loss: 1.0250\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 1.0317\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0082 - val_loss: 1.0209\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0090 - val_loss: 1.0224\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0071 - val_loss: 1.0269\n",
      "625/625 [==============================] - 1s 976us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2640 - val_loss: 1.0336\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0338 - val_loss: 1.0219\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 1.0209\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0272 - val_loss: 1.0314\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0243 - val_loss: 1.0237\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0080\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0426\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0091\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0181 - val_loss: 1.0270\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0184 - val_loss: 1.0091\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2624 - val_loss: 1.0278\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0217\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0121 - val_loss: 1.0090\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0126 - val_loss: 1.0159\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0116 - val_loss: 1.0231\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0094 - val_loss: 0.9977\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0068 - val_loss: 1.0088\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0064 - val_loss: 1.0220\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0055 - val_loss: 0.9898\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0050 - val_loss: 1.0085\n",
      "625/625 [==============================] - 1s 985us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2822 - val_loss: 1.0179\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0066\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0149 - val_loss: 1.0058\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0094 - val_loss: 1.0135\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0094\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0071 - val_loss: 1.0141\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0079 - val_loss: 1.0304\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0050 - val_loss: 1.0112\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0035 - val_loss: 1.0089\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0041 - val_loss: 1.0089\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2631 - val_loss: 1.1135\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0075\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0124\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0211 - val_loss: 1.0444\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0298\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0039\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0032\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0102\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0161 - val_loss: 1.0054\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0048\n",
      "625/625 [==============================] - 1s 942us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3085 - val_loss: 1.0238\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0255 - val_loss: 1.0267\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0127\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0112\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0091\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0154 - val_loss: 1.0031\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0146 - val_loss: 1.0081\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0130 - val_loss: 1.0039\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0122 - val_loss: 1.0104\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0115 - val_loss: 0.9996\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2619 - val_loss: 1.0201\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0322 - val_loss: 1.0449\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0096\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0269 - val_loss: 1.0140\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0235 - val_loss: 1.0168\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0137\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0213 - val_loss: 1.0137\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0152\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0170\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0193 - val_loss: 1.0192\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3336 - val_loss: 1.0379\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0302 - val_loss: 1.0601\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0390\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0175\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 1.0318\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0214\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0172 - val_loss: 1.0145\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0142 - val_loss: 1.0112\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0108\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0182\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3165 - val_loss: 1.0082\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 0.9984\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0041\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 1.0166\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0107 - val_loss: 1.0036\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0027\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 0.9973\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0073 - val_loss: 1.0062\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0067 - val_loss: 1.0010\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0068 - val_loss: 1.0044\n",
      "625/625 [==============================] - 1s 975us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3337 - val_loss: 1.0057\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 0.9926\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0228 - val_loss: 0.9986\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0174 - val_loss: 0.9914\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 1.0022\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0133 - val_loss: 0.9991\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0135 - val_loss: 0.9870\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 0.9907\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0102 - val_loss: 0.9845\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0106 - val_loss: 0.9904\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3583 - val_loss: 1.0168\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0171 - val_loss: 1.0415\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 1.0102\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0103 - val_loss: 1.0130\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0076 - val_loss: 1.0518\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0051 - val_loss: 1.0112\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0073 - val_loss: 1.0171\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0030 - val_loss: 1.0081\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0048 - val_loss: 1.0275\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0040 - val_loss: 1.0014\n",
      "625/625 [==============================] - 1s 799us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.3161 - val_loss: 1.0038\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0293 - val_loss: 1.0012\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0269 - val_loss: 1.0507\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0240 - val_loss: 1.0144\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0239 - val_loss: 1.0046\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0222 - val_loss: 0.9964\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0217 - val_loss: 1.0519\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0182 - val_loss: 1.0139\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0194 - val_loss: 1.0267\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0189 - val_loss: 1.0059\n",
      "625/625 [==============================] - 1s 836us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2767 - val_loss: 1.0717\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0271 - val_loss: 1.0344\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0216 - val_loss: 1.0152\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0298\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 1.0170\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0165 - val_loss: 1.0172\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0153 - val_loss: 1.0413\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0178 - val_loss: 1.0074\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0144 - val_loss: 1.0086\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0147 - val_loss: 1.0197\n",
      "625/625 [==============================] - 1s 812us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2219 - val_loss: 1.0557\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0229 - val_loss: 1.0220\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0176 - val_loss: 1.0167\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0162 - val_loss: 1.0337\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0137 - val_loss: 1.0334\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0150 - val_loss: 1.0244\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0115 - val_loss: 1.0194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0102 - val_loss: 1.0226\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0106 - val_loss: 1.0262\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0104 - val_loss: 1.0188\n",
      "625/625 [==============================] - 1s 875us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3418 - val_loss: 1.0127\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0228 - val_loss: 1.0077\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0204\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0150 - val_loss: 1.0050\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0112 - val_loss: 1.0097\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0104 - val_loss: 1.0019\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0096 - val_loss: 1.0050\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0098 - val_loss: 1.0019\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0090 - val_loss: 1.0043\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0074 - val_loss: 0.9991\n",
      "625/625 [==============================] - 1s 877us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2874 - val_loss: 1.0237\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0201 - val_loss: 1.0463\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0166 - val_loss: 1.0149\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0141 - val_loss: 1.0115\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0128 - val_loss: 1.0241\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0112 - val_loss: 1.0236\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0104 - val_loss: 1.0270\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0080 - val_loss: 1.0233\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0079 - val_loss: 1.0112\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0071 - val_loss: 1.0096\n",
      "625/625 [==============================] - 1s 871us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2965 - val_loss: 1.0311\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0220 - val_loss: 1.0110\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0178 - val_loss: 1.0111\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0169 - val_loss: 1.0406\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0139 - val_loss: 1.0049\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0149 - val_loss: 1.0105\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0108 - val_loss: 1.0047\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0116 - val_loss: 1.0684\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0119 - val_loss: 1.0060\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0113 - val_loss: 1.0073\n",
      "625/625 [==============================] - 1s 845us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2853 - val_loss: 1.0059\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 0.9950\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0243 - val_loss: 1.0201\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0208 - val_loss: 1.0063\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 0.9985\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0162 - val_loss: 1.0167\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0177 - val_loss: 0.9981\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0156 - val_loss: 1.0080\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0143 - val_loss: 1.0372\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0131 - val_loss: 1.0036\n",
      "625/625 [==============================] - 1s 877us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3400 - val_loss: 1.0037\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0261 - val_loss: 1.0209\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0196 - val_loss: 1.0076\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0188 - val_loss: 1.0078\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0157 - val_loss: 1.0035\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0146 - val_loss: 0.9987\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0137 - val_loss: 0.9927\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0134 - val_loss: 1.0092\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0123 - val_loss: 1.0409\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0114 - val_loss: 0.9886\n",
      "625/625 [==============================] - 1s 886us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2992 - val_loss: 1.0417\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0284 - val_loss: 1.0633\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0238 - val_loss: 1.0330\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0215 - val_loss: 1.0265\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0187\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0175 - val_loss: 1.0308\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 1.0463\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0153 - val_loss: 1.0219\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0153 - val_loss: 1.0401\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0143 - val_loss: 1.0253\n",
      "625/625 [==============================] - 1s 891us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2668 - val_loss: 1.0369\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0196 - val_loss: 1.0214\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0163 - val_loss: 1.0106\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0146 - val_loss: 1.0135\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0124 - val_loss: 1.0091\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0118 - val_loss: 1.0225\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0104 - val_loss: 1.0136\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0097 - val_loss: 1.0033\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0087 - val_loss: 1.0085\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0072 - val_loss: 1.0202\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.3027 - val_loss: 1.0348\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0351 - val_loss: 1.0111\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0278 - val_loss: 1.0341\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0256 - val_loss: 1.0549\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0223 - val_loss: 1.0329\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0224 - val_loss: 1.0148\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0206 - val_loss: 1.0265\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0204 - val_loss: 1.0170\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0201 - val_loss: 1.0158\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0175 - val_loss: 1.0163\n",
      "625/625 [==============================] - 1s 785us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.3157 - val_loss: 1.0226\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0401 - val_loss: 1.0286\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0355 - val_loss: 1.0541\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0341 - val_loss: 1.0035\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0320 - val_loss: 1.0078\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0305 - val_loss: 1.0229\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0057\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0276 - val_loss: 1.0011\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0278 - val_loss: 1.0051\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0252 - val_loss: 1.0095\n",
      "625/625 [==============================] - 1s 824us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3089 - val_loss: 1.0396\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0257 - val_loss: 1.0427\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0208 - val_loss: 1.0390\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0329\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0156 - val_loss: 1.0334\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0147 - val_loss: 1.0402\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0124 - val_loss: 1.0349\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0142 - val_loss: 1.0516\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0106 - val_loss: 1.0376\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0098 - val_loss: 1.0373\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3449 - val_loss: 1.0079\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0241 - val_loss: 0.9941\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0222 - val_loss: 1.0095\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0190 - val_loss: 0.9950\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0157\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0151 - val_loss: 1.0094\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0144 - val_loss: 1.0039\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0138 - val_loss: 1.0001\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0134 - val_loss: 1.0019\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0126 - val_loss: 1.0018\n",
      "625/625 [==============================] - 1s 881us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2522 - val_loss: 1.0329\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0268 - val_loss: 1.0265\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0223 - val_loss: 1.0277\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0210 - val_loss: 1.0641\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0171 - val_loss: 1.0254\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0171 - val_loss: 1.0133\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0152 - val_loss: 1.0197\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0150 - val_loss: 1.0143\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0141 - val_loss: 1.0193\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0146 - val_loss: 1.0242\n",
      "625/625 [==============================] - 1s 942us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2572 - val_loss: 1.0536\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0345 - val_loss: 1.0473\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0298 - val_loss: 1.0431\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0269 - val_loss: 1.0178\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0369\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0215\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0217 - val_loss: 1.0448\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 1.0184\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0198 - val_loss: 1.0169\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0127\n",
      "625/625 [==============================] - 1s 939us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3315 - val_loss: 1.0149\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0316 - val_loss: 1.0117\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0252 - val_loss: 1.0403\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0244 - val_loss: 1.0046\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0218 - val_loss: 1.0047\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0212 - val_loss: 1.0003\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 0.9993\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 1.0268\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0171 - val_loss: 1.0087\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0161 - val_loss: 1.0331\n",
      "625/625 [==============================] - 1s 876us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2658 - val_loss: 1.0158\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0267 - val_loss: 1.0113\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0235 - val_loss: 1.0122\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0195 - val_loss: 1.0028\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0195 - val_loss: 0.9960\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0174 - val_loss: 1.0075\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0153 - val_loss: 0.9939\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0143 - val_loss: 0.9988\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0137 - val_loss: 1.0042\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0143 - val_loss: 0.9964\n",
      "625/625 [==============================] - 1s 878us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2694 - val_loss: 1.0324\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0315 - val_loss: 1.0073\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0254 - val_loss: 1.0133\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0212 - val_loss: 1.0073\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0176\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0209 - val_loss: 1.0166\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0167\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0180 - val_loss: 1.0219\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0174 - val_loss: 1.0030\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0165 - val_loss: 1.0036\n",
      "625/625 [==============================] - 1s 837us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3149 - val_loss: 1.0341\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0290 - val_loss: 1.0237\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0225 - val_loss: 1.0719\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0202 - val_loss: 1.0181\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0178 - val_loss: 1.0509\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0178 - val_loss: 1.0241\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0170 - val_loss: 1.0332\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0162 - val_loss: 1.0443\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0141 - val_loss: 1.0227\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0136 - val_loss: 1.0212\n",
      "625/625 [==============================] - 1s 916us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2609 - val_loss: 1.0317\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0282 - val_loss: 1.0263\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0240 - val_loss: 1.0338\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0214 - val_loss: 1.0234\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0194 - val_loss: 1.0556\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 1.0321\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0185 - val_loss: 1.0208\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0164 - val_loss: 1.0351\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0147 - val_loss: 1.0243\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0150 - val_loss: 1.0250\n",
      "625/625 [==============================] - 1s 910us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2611 - val_loss: 1.0444\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0363 - val_loss: 1.0436\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0352 - val_loss: 1.0335\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0284 - val_loss: 1.0452\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0263 - val_loss: 1.0442\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0435\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0232 - val_loss: 1.0329\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0223 - val_loss: 1.0435\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0213 - val_loss: 1.0333\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0204 - val_loss: 1.0309\n",
      "625/625 [==============================] - 1s 912us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3412 - val_loss: 1.0221\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0321 - val_loss: 1.0121\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0281 - val_loss: 1.0421\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0270 - val_loss: 1.0098\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0237 - val_loss: 1.0108\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0238 - val_loss: 1.0364\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0214 - val_loss: 1.0031\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0203 - val_loss: 1.0086\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0715\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0200 - val_loss: 1.0178\n",
      "625/625 [==============================] - 1s 877us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2672 - val_loss: 1.0118\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0367 - val_loss: 1.0497\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0316 - val_loss: 1.0165\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0306 - val_loss: 1.0110\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0289 - val_loss: 1.0485\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0339\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0066\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0246 - val_loss: 1.0048\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0098\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0228 - val_loss: 1.0086\n",
      "625/625 [==============================] - 1s 820us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2349 - val_loss: 1.0214\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0329 - val_loss: 1.0167\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0256 - val_loss: 1.0115\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0225 - val_loss: 1.0166\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0219 - val_loss: 1.0092\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0207 - val_loss: 1.0298\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0198 - val_loss: 1.0051\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0178 - val_loss: 1.0150\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0182 - val_loss: 1.0122\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0177 - val_loss: 1.0377\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2958 - val_loss: 1.0044\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0272 - val_loss: 0.9954\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 1.0062\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0190 - val_loss: 1.0026\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0176 - val_loss: 1.0246\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0150 - val_loss: 1.0014\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0158 - val_loss: 0.9961\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0151 - val_loss: 0.9985\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0123 - val_loss: 0.9992\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0130 - val_loss: 0.9927\n",
      "625/625 [==============================] - 1s 815us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3173 - val_loss: 1.0746\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0243\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0209 - val_loss: 1.0071\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0181 - val_loss: 1.0030\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0151 - val_loss: 1.0126\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0134 - val_loss: 1.0140\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0141 - val_loss: 0.9997\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0110 - val_loss: 1.0232\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0114 - val_loss: 1.0122\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0113 - val_loss: 1.0479\n",
      "625/625 [==============================] - 1s 873us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2741 - val_loss: 1.0386\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0253 - val_loss: 1.0078\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0208 - val_loss: 1.0121\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0187 - val_loss: 1.0109\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0185 - val_loss: 1.0356\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0140 - val_loss: 1.0078\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0135 - val_loss: 1.0193\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0126 - val_loss: 1.0085\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0113 - val_loss: 1.0465\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0104 - val_loss: 1.0032\n",
      "625/625 [==============================] - 1s 877us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3032 - val_loss: 1.0293\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0251 - val_loss: 1.0039\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0215 - val_loss: 1.0095\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0184 - val_loss: 1.0108\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0166 - val_loss: 1.0142\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0155 - val_loss: 0.9978\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0128 - val_loss: 1.0078\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0127 - val_loss: 1.0081\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0118 - val_loss: 1.0116\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0115 - val_loss: 1.0154\n",
      "625/625 [==============================] - 1s 925us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3492 - val_loss: 1.0206\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0250 - val_loss: 1.0408\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0198 - val_loss: 1.0253\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0180 - val_loss: 1.0349\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0146 - val_loss: 1.0214\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0127 - val_loss: 1.0265\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0121 - val_loss: 1.0205\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0132 - val_loss: 1.0179\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0122 - val_loss: 1.0150\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0103 - val_loss: 1.0212\n",
      "625/625 [==============================] - 1s 874us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3351 - val_loss: 1.0206\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0251 - val_loss: 1.0231\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0203 - val_loss: 1.0108\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 1.0179\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0153 - val_loss: 1.0114\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0142 - val_loss: 1.0034\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0137 - val_loss: 1.0026\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0129 - val_loss: 1.0081\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0133 - val_loss: 1.0030\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0112 - val_loss: 1.0153\n",
      "625/625 [==============================] - 1s 849us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2736 - val_loss: 1.0245\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0061\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0340\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0169 - val_loss: 0.9959\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0152 - val_loss: 0.9992\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0116 - val_loss: 0.9941\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0127 - val_loss: 0.9987\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0099 - val_loss: 1.0213\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0093 - val_loss: 1.0076\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0105 - val_loss: 1.0111\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3472 - val_loss: 1.0240\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0307 - val_loss: 1.0241\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0257 - val_loss: 1.0291\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0191\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0198 - val_loss: 1.0140\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0210 - val_loss: 1.0156\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0187 - val_loss: 1.0258\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0130\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0180 - val_loss: 1.0188\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0168 - val_loss: 1.0288\n",
      "625/625 [==============================] - 1s 824us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2562 - val_loss: 1.0142\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0247 - val_loss: 1.0136\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0182 - val_loss: 1.0068\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0179 - val_loss: 1.0090\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0148 - val_loss: 1.0005\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0131 - val_loss: 1.0218\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0120 - val_loss: 1.0203\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0112 - val_loss: 1.0016\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0107 - val_loss: 0.9936\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0100 - val_loss: 1.0306\n",
      "625/625 [==============================] - 1s 916us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2844 - val_loss: 0.9938\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0276 - val_loss: 0.9924\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0220 - val_loss: 0.9792\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0199 - val_loss: 0.9930\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 0.9822\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0155 - val_loss: 1.0006\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0153 - val_loss: 0.9823\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0155 - val_loss: 0.9894\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0140 - val_loss: 0.9961\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0138 - val_loss: 1.0089\n",
      "625/625 [==============================] - 1s 938us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2731 - val_loss: 1.0578\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0256 - val_loss: 1.0933\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0244 - val_loss: 1.0270\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0173 - val_loss: 1.0187\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0180 - val_loss: 1.0714\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0147 - val_loss: 1.0277\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0125 - val_loss: 1.0185\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0136 - val_loss: 1.0187\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0127 - val_loss: 1.0264\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0113 - val_loss: 1.0234\n",
      "625/625 [==============================] - 1s 869us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3055 - val_loss: 1.0432\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0348 - val_loss: 1.0124\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0294 - val_loss: 1.0053\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0264 - val_loss: 1.0193\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0242 - val_loss: 1.0025\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0237 - val_loss: 1.0054\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0216 - val_loss: 1.0039\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0213 - val_loss: 1.0052\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0206 - val_loss: 1.0054\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0194 - val_loss: 1.0121\n",
      "625/625 [==============================] - 1s 883us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2818 - val_loss: 1.0473\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0277 - val_loss: 1.0194\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0245 - val_loss: 1.0299\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 1.0089\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0187 - val_loss: 1.0130\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0181 - val_loss: 1.0380\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0163 - val_loss: 1.0299\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 1.0103\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0139 - val_loss: 1.0136\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0133 - val_loss: 1.0090\n",
      "625/625 [==============================] - 1s 979us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3373 - val_loss: 1.0314\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0366 - val_loss: 1.0301\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0315 - val_loss: 1.1009\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0283 - val_loss: 1.0229\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0270 - val_loss: 1.0191\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0257 - val_loss: 1.0269\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0228\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0218 - val_loss: 1.0182\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0235 - val_loss: 1.0195\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0211 - val_loss: 1.0232\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3466 - val_loss: 1.0295\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0205\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0422\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0190 - val_loss: 1.0517\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0158 - val_loss: 1.0189\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0147 - val_loss: 1.0324\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0137 - val_loss: 1.0147\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0132 - val_loss: 1.0250\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0130 - val_loss: 1.0161\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0114 - val_loss: 1.0207\n",
      "625/625 [==============================] - 1s 876us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3171 - val_loss: 1.0143\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0250 - val_loss: 1.0198\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0236 - val_loss: 0.9927\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0196 - val_loss: 0.9901\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0186 - val_loss: 1.0068\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0160 - val_loss: 1.0181\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0157 - val_loss: 0.9913\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0149 - val_loss: 0.9968\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0134 - val_loss: 1.0126\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0136 - val_loss: 1.0057\n",
      "625/625 [==============================] - 1s 903us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3022 - val_loss: 1.0386\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0252 - val_loss: 1.0030\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0233 - val_loss: 1.0031\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0200 - val_loss: 1.0069\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0170 - val_loss: 1.0126\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0158 - val_loss: 1.0001\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0162 - val_loss: 1.0070\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0142 - val_loss: 0.9991\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0135 - val_loss: 0.9950\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0130 - val_loss: 1.0095\n",
      "625/625 [==============================] - 1s 947us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2905 - val_loss: 1.0107\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0311 - val_loss: 1.0227\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0250 - val_loss: 1.0265\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0239 - val_loss: 1.0111\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0225 - val_loss: 1.0079\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0197 - val_loss: 1.0206\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0201 - val_loss: 1.0199\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0190 - val_loss: 1.0084\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0178 - val_loss: 1.0059\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0175 - val_loss: 1.0233\n",
      "625/625 [==============================] - 1s 912us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3455 - val_loss: 1.0651\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0306 - val_loss: 1.0574\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0252 - val_loss: 1.0461\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0249 - val_loss: 1.0210\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0210 - val_loss: 1.0795\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0215 - val_loss: 1.0121\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0190 - val_loss: 1.0613\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0191 - val_loss: 1.0423\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0184 - val_loss: 1.0126\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0163 - val_loss: 1.0076\n",
      "625/625 [==============================] - 1s 843us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2791 - val_loss: 1.0249\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0299 - val_loss: 1.0057\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0244 - val_loss: 1.0216\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0213 - val_loss: 1.0136\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0212 - val_loss: 1.0077\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0190 - val_loss: 0.9941\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0162 - val_loss: 0.9983\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0156 - val_loss: 0.9973\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0161 - val_loss: 1.0041\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0142 - val_loss: 1.0032\n",
      "625/625 [==============================] - 1s 968us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3011 - val_loss: 1.0146\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0295 - val_loss: 1.0180\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0269 - val_loss: 1.0325\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0224 - val_loss: 1.0070\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0209 - val_loss: 1.0118\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0185 - val_loss: 1.0109\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0183 - val_loss: 1.0087\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0162 - val_loss: 1.0253\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0147 - val_loss: 1.0085\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0154 - val_loss: 1.0057\n",
      "625/625 [==============================] - 1s 968us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3154 - val_loss: 1.0182\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0328 - val_loss: 1.0228\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0278 - val_loss: 1.0180\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0268 - val_loss: 1.0462\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0249 - val_loss: 1.0145\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0220 - val_loss: 1.0232\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0207 - val_loss: 1.0126\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0198 - val_loss: 1.0094\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0097\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0185 - val_loss: 1.0035\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2725 - val_loss: 1.0716\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0145\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0178 - val_loss: 1.0133\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0153\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0122 - val_loss: 1.0414\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0110 - val_loss: 1.0134\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0099 - val_loss: 1.0270\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0086 - val_loss: 1.0080\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0091 - val_loss: 1.0191\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0090 - val_loss: 1.0195\n",
      "625/625 [==============================] - 1s 937us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2690 - val_loss: 1.0256\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0482\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0165\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0145 - val_loss: 1.0215\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0129 - val_loss: 1.0333\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0447\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0120 - val_loss: 1.0205\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0100 - val_loss: 1.0450\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0087 - val_loss: 1.0194\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0097 - val_loss: 1.0190\n",
      "625/625 [==============================] - 1s 944us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2472 - val_loss: 1.0309\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0242 - val_loss: 1.0442\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0179 - val_loss: 1.0401\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0163 - val_loss: 1.0170\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0136 - val_loss: 1.0458\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0132 - val_loss: 1.0148\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0113 - val_loss: 1.0266\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0111 - val_loss: 1.0322\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0098 - val_loss: 1.0541\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0091 - val_loss: 1.0220\n",
      "625/625 [==============================] - 1s 906us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2656 - val_loss: 1.0069\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0258 - val_loss: 0.9963\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0204 - val_loss: 1.0382\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0193 - val_loss: 0.9963\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0160 - val_loss: 0.9932\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0154 - val_loss: 0.9905\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 1.0147\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0141 - val_loss: 1.0019\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0114 - val_loss: 0.9871\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0123 - val_loss: 1.0028\n",
      "625/625 [==============================] - 1s 974us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2666 - val_loss: 1.0492\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0276\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0324\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0192 - val_loss: 1.0428\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0150\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0484\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0144 - val_loss: 1.0222\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0141 - val_loss: 1.0174\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0133 - val_loss: 1.0182\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0127 - val_loss: 1.0490\n",
      "625/625 [==============================] - 1s 936us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2877 - val_loss: 1.0242\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0218 - val_loss: 1.0270\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0180 - val_loss: 1.0128\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0340\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0144 - val_loss: 1.0205\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0112 - val_loss: 1.0140\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 1.0376\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 1.0134\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0103 - val_loss: 1.0319\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0082 - val_loss: 1.0120\n",
      "625/625 [==============================] - 1s 983us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3186 - val_loss: 1.0070\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0318 - val_loss: 1.0116\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0270 - val_loss: 1.0062\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0230 - val_loss: 1.0051\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0215 - val_loss: 0.9983\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0185 - val_loss: 1.0101\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0200 - val_loss: 0.9989\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0175 - val_loss: 1.0170\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0174 - val_loss: 1.0359\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0166 - val_loss: 1.0099\n",
      "625/625 [==============================] - 1s 933us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3150 - val_loss: 1.0251\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0260 - val_loss: 1.0368\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0205 - val_loss: 1.0422\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0169 - val_loss: 1.0311\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0306\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0140 - val_loss: 1.0227\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0267\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0134 - val_loss: 1.0290\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0112 - val_loss: 1.0408\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0121 - val_loss: 1.0440\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2913 - val_loss: 1.0177\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0335 - val_loss: 1.1144\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 1.0683\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0265 - val_loss: 1.0161\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0275\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0221 - val_loss: 1.0105\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0226 - val_loss: 1.0116\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0324\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0192 - val_loss: 1.0132\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 1.0383\n",
      "625/625 [==============================] - 1s 989us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2700 - val_loss: 1.0122\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0243 - val_loss: 1.0153\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 0.9977\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0171 - val_loss: 0.9952\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0153 - val_loss: 1.0147\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0139 - val_loss: 0.9996\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0133 - val_loss: 1.0546\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0122 - val_loss: 0.9948\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0109 - val_loss: 1.0047\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0108 - val_loss: 1.0254\n",
      "625/625 [==============================] - 1s 900us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.2554 - val_loss: 1.0349\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0303 - val_loss: 1.0159\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0268 - val_loss: 1.0208\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0245 - val_loss: 1.0333\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0221 - val_loss: 1.0389\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0111\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0185 - val_loss: 1.0184\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0080\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0169 - val_loss: 1.0090\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0171 - val_loss: 1.0129\n",
      "625/625 [==============================] - 1s 932us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3146 - val_loss: 1.0236\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0316 - val_loss: 1.0009\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0242 - val_loss: 1.0091\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0103\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0219 - val_loss: 0.9982\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0195 - val_loss: 0.9990\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0180 - val_loss: 1.0195\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0196 - val_loss: 1.0030\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0179 - val_loss: 0.9960\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0175 - val_loss: 1.0007\n",
      "625/625 [==============================] - 1s 951us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3574 - val_loss: 1.0421\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0271 - val_loss: 1.0707\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0294\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0324\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0171\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0181 - val_loss: 1.0410\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0252\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 1.0274\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0150 - val_loss: 1.0176\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0142 - val_loss: 1.0400\n",
      "625/625 [==============================] - 1s 983us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2739 - val_loss: 1.0389\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0288 - val_loss: 1.0089\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0114\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 0.9988\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0215 - val_loss: 1.0104\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0192 - val_loss: 1.0019\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0207 - val_loss: 0.9961\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0172 - val_loss: 1.0074\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 1.0065\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0163 - val_loss: 0.9983\n",
      "625/625 [==============================] - 1s 941us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3064 - val_loss: 1.0313\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0394\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0192 - val_loss: 1.0180\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0128\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0143 - val_loss: 1.0289\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0130 - val_loss: 1.0343\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0114 - val_loss: 1.0121\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0120 - val_loss: 1.0334\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0100 - val_loss: 1.0140\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0099 - val_loss: 1.0238\n",
      "625/625 [==============================] - 1s 988us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3063 - val_loss: 1.0634\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0276\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0702\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0677\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0363\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0200 - val_loss: 1.0416\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0308\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0253\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0215\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0187\n",
      "625/625 [==============================] - 1s 943us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3189 - val_loss: 1.0092\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0204 - val_loss: 0.9958\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0167 - val_loss: 1.0060\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0124 - val_loss: 1.0128\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0113 - val_loss: 1.0089\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0112 - val_loss: 0.9959\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0077 - val_loss: 1.0215\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0086 - val_loss: 1.0017\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0066 - val_loss: 1.0019\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0073 - val_loss: 1.0122\n",
      "625/625 [==============================] - 1s 985us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3169 - val_loss: 1.0240\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0212 - val_loss: 1.0148\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0171 - val_loss: 1.0286\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0198\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0140 - val_loss: 1.0304\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0118 - val_loss: 1.0196\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0113 - val_loss: 1.0430\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0100 - val_loss: 1.0202\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0101 - val_loss: 1.0274\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0089 - val_loss: 1.0198\n",
      "625/625 [==============================] - 1s 989us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3475 - val_loss: 1.0164\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0292\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 1.0146\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0155 - val_loss: 1.0117\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0130 - val_loss: 1.0155\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0135 - val_loss: 1.0174\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0109 - val_loss: 1.0395\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0107 - val_loss: 1.0392\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0262\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 1.0143\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3001 - val_loss: 1.0101\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0128 - val_loss: 0.9995\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0077 - val_loss: 0.9975\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0053 - val_loss: 1.0146\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0026 - val_loss: 1.0135\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0011 - val_loss: 0.9928\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0001 - val_loss: 0.9948\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9999 - val_loss: 1.0118\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9981 - val_loss: 1.0005\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.9985 - val_loss: 0.9945\n",
      "625/625 [==============================] - 1s 955us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.2682 - val_loss: 1.0483\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0869\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 1.0523\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0136 - val_loss: 1.0481\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0098 - val_loss: 1.0746\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0080 - val_loss: 1.0452\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0333\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0077 - val_loss: 1.0533\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0068 - val_loss: 1.0502\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0062 - val_loss: 1.0315\n",
      "625/625 [==============================] - 1s 992us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3334 - val_loss: 1.0915\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0484\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0217 - val_loss: 1.0308\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0387\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0180 - val_loss: 1.0358\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0142 - val_loss: 1.0362\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0125 - val_loss: 1.0328\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0125 - val_loss: 1.0475\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0114 - val_loss: 1.0290\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0098 - val_loss: 1.0326\n",
      "625/625 [==============================] - 1s 912us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.3194 - val_loss: 1.0253\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0221 - val_loss: 1.0068\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0183 - val_loss: 0.9947\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0154 - val_loss: 0.9913\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 0.9836\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 0.9857\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0106 - val_loss: 1.0026\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0096 - val_loss: 1.0042\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0090 - val_loss: 0.9857\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0086 - val_loss: 0.9923\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2737 - val_loss: 1.0589\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0388\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0656\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0144 - val_loss: 1.0354\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0138 - val_loss: 1.0312\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0124 - val_loss: 1.0335\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 1.0440\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0115 - val_loss: 1.0271\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 1.0361\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0094 - val_loss: 1.0360\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Results for data2:\n",
      "Iteration 1: MAPE: 59.70%\n",
      "Iteration 2: MAPE: 158.95%\n",
      "Iteration 3: MAPE: 76.24%\n",
      "Iteration 4: MAPE: 979.77%\n",
      "Iteration 5: MAPE: 131.57%\n",
      "Iteration 6: MAPE: 115.39%\n",
      "Iteration 7: MAPE: 67.21%\n",
      "Iteration 8: MAPE: 105.01%\n",
      "Iteration 9: MAPE: 96.06%\n",
      "Iteration 10: MAPE: 69.78%\n",
      "Iteration 11: MAPE: 68.51%\n",
      "Iteration 12: MAPE: 80.53%\n",
      "Iteration 13: MAPE: 687.51%\n",
      "Iteration 14: MAPE: 67.74%\n",
      "Iteration 15: MAPE: 71.83%\n",
      "Iteration 16: MAPE: 74.38%\n",
      "Iteration 17: MAPE: 71.53%\n",
      "Iteration 18: MAPE: 65.63%\n",
      "Iteration 19: MAPE: 64.17%\n",
      "Iteration 20: MAPE: 63.39%\n",
      "Iteration 21: MAPE: 89.77%\n",
      "Iteration 22: MAPE: 65.71%\n",
      "Iteration 23: MAPE: 131.65%\n",
      "Iteration 24: MAPE: 84.73%\n",
      "Iteration 25: MAPE: 68.22%\n",
      "Iteration 26: MAPE: 70.34%\n",
      "Iteration 27: MAPE: 56.72%\n",
      "Iteration 28: MAPE: 72.99%\n",
      "Iteration 29: MAPE: 80.79%\n",
      "Iteration 30: MAPE: 74.92%\n",
      "Iteration 31: MAPE: 75.07%\n",
      "Iteration 32: MAPE: 81.87%\n",
      "Iteration 33: MAPE: 64.98%\n",
      "Iteration 34: MAPE: 72.15%\n",
      "Iteration 35: MAPE: 141.66%\n",
      "Iteration 36: MAPE: 78.09%\n",
      "Iteration 37: MAPE: 69.31%\n",
      "Iteration 38: MAPE: 58.16%\n",
      "Iteration 39: MAPE: 152.54%\n",
      "Iteration 40: MAPE: 60.17%\n",
      "Iteration 41: MAPE: 111.82%\n",
      "Iteration 42: MAPE: 77.75%\n",
      "Iteration 43: MAPE: 580.71%\n",
      "Iteration 44: MAPE: 172.25%\n",
      "Iteration 45: MAPE: 71.11%\n",
      "Iteration 46: MAPE: 164.52%\n",
      "Iteration 47: MAPE: 57.82%\n",
      "Iteration 48: MAPE: 86.96%\n",
      "Iteration 49: MAPE: 76.18%\n",
      "Iteration 50: MAPE: 67.66%\n",
      "Iteration 51: MAPE: 77.26%\n",
      "Iteration 52: MAPE: 87.31%\n",
      "Iteration 53: MAPE: 100.75%\n",
      "Iteration 54: MAPE: 4213.58%\n",
      "Iteration 55: MAPE: 78.92%\n",
      "Iteration 56: MAPE: 53.58%\n",
      "Iteration 57: MAPE: 143.10%\n",
      "Iteration 58: MAPE: 107.05%\n",
      "Iteration 59: MAPE: 127.08%\n",
      "Iteration 60: MAPE: 56.60%\n",
      "Iteration 61: MAPE: 85.29%\n",
      "Iteration 62: MAPE: 106.30%\n",
      "Iteration 63: MAPE: 87.93%\n",
      "Iteration 64: MAPE: 80.99%\n",
      "Iteration 65: MAPE: 84.14%\n",
      "Iteration 66: MAPE: 179.73%\n",
      "Iteration 67: MAPE: 80.93%\n",
      "Iteration 68: MAPE: 387.64%\n",
      "Iteration 69: MAPE: 64.51%\n",
      "Iteration 70: MAPE: 88.51%\n",
      "Iteration 71: MAPE: 62.74%\n",
      "Iteration 72: MAPE: 74.50%\n",
      "Iteration 73: MAPE: 73.75%\n",
      "Iteration 74: MAPE: 80.62%\n",
      "Iteration 75: MAPE: 72.23%\n",
      "Iteration 76: MAPE: 80.35%\n",
      "Iteration 77: MAPE: 74.81%\n",
      "Iteration 78: MAPE: 67.75%\n",
      "Iteration 79: MAPE: 54.66%\n",
      "Iteration 80: MAPE: 87.20%\n",
      "Iteration 81: MAPE: 121.24%\n",
      "Iteration 82: MAPE: 61.73%\n",
      "Iteration 83: MAPE: 73.52%\n",
      "Iteration 84: MAPE: 59.65%\n",
      "Iteration 85: MAPE: 77.13%\n",
      "Iteration 86: MAPE: 99.15%\n",
      "Iteration 87: MAPE: 78.45%\n",
      "Iteration 88: MAPE: 130.53%\n",
      "Iteration 89: MAPE: 201.45%\n",
      "Iteration 90: MAPE: 152.52%\n",
      "Iteration 91: MAPE: 76.02%\n",
      "Iteration 92: MAPE: 276.07%\n",
      "Iteration 93: MAPE: 64.59%\n",
      "Iteration 94: MAPE: 78.40%\n",
      "Iteration 95: MAPE: 83.12%\n",
      "Iteration 96: MAPE: 78.60%\n",
      "Iteration 97: MAPE: 80.39%\n",
      "Iteration 98: MAPE: 72.81%\n",
      "Iteration 99: MAPE: 75.57%\n",
      "Iteration 100: MAPE: 248.31%\n",
      "Iteration 101: MAPE: 165.06%\n",
      "Iteration 102: MAPE: 161.20%\n",
      "Iteration 103: MAPE: 102.02%\n",
      "Iteration 104: MAPE: 215.14%\n",
      "Iteration 105: MAPE: 147.71%\n",
      "Iteration 106: MAPE: 202.22%\n",
      "Iteration 107: MAPE: 106.09%\n",
      "Iteration 108: MAPE: 190.85%\n",
      "Iteration 109: MAPE: 118.25%\n",
      "Iteration 110: MAPE: 200.88%\n",
      "Iteration 111: MAPE: 118.67%\n",
      "Iteration 112: MAPE: 131.91%\n",
      "Iteration 113: MAPE: 192.13%\n",
      "Iteration 114: MAPE: 201.56%\n",
      "Iteration 115: MAPE: 154.20%\n",
      "Iteration 116: MAPE: 127.56%\n",
      "Iteration 117: MAPE: 126.65%\n",
      "Iteration 118: MAPE: 155.34%\n",
      "Iteration 119: MAPE: 109.35%\n",
      "Iteration 120: MAPE: 129.31%\n",
      "Iteration 121: MAPE: 124.93%\n",
      "Iteration 122: MAPE: 111.93%\n",
      "Iteration 123: MAPE: 177.06%\n",
      "Iteration 124: MAPE: 122.07%\n",
      "Iteration 125: MAPE: 145.88%\n",
      "Iteration 126: MAPE: 138.76%\n",
      "Iteration 127: MAPE: 125.83%\n",
      "Iteration 128: MAPE: 157.35%\n",
      "Iteration 129: MAPE: 189.18%\n",
      "Iteration 130: MAPE: 123.42%\n",
      "Iteration 131: MAPE: 187.30%\n",
      "Iteration 132: MAPE: 131.41%\n",
      "Iteration 133: MAPE: 140.66%\n",
      "Iteration 134: MAPE: 118.56%\n",
      "Iteration 135: MAPE: 472.02%\n",
      "Iteration 136: MAPE: 739.98%\n",
      "Iteration 137: MAPE: 165.79%\n",
      "Iteration 138: MAPE: 168.34%\n",
      "Iteration 139: MAPE: 172.63%\n",
      "Iteration 140: MAPE: 109.32%\n",
      "Iteration 141: MAPE: 126.96%\n",
      "Iteration 142: MAPE: 321.10%\n",
      "Iteration 143: MAPE: 101.56%\n",
      "Iteration 144: MAPE: 348.21%\n",
      "Iteration 145: MAPE: 250.27%\n",
      "Iteration 146: MAPE: 108.85%\n",
      "Iteration 147: MAPE: 131.08%\n",
      "Iteration 148: MAPE: 217.11%\n",
      "Iteration 149: MAPE: 217.13%\n",
      "Iteration 150: MAPE: 113.32%\n",
      "Iteration 151: MAPE: 99.63%\n",
      "Iteration 152: MAPE: 167.66%\n",
      "Iteration 153: MAPE: 142.78%\n",
      "Iteration 154: MAPE: 2918.12%\n",
      "Iteration 155: MAPE: 243.14%\n",
      "Iteration 156: MAPE: 143.58%\n",
      "Iteration 157: MAPE: 130.28%\n",
      "Iteration 158: MAPE: 123.24%\n",
      "Iteration 159: MAPE: 123.12%\n",
      "Iteration 160: MAPE: 122.18%\n",
      "Iteration 161: MAPE: 124.64%\n",
      "Iteration 162: MAPE: 2840.24%\n",
      "Iteration 163: MAPE: 145.12%\n",
      "Iteration 164: MAPE: 134.80%\n",
      "Iteration 165: MAPE: 134.36%\n",
      "Iteration 166: MAPE: 480.30%\n",
      "Iteration 167: MAPE: 106.60%\n",
      "Iteration 168: MAPE: 2369.03%\n",
      "Iteration 169: MAPE: 106.38%\n",
      "Iteration 170: MAPE: 165.29%\n",
      "Iteration 171: MAPE: 117.21%\n",
      "Iteration 172: MAPE: 123.12%\n",
      "Iteration 173: MAPE: 194.21%\n",
      "Iteration 174: MAPE: 95.66%\n",
      "Iteration 175: MAPE: 149.84%\n",
      "Iteration 176: MAPE: 312.68%\n",
      "Iteration 177: MAPE: 131.76%\n",
      "Iteration 178: MAPE: 290.35%\n",
      "Iteration 179: MAPE: 151.13%\n",
      "Iteration 180: MAPE: 317.92%\n",
      "Iteration 181: MAPE: 119.26%\n",
      "Iteration 182: MAPE: 191.32%\n",
      "Iteration 183: MAPE: 129.14%\n",
      "Iteration 184: MAPE: 132.71%\n",
      "Iteration 185: MAPE: 289.35%\n",
      "Iteration 186: MAPE: 187.33%\n",
      "Iteration 187: MAPE: 136.04%\n",
      "Iteration 188: MAPE: 106.86%\n",
      "Iteration 189: MAPE: 123.37%\n",
      "Iteration 190: MAPE: 148.57%\n",
      "Iteration 191: MAPE: 133.67%\n",
      "Iteration 192: MAPE: 111.90%\n",
      "Iteration 193: MAPE: 159.14%\n",
      "Iteration 194: MAPE: 122.50%\n",
      "Iteration 195: MAPE: 138.36%\n",
      "Iteration 196: MAPE: 205.91%\n",
      "Iteration 197: MAPE: 202.62%\n",
      "Iteration 198: MAPE: 118.52%\n",
      "Iteration 199: MAPE: 102.85%\n",
      "Iteration 200: MAPE: 122.37%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7801 - val_loss: 1.1341\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0300 - val_loss: 1.0530\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0478\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0299\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0181 - val_loss: 1.1158\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0184 - val_loss: 1.0151\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0203 - val_loss: 1.0158\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0157 - val_loss: 1.0310\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0149 - val_loss: 1.0175\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0147 - val_loss: 1.0267\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.6196 - val_loss: 1.0215\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0275 - val_loss: 1.0443\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0244 - val_loss: 1.0256\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0332\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0233\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0185 - val_loss: 1.0152\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0170 - val_loss: 1.0146\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0102\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0147 - val_loss: 1.0154\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0128 - val_loss: 1.0174\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5481 - val_loss: 1.0297\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0322 - val_loss: 1.0289\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0266 - val_loss: 1.1163\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0224 - val_loss: 1.0389\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0207\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.1257\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0239\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0144 - val_loss: 1.0426\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0163 - val_loss: 1.0332\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 1.0457\n",
      "625/625 [==============================] - 1s 966us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7450 - val_loss: 1.0703\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0270\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0252 - val_loss: 1.0365\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0933\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0196 - val_loss: 1.0394\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0157 - val_loss: 1.0290\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0161 - val_loss: 1.0328\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0421\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0120 - val_loss: 1.0407\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0145 - val_loss: 1.0385\n",
      "625/625 [==============================] - 1s 985us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6165 - val_loss: 1.0162\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0266 - val_loss: 1.0270\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 1.0242\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0063\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0152\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0041\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0153 - val_loss: 1.0180\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0143 - val_loss: 1.0072\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0146 - val_loss: 1.0011\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0153 - val_loss: 1.0129\n",
      "625/625 [==============================] - 1s 993us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7084 - val_loss: 1.0486\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0401 - val_loss: 1.0324\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0349 - val_loss: 1.0432\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0341 - val_loss: 1.0096\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 1.0059\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0262 - val_loss: 0.9994\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0280 - val_loss: 1.0038\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0263 - val_loss: 1.0150\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0251 - val_loss: 1.0090\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0247 - val_loss: 1.0159\n",
      "625/625 [==============================] - 1s 978us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6822 - val_loss: 1.0421\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0408 - val_loss: 1.0525\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0382 - val_loss: 1.1130\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0355 - val_loss: 1.0232\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0312 - val_loss: 1.0238\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0307 - val_loss: 1.0287\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0291 - val_loss: 1.0154\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0266 - val_loss: 1.0301\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0267 - val_loss: 1.0217\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0250 - val_loss: 1.0218\n",
      "625/625 [==============================] - 1s 930us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.6233 - val_loss: 1.0715\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0312 - val_loss: 1.0330\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0287 - val_loss: 1.0259\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0270 - val_loss: 1.0240\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.1329\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0215 - val_loss: 1.0335\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0325\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0364\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0185 - val_loss: 1.0225\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0265\n",
      "625/625 [==============================] - 1s 963us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6957 - val_loss: 1.1629\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0349 - val_loss: 1.0168\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0137\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0243 - val_loss: 1.0272\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0258 - val_loss: 1.0039\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0091\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0263\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0199\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0172 - val_loss: 1.0138\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0234\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6458 - val_loss: 1.0130\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0385 - val_loss: 1.0314\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0339 - val_loss: 1.0145\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0329 - val_loss: 1.0172\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0275 - val_loss: 1.0374\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0279 - val_loss: 1.0112\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 1.0194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0235 - val_loss: 1.0697\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0231 - val_loss: 1.0048\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0210 - val_loss: 1.0124\n",
      "625/625 [==============================] - 1s 935us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6150 - val_loss: 1.0318\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0351 - val_loss: 1.0379\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0339 - val_loss: 1.0386\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0306 - val_loss: 1.0408\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0283 - val_loss: 1.0353\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0362\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0397\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0247 - val_loss: 1.0291\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0195\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0228 - val_loss: 1.0235\n",
      "625/625 [==============================] - 1s 995us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8613 - val_loss: 0.9986\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0354 - val_loss: 1.0383\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0327 - val_loss: 1.0230\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0295 - val_loss: 1.0386\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0259 - val_loss: 1.0271\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0074\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0383\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0248 - val_loss: 1.0222\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0098\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0172\n",
      "625/625 [==============================] - 1s 991us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6580 - val_loss: 1.0741\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0409 - val_loss: 1.0503\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0349 - val_loss: 1.0515\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0320 - val_loss: 1.0221\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0320 - val_loss: 1.0551\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0297 - val_loss: 1.0478\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0278 - val_loss: 1.0330\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0280 - val_loss: 1.0098\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0292 - val_loss: 1.0162\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0241 - val_loss: 1.0361\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6703 - val_loss: 1.0337\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0386 - val_loss: 1.0260\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0327 - val_loss: 1.0069\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0290 - val_loss: 1.0128\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0777\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0022\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0241 - val_loss: 1.0368\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0317\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0045\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0210 - val_loss: 1.0000\n",
      "625/625 [==============================] - 1s 979us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5900 - val_loss: 1.0384\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0363 - val_loss: 1.0443\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0303 - val_loss: 1.0340\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0329\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0268 - val_loss: 1.0357\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0445\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0237 - val_loss: 1.0517\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0724\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.0289\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0331\n",
      "625/625 [==============================] - 1s 965us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7160 - val_loss: 1.0153\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0363 - val_loss: 1.0160\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0352 - val_loss: 1.0073\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0319 - val_loss: 1.0078\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0292 - val_loss: 1.0595\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0274 - val_loss: 1.0054\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0089\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0055\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0243 - val_loss: 1.0066\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0243 - val_loss: 1.0319\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6496 - val_loss: 1.0452\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0332 - val_loss: 1.0224\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0259 - val_loss: 1.0185\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0503\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.0387\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0196 - val_loss: 1.0238\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0296\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0190 - val_loss: 1.0243\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0161 - val_loss: 1.0109\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0139 - val_loss: 1.0223\n",
      "625/625 [==============================] - 1s 912us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.6022 - val_loss: 1.0106\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0316 - val_loss: 1.0284\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0226\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0255 - val_loss: 1.0477\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0137\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0124\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0169 - val_loss: 1.0160\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0186 - val_loss: 1.0036\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0120\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0068\n",
      "625/625 [==============================] - 1s 966us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7115 - val_loss: 1.0362\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0469 - val_loss: 1.0306\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0426 - val_loss: 1.0393\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0384 - val_loss: 1.0274\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0359 - val_loss: 1.0245\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0346 - val_loss: 1.0360\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0305 - val_loss: 1.0303\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0319 - val_loss: 1.0265\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0333 - val_loss: 1.0292\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0300 - val_loss: 1.1844\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6883 - val_loss: 1.0323\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0365 - val_loss: 1.0094\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0319 - val_loss: 1.0064\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 1.0817\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 0.9950\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0258 - val_loss: 1.0239\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0256 - val_loss: 1.0004\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0023\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0214 - val_loss: 1.0204\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0107\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5138 - val_loss: 1.0700\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0393 - val_loss: 1.0201\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0293 - val_loss: 1.1005\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0248 - val_loss: 1.0246\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0250 - val_loss: 1.0158\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0349\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0235 - val_loss: 1.0503\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0217 - val_loss: 1.0613\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0214 - val_loss: 1.0380\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0165\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7330 - val_loss: 1.0224\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0402 - val_loss: 1.1201\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0357 - val_loss: 1.0192\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0312 - val_loss: 1.0358\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0291 - val_loss: 1.0138\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0282 - val_loss: 1.0160\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 1.0368\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0253 - val_loss: 1.0273\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0243 - val_loss: 1.0107\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0242\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7340 - val_loss: 1.0365\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0138\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0544\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0178 - val_loss: 1.0277\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0279\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0126 - val_loss: 1.0500\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0174\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0110 - val_loss: 1.0274\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0110 - val_loss: 1.0195\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0077 - val_loss: 1.0115\n",
      "625/625 [==============================] - 1s 928us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6473 - val_loss: 1.0129\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0448 - val_loss: 1.0210\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0424 - val_loss: 1.0687\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0381 - val_loss: 1.0241\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0357 - val_loss: 1.0197\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0335 - val_loss: 1.0255\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0329 - val_loss: 1.0116\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0046\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0301 - val_loss: 1.0357\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0298 - val_loss: 1.0073\n",
      "625/625 [==============================] - 1s 995us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6359 - val_loss: 1.0059\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0374 - val_loss: 1.0658\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0322 - val_loss: 1.0340\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 1.0047\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0000\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0251 - val_loss: 1.0136\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0235 - val_loss: 1.0072\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0230 - val_loss: 1.0026\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0075\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0217 - val_loss: 1.0181\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5202 - val_loss: 0.9955\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0422 - val_loss: 1.0034\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0415 - val_loss: 0.9868\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0367 - val_loss: 1.0555\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0329 - val_loss: 0.9987\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0309 - val_loss: 1.0342\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0292 - val_loss: 0.9887\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0300 - val_loss: 0.9881\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 0.9800\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0289 - val_loss: 1.0001\n",
      "625/625 [==============================] - 1s 979us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7390 - val_loss: 1.0209\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0329 - val_loss: 1.0291\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 1.0357\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0266 - val_loss: 1.0210\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0217 - val_loss: 1.0326\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0228 - val_loss: 1.0419\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0217\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0287\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0218\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0193 - val_loss: 1.0173\n",
      "625/625 [==============================] - 1s 912us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5696 - val_loss: 1.0639\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0385 - val_loss: 1.0526\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0363 - val_loss: 1.0339\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0330 - val_loss: 1.0134\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0311 - val_loss: 1.0696\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0286 - val_loss: 1.0384\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0288 - val_loss: 1.0127\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0241 - val_loss: 1.0305\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0195\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0256 - val_loss: 1.0121\n",
      "625/625 [==============================] - 1s 957us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7133 - val_loss: 0.9965\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0308 - val_loss: 0.9974\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0293 - val_loss: 0.9993\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0103\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0223 - val_loss: 0.9993\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0169\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 0.9924\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0203 - val_loss: 1.0028\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 1.0523\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 0.9896\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.8443 - val_loss: 1.0326\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0292 - val_loss: 1.0187\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0224 - val_loss: 0.9987\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0006\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0084\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 0.9912\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 0.9965\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0340\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0161 - val_loss: 1.0266\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 1.0429\n",
      "625/625 [==============================] - 1s 943us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6446 - val_loss: 1.0122\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0210 - val_loss: 1.0243\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0212 - val_loss: 1.0089\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0189 - val_loss: 1.0230\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0168 - val_loss: 1.0113\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0131 - val_loss: 1.0054\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0122 - val_loss: 1.0277\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0120 - val_loss: 1.0185\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0114 - val_loss: 1.0051\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0108 - val_loss: 1.0152\n",
      "625/625 [==============================] - 1s 910us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5677 - val_loss: 1.0441\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0270 - val_loss: 1.0025\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0008\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0082\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0107\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0046\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0236\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0163\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0125 - val_loss: 1.0044\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0147 - val_loss: 1.0051\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5384 - val_loss: 1.0271\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0318 - val_loss: 1.0291\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0293 - val_loss: 1.0232\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0249 - val_loss: 1.0708\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0373\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0045\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0391\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0346\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0129\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0290\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6575 - val_loss: 1.0738\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0263 - val_loss: 1.0340\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0219 - val_loss: 1.0273\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0313\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0981\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0284\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0164 - val_loss: 1.0215\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 1.0237\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0795\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0118 - val_loss: 1.0400\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6695 - val_loss: 1.0105\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.0417\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0200 - val_loss: 1.0017\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0154 - val_loss: 1.0033\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0145 - val_loss: 1.0031\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0145 - val_loss: 1.0060\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0113 - val_loss: 1.0088\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0110 - val_loss: 1.0032\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0031\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0092 - val_loss: 1.0131\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6033 - val_loss: 1.0667\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0255 - val_loss: 1.0724\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0300\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0197 - val_loss: 1.0200\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0085\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0174 - val_loss: 1.0151\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0150 - val_loss: 1.0169\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0169 - val_loss: 1.0111\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0126 - val_loss: 1.0219\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 1.0092\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6648 - val_loss: 1.0079\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0390 - val_loss: 1.0184\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0349 - val_loss: 1.0450\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0325 - val_loss: 0.9962\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0303 - val_loss: 0.9955\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0266 - val_loss: 1.0553\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0259 - val_loss: 1.0012\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0262 - val_loss: 1.0047\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0256 - val_loss: 0.9949\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 0.9975\n",
      "625/625 [==============================] - 1s 963us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7425 - val_loss: 1.0552\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0385 - val_loss: 1.0323\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0335 - val_loss: 1.0325\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0339 - val_loss: 1.0385\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0301 - val_loss: 1.0114\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0279 - val_loss: 1.0395\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0262 - val_loss: 1.0136\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0269 - val_loss: 1.0032\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0749\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0270 - val_loss: 1.0093\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6498 - val_loss: 1.0116\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0319 - val_loss: 1.0119\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0229\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0187\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0218 - val_loss: 1.0329\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0170\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0170 - val_loss: 1.0080\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0162 - val_loss: 1.0030\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0179 - val_loss: 1.0138\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0143 - val_loss: 1.0117\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6787 - val_loss: 1.0088\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0331 - val_loss: 0.9979\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0196\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0262 - val_loss: 1.0037\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0019\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 0.9984\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0111\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0003\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0283\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0164\n",
      "625/625 [==============================] - 1s 956us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6184 - val_loss: 1.0163\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0367 - val_loss: 1.0396\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0353 - val_loss: 1.0398\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0321 - val_loss: 1.0137\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0274 - val_loss: 1.0050\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0288 - val_loss: 1.0131\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0251 - val_loss: 1.0044\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0248 - val_loss: 1.0056\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0292\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0477\n",
      "625/625 [==============================] - 1s 955us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7568 - val_loss: 1.0319\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0393 - val_loss: 1.0197\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0330 - val_loss: 1.0438\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0289 - val_loss: 1.0275\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0258 - val_loss: 1.0096\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0244\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0153\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0495\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0349\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0197\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6189 - val_loss: 1.0012\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0324 - val_loss: 1.0332\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 0.9917\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0244 - val_loss: 1.0044\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 0.9925\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 1.0406\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 0.9856\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0184 - val_loss: 0.9897\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0180 - val_loss: 0.9905\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0165 - val_loss: 0.9993\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7494 - val_loss: 1.0269\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0429 - val_loss: 1.0084\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0375 - val_loss: 1.0736\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0331 - val_loss: 1.0588\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0311 - val_loss: 1.0095\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0312 - val_loss: 1.0054\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0294 - val_loss: 1.0165\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0282 - val_loss: 1.0089\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0256 - val_loss: 1.0095\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0251 - val_loss: 1.0142\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6160 - val_loss: 1.0417\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0423 - val_loss: 1.0802\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0327 - val_loss: 1.0206\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0294 - val_loss: 1.0474\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0306 - val_loss: 1.0068\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0280 - val_loss: 1.0081\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0264 - val_loss: 1.0217\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0243 - val_loss: 1.0065\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0063\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0056\n",
      "625/625 [==============================] - 1s 979us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6700 - val_loss: 1.0721\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0376 - val_loss: 1.0309\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0313 - val_loss: 1.0618\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0304 - val_loss: 1.0291\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0362\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0268\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0223 - val_loss: 1.0380\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0434\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0398\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0451\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6059 - val_loss: 1.1043\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0351 - val_loss: 1.0698\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0319 - val_loss: 1.0445\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 1.1347\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0421\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0256 - val_loss: 1.0301\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0229 - val_loss: 1.0274\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0673\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0791\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0414\n",
      "625/625 [==============================] - 1s 942us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5957 - val_loss: 1.0377\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0622\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0255 - val_loss: 1.0379\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.0365\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0365\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 1.0393\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0179 - val_loss: 1.0536\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0175 - val_loss: 1.0364\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 1.0357\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0301\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6139 - val_loss: 1.0272\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0335 - val_loss: 1.0314\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0313 - val_loss: 1.0168\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0267\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0149\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0252\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0362\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0218 - val_loss: 1.0464\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0193 - val_loss: 1.0621\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0509\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.7049 - val_loss: 1.0167\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0260 - val_loss: 1.0086\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0214 - val_loss: 1.0387\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0187 - val_loss: 1.0161\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0174 - val_loss: 1.0079\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0162 - val_loss: 1.0080\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0127 - val_loss: 1.0170\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 1.0119 - val_loss: 1.0123\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 12s 5ms/step - loss: 1.0108 - val_loss: 1.0162\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.0119 - val_loss: 1.0044\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.7519 - val_loss: 1.0091\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0272 - val_loss: 1.0123\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0111\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.1052\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0165 - val_loss: 1.0023\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0177 - val_loss: 1.0183\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0141 - val_loss: 1.0056\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0155 - val_loss: 1.0405\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0109 - val_loss: 0.9986\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0116 - val_loss: 1.0071\n",
      "625/625 [==============================] - 1s 858us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.6242 - val_loss: 1.0167\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 1.0428 - val_loss: 1.0499\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0378 - val_loss: 1.0080\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0315 - val_loss: 1.0588\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0328 - val_loss: 1.0125\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0015\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0357\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0304 - val_loss: 1.0217\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0259 - val_loss: 0.9992\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0275 - val_loss: 1.0011\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7117 - val_loss: 1.0092\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0334 - val_loss: 1.0405\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0346 - val_loss: 1.0842\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0304 - val_loss: 1.0306\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0052\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0108\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0223 - val_loss: 1.0128\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0160\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0270\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0105\n",
      "625/625 [==============================] - 1s 1000us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7203 - val_loss: 1.0106\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0382 - val_loss: 1.0218\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0252 - val_loss: 1.0089\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0567\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0207\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0078\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0122\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0213 - val_loss: 1.0025\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0322\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0174 - val_loss: 1.0327\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7347 - val_loss: 1.0192\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0330 - val_loss: 1.0185\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0295 - val_loss: 1.0161\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0283 - val_loss: 1.0189\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0269 - val_loss: 1.0640\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0294\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0123\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0330\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.0527\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0137\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5925 - val_loss: 1.0584\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0287 - val_loss: 0.9934\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0256 - val_loss: 1.0309\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0151\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0205 - val_loss: 0.9871\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 0.9945\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0141 - val_loss: 1.0020\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0136 - val_loss: 0.9815\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 0.9850\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0140 - val_loss: 0.9819\n",
      "625/625 [==============================] - 1s 994us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6890 - val_loss: 1.0287\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0321 - val_loss: 1.0287\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0290 - val_loss: 1.0439\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 1.0629\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0253 - val_loss: 1.0159\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0130\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0186 - val_loss: 1.0157\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0169\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0186 - val_loss: 1.0150\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0192 - val_loss: 1.0147\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6136 - val_loss: 1.0201\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0347 - val_loss: 1.1133\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0326 - val_loss: 1.0625\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0127\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0250 - val_loss: 1.0105\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0250 - val_loss: 1.0174\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0197\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0271\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0200 - val_loss: 1.0240\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0183 - val_loss: 1.0221\n",
      "625/625 [==============================] - 1s 971us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6422 - val_loss: 1.0345\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0344 - val_loss: 1.0253\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0308 - val_loss: 1.0545\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0263 - val_loss: 1.0460\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0269 - val_loss: 1.0672\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0719\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0222\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0210 - val_loss: 1.0240\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0183\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0431\n",
      "625/625 [==============================] - 1s 988us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7795 - val_loss: 1.0290\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0368 - val_loss: 1.0480\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0338 - val_loss: 1.0070\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0307 - val_loss: 1.0620\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0265 - val_loss: 1.0661\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0271 - val_loss: 1.0202\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 1.0087\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0249 - val_loss: 1.0144\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.0124\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0255\n",
      "625/625 [==============================] - 1s 958us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5588 - val_loss: 1.0297\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0266 - val_loss: 1.0476\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0257\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0269\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0280\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0161 - val_loss: 1.0428\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0129 - val_loss: 1.0112\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0144\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0127 - val_loss: 1.0094\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 1.0207\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6732 - val_loss: 1.0362\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0315 - val_loss: 1.0212\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0272 - val_loss: 1.0624\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0236 - val_loss: 1.0495\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0212 - val_loss: 1.0120\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 1.0203\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0165 - val_loss: 1.0118\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0189 - val_loss: 1.0709\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0175 - val_loss: 1.0120\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0097\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6614 - val_loss: 1.0218\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0334 - val_loss: 1.0300\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0311 - val_loss: 1.0163\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0827\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0250\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0169\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0164\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0208\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0198\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0263\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6005 - val_loss: 1.0248\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0273\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0142\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0153\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0327\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0178 - val_loss: 1.0061\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0143 - val_loss: 1.0090\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0120 - val_loss: 1.0099\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0121 - val_loss: 1.0139\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0096\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6787 - val_loss: 1.0195\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0380 - val_loss: 1.0383\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0326 - val_loss: 1.0165\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0305 - val_loss: 1.0152\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0030\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0286\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0014\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0126\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0091\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0264\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.5369 - val_loss: 1.0389\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0306 - val_loss: 1.0406\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0438\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0335\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 1.0178 - val_loss: 1.0438\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 1.0260\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0186 - val_loss: 1.0280\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0155 - val_loss: 1.0250\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0136 - val_loss: 1.0699\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0141 - val_loss: 1.0281\n",
      "625/625 [==============================] - 1s 1000us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6790 - val_loss: 1.0014\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0394 - val_loss: 1.0539\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0410 - val_loss: 1.0010\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0336 - val_loss: 0.9917\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0329 - val_loss: 0.9941\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0318 - val_loss: 0.9899\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0288 - val_loss: 1.0000\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0295 - val_loss: 1.0137\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0007\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 0.9955\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6980 - val_loss: 1.0387\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0282\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0212 - val_loss: 1.0112\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0430\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0163 - val_loss: 1.0934\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0136 - val_loss: 1.0080\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0140 - val_loss: 1.0341\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0110 - val_loss: 0.9999\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0106 - val_loss: 1.0026\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 1.0002\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6415 - val_loss: 1.0398\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0342 - val_loss: 1.0672\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0316 - val_loss: 1.0403\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0366\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0257 - val_loss: 1.0327\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0294\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0223 - val_loss: 1.0448\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0213 - val_loss: 1.0346\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0306\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0180 - val_loss: 1.0472\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6140 - val_loss: 1.0619\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0369 - val_loss: 1.0301\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0321 - val_loss: 1.1160\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0297 - val_loss: 1.0267\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0262 - val_loss: 1.0734\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0254 - val_loss: 1.0142\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0063\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0492\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0121\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0213 - val_loss: 1.0282\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6429 - val_loss: 1.0517\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0379 - val_loss: 1.0316\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0366 - val_loss: 1.0284\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0349 - val_loss: 1.0259\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0304 - val_loss: 1.0320\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0309\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0273 - val_loss: 1.0308\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0242 - val_loss: 1.0397\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0312\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0322\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.4653 - val_loss: 1.0299\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0269 - val_loss: 1.0300\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0196\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0127\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0216\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0390\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0403\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 1.0242\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0163\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0113 - val_loss: 1.0328\n",
      "625/625 [==============================] - 1s 999us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6902 - val_loss: 1.0158\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0403 - val_loss: 1.0398\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0341 - val_loss: 1.0135\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0330 - val_loss: 1.0120\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0183\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0301 - val_loss: 1.1121\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.1307\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0274 - val_loss: 1.0064\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0280 - val_loss: 1.0033\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0161\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7699 - val_loss: 1.0145\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0337 - val_loss: 1.0593\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0304 - val_loss: 1.0118\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0146\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0262 - val_loss: 1.0149\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.0115\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0221 - val_loss: 1.0138\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0125\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0224 - val_loss: 1.0395\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0192 - val_loss: 1.0084\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5991 - val_loss: 1.0473\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0386\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.0399\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0231 - val_loss: 1.0164\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0184 - val_loss: 1.0310\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0192 - val_loss: 1.0267\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0194\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0189\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0148 - val_loss: 1.0374\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0136 - val_loss: 1.0519\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.8065 - val_loss: 1.0388\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0296 - val_loss: 1.0585\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0285 - val_loss: 1.0155\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0264 - val_loss: 1.0247\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0224 - val_loss: 1.0141\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0198 - val_loss: 1.0349\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0193 - val_loss: 1.0106\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0123\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0174 - val_loss: 1.0071\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0171 - val_loss: 1.0092\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6118 - val_loss: 1.0202\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0281 - val_loss: 1.0674\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0102\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0220 - val_loss: 1.0266\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0179 - val_loss: 1.0455\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0278\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0152 - val_loss: 1.0159\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 1.0268\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 1.0242\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0140 - val_loss: 1.0101\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7120 - val_loss: 1.0401\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0414 - val_loss: 1.0464\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0366 - val_loss: 1.0263\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0338 - val_loss: 1.0287\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0338 - val_loss: 1.0152\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0319 - val_loss: 1.0180\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0302 - val_loss: 1.0152\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0289 - val_loss: 1.0050\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0294 - val_loss: 1.0116\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0268 - val_loss: 1.0145\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.7004 - val_loss: 1.0572\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0326 - val_loss: 1.0539\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0335 - val_loss: 1.0397\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0289 - val_loss: 1.0195\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0243 - val_loss: 1.0553\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0211 - val_loss: 1.0476\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0229 - val_loss: 1.0207\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0220 - val_loss: 1.0502\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0214 - val_loss: 1.0414\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0228 - val_loss: 1.0074\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6710 - val_loss: 1.0411\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0252\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0296\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0187 - val_loss: 1.0153\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0150 - val_loss: 1.0065\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0132 - val_loss: 1.0050\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 1.0208\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0111 - val_loss: 1.0147\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0110 - val_loss: 1.0092\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0101 - val_loss: 1.0056\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7632 - val_loss: 1.0421\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0317 - val_loss: 1.0123\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0292 - val_loss: 1.0472\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0419\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0233 - val_loss: 1.1110\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0215 - val_loss: 1.0163\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 1.0124\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0181 - val_loss: 1.0213\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 1.0302\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0167 - val_loss: 1.0110\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7293 - val_loss: 1.0524\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0343 - val_loss: 1.0231\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0333 - val_loss: 1.0262\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0278 - val_loss: 1.0275\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.1012\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0260 - val_loss: 1.0124\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0236 - val_loss: 1.0202\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0236 - val_loss: 1.0204\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0248\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0436\n",
      "625/625 [==============================] - 1s 997us/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6358 - val_loss: 1.0402\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0392 - val_loss: 1.1428\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0385 - val_loss: 1.0092\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0325 - val_loss: 1.0159\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0322 - val_loss: 1.0054\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0286 - val_loss: 1.0158\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0289 - val_loss: 1.0451\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0291 - val_loss: 1.0288\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0258 - val_loss: 1.0068\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0260 - val_loss: 1.0076\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6302 - val_loss: 1.0518\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0363 - val_loss: 1.0191\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0332 - val_loss: 1.0059\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0334 - val_loss: 1.0299\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0301 - val_loss: 1.0103\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0275 - val_loss: 1.0033\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0235 - val_loss: 1.0373\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 0.9998\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0239 - val_loss: 0.9992\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0259\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6132 - val_loss: 1.0245\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0272 - val_loss: 1.0104\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0250 - val_loss: 1.0128\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0223 - val_loss: 1.0601\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0213 - val_loss: 1.0131\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0180 - val_loss: 1.0153\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0155 - val_loss: 1.0091\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 1.0150\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0159 - val_loss: 1.0713\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0118 - val_loss: 1.0109\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7338 - val_loss: 1.0324\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0338 - val_loss: 1.0207\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0327 - val_loss: 1.0740\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0293 - val_loss: 1.0215\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0305 - val_loss: 1.0708\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0257 - val_loss: 1.0272\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0247 - val_loss: 1.0215\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0248 - val_loss: 1.0162\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0230 - val_loss: 1.0181\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0201\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6866 - val_loss: 1.0306\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 1.0042\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0030\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0870\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0108\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0002\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0139 - val_loss: 1.0142\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0153 - val_loss: 0.9959\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0133 - val_loss: 0.9951\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 0.9999\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5360 - val_loss: 1.0802\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0580\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0774\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0363\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0410\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0171 - val_loss: 1.0615\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0333\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0159 - val_loss: 1.0351\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0112 - val_loss: 1.0327\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0126 - val_loss: 1.0353\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7790 - val_loss: 1.0708\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0296 - val_loss: 1.0303\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0241 - val_loss: 1.0228\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0218 - val_loss: 1.0140\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0193 - val_loss: 1.0186\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0183 - val_loss: 1.0211\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0174\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0170 - val_loss: 1.0069\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0149 - val_loss: 1.0187\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0141 - val_loss: 1.0091\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.6141 - val_loss: 1.0265\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0335 - val_loss: 0.9894\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0308 - val_loss: 1.0081\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0280 - val_loss: 1.0776\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0239 - val_loss: 1.0042\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0236 - val_loss: 0.9910\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0229 - val_loss: 0.9860\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0211 - val_loss: 0.9847\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0200 - val_loss: 1.0326\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0174 - val_loss: 0.9840\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5803 - val_loss: 1.0219\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0349 - val_loss: 1.0165\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0317 - val_loss: 1.0215\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0250 - val_loss: 1.0268\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0274 - val_loss: 1.0103\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0227 - val_loss: 1.0255\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0204 - val_loss: 1.0085\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0236 - val_loss: 1.0045\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0326\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0192 - val_loss: 1.0137\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5672 - val_loss: 1.0721\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0375 - val_loss: 1.0375\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0361 - val_loss: 1.1198\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0307 - val_loss: 1.0209\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0294 - val_loss: 1.0860\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0294 - val_loss: 1.0487\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0246 - val_loss: 1.0138\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0244 - val_loss: 1.0328\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0255 - val_loss: 1.0236\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.1069\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.7808 - val_loss: 1.0224\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0302 - val_loss: 1.0083\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0237 - val_loss: 1.0413\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0212 - val_loss: 1.0101\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0074\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0332\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0147 - val_loss: 1.0247\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0149 - val_loss: 1.0159\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0151 - val_loss: 1.0036\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0139 - val_loss: 1.0015\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.7377 - val_loss: 1.0520\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0392 - val_loss: 1.0363\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0387 - val_loss: 1.0280\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0368 - val_loss: 1.0656\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0331 - val_loss: 1.0236\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0328 - val_loss: 1.0287\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0307 - val_loss: 1.0203\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0283 - val_loss: 1.0236\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0284 - val_loss: 1.0171\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0267 - val_loss: 1.0165\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6101 - val_loss: 1.0297\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0326 - val_loss: 1.0210\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0253 - val_loss: 1.0126\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0253 - val_loss: 1.1050\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0214 - val_loss: 1.0082\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 1.0141\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0180 - val_loss: 1.0082\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0105\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0142\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0176 - val_loss: 1.0102\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5788 - val_loss: 1.0367\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0314 - val_loss: 1.0169\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0275 - val_loss: 1.0154\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0687\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0234 - val_loss: 1.0149\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0210 - val_loss: 1.0615\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0211\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0195 - val_loss: 1.0332\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0190 - val_loss: 1.0218\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0159 - val_loss: 1.0043\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.5814 - val_loss: 1.0836\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0463 - val_loss: 1.0290\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0382 - val_loss: 1.0074\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0387 - val_loss: 1.0302\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0342 - val_loss: 1.0103\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0328 - val_loss: 1.0145\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0334 - val_loss: 1.0224\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0343 - val_loss: 1.0071\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0310 - val_loss: 1.0532\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0274 - val_loss: 1.0325\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6199 - val_loss: 1.0443\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0377 - val_loss: 1.0314\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0360 - val_loss: 1.0151\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0317 - val_loss: 1.0185\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0286 - val_loss: 1.0368\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0305 - val_loss: 1.0025\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0252 - val_loss: 1.0224\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0132\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0267 - val_loss: 1.0231\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0241 - val_loss: 1.0149\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6169 - val_loss: 1.0330\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0346 - val_loss: 1.0262\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0297 - val_loss: 1.0161\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0452\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0256 - val_loss: 1.0168\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0250 - val_loss: 1.0386\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0209 - val_loss: 1.0119\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0217 - val_loss: 1.0212\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0086\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0258\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.6613 - val_loss: 1.0626\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0363 - val_loss: 1.0289\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0313 - val_loss: 1.0062\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0277 - val_loss: 1.0155\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0270 - val_loss: 1.0153\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0259 - val_loss: 1.0128\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0202\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0214 - val_loss: 1.1362\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0188 - val_loss: 1.0169\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0788\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Results for data3:\n",
      "Iteration 1: MAPE: 59.70%\n",
      "Iteration 2: MAPE: 158.95%\n",
      "Iteration 3: MAPE: 76.24%\n",
      "Iteration 4: MAPE: 979.77%\n",
      "Iteration 5: MAPE: 131.57%\n",
      "Iteration 6: MAPE: 115.39%\n",
      "Iteration 7: MAPE: 67.21%\n",
      "Iteration 8: MAPE: 105.01%\n",
      "Iteration 9: MAPE: 96.06%\n",
      "Iteration 10: MAPE: 69.78%\n",
      "Iteration 11: MAPE: 68.51%\n",
      "Iteration 12: MAPE: 80.53%\n",
      "Iteration 13: MAPE: 687.51%\n",
      "Iteration 14: MAPE: 67.74%\n",
      "Iteration 15: MAPE: 71.83%\n",
      "Iteration 16: MAPE: 74.38%\n",
      "Iteration 17: MAPE: 71.53%\n",
      "Iteration 18: MAPE: 65.63%\n",
      "Iteration 19: MAPE: 64.17%\n",
      "Iteration 20: MAPE: 63.39%\n",
      "Iteration 21: MAPE: 89.77%\n",
      "Iteration 22: MAPE: 65.71%\n",
      "Iteration 23: MAPE: 131.65%\n",
      "Iteration 24: MAPE: 84.73%\n",
      "Iteration 25: MAPE: 68.22%\n",
      "Iteration 26: MAPE: 70.34%\n",
      "Iteration 27: MAPE: 56.72%\n",
      "Iteration 28: MAPE: 72.99%\n",
      "Iteration 29: MAPE: 80.79%\n",
      "Iteration 30: MAPE: 74.92%\n",
      "Iteration 31: MAPE: 75.07%\n",
      "Iteration 32: MAPE: 81.87%\n",
      "Iteration 33: MAPE: 64.98%\n",
      "Iteration 34: MAPE: 72.15%\n",
      "Iteration 35: MAPE: 141.66%\n",
      "Iteration 36: MAPE: 78.09%\n",
      "Iteration 37: MAPE: 69.31%\n",
      "Iteration 38: MAPE: 58.16%\n",
      "Iteration 39: MAPE: 152.54%\n",
      "Iteration 40: MAPE: 60.17%\n",
      "Iteration 41: MAPE: 111.82%\n",
      "Iteration 42: MAPE: 77.75%\n",
      "Iteration 43: MAPE: 580.71%\n",
      "Iteration 44: MAPE: 172.25%\n",
      "Iteration 45: MAPE: 71.11%\n",
      "Iteration 46: MAPE: 164.52%\n",
      "Iteration 47: MAPE: 57.82%\n",
      "Iteration 48: MAPE: 86.96%\n",
      "Iteration 49: MAPE: 76.18%\n",
      "Iteration 50: MAPE: 67.66%\n",
      "Iteration 51: MAPE: 77.26%\n",
      "Iteration 52: MAPE: 87.31%\n",
      "Iteration 53: MAPE: 100.75%\n",
      "Iteration 54: MAPE: 4213.58%\n",
      "Iteration 55: MAPE: 78.92%\n",
      "Iteration 56: MAPE: 53.58%\n",
      "Iteration 57: MAPE: 143.10%\n",
      "Iteration 58: MAPE: 107.05%\n",
      "Iteration 59: MAPE: 127.08%\n",
      "Iteration 60: MAPE: 56.60%\n",
      "Iteration 61: MAPE: 85.29%\n",
      "Iteration 62: MAPE: 106.30%\n",
      "Iteration 63: MAPE: 87.93%\n",
      "Iteration 64: MAPE: 80.99%\n",
      "Iteration 65: MAPE: 84.14%\n",
      "Iteration 66: MAPE: 179.73%\n",
      "Iteration 67: MAPE: 80.93%\n",
      "Iteration 68: MAPE: 387.64%\n",
      "Iteration 69: MAPE: 64.51%\n",
      "Iteration 70: MAPE: 88.51%\n",
      "Iteration 71: MAPE: 62.74%\n",
      "Iteration 72: MAPE: 74.50%\n",
      "Iteration 73: MAPE: 73.75%\n",
      "Iteration 74: MAPE: 80.62%\n",
      "Iteration 75: MAPE: 72.23%\n",
      "Iteration 76: MAPE: 80.35%\n",
      "Iteration 77: MAPE: 74.81%\n",
      "Iteration 78: MAPE: 67.75%\n",
      "Iteration 79: MAPE: 54.66%\n",
      "Iteration 80: MAPE: 87.20%\n",
      "Iteration 81: MAPE: 121.24%\n",
      "Iteration 82: MAPE: 61.73%\n",
      "Iteration 83: MAPE: 73.52%\n",
      "Iteration 84: MAPE: 59.65%\n",
      "Iteration 85: MAPE: 77.13%\n",
      "Iteration 86: MAPE: 99.15%\n",
      "Iteration 87: MAPE: 78.45%\n",
      "Iteration 88: MAPE: 130.53%\n",
      "Iteration 89: MAPE: 201.45%\n",
      "Iteration 90: MAPE: 152.52%\n",
      "Iteration 91: MAPE: 76.02%\n",
      "Iteration 92: MAPE: 276.07%\n",
      "Iteration 93: MAPE: 64.59%\n",
      "Iteration 94: MAPE: 78.40%\n",
      "Iteration 95: MAPE: 83.12%\n",
      "Iteration 96: MAPE: 78.60%\n",
      "Iteration 97: MAPE: 80.39%\n",
      "Iteration 98: MAPE: 72.81%\n",
      "Iteration 99: MAPE: 75.57%\n",
      "Iteration 100: MAPE: 248.31%\n",
      "Iteration 101: MAPE: 165.06%\n",
      "Iteration 102: MAPE: 161.20%\n",
      "Iteration 103: MAPE: 102.02%\n",
      "Iteration 104: MAPE: 215.14%\n",
      "Iteration 105: MAPE: 147.71%\n",
      "Iteration 106: MAPE: 202.22%\n",
      "Iteration 107: MAPE: 106.09%\n",
      "Iteration 108: MAPE: 190.85%\n",
      "Iteration 109: MAPE: 118.25%\n",
      "Iteration 110: MAPE: 200.88%\n",
      "Iteration 111: MAPE: 118.67%\n",
      "Iteration 112: MAPE: 131.91%\n",
      "Iteration 113: MAPE: 192.13%\n",
      "Iteration 114: MAPE: 201.56%\n",
      "Iteration 115: MAPE: 154.20%\n",
      "Iteration 116: MAPE: 127.56%\n",
      "Iteration 117: MAPE: 126.65%\n",
      "Iteration 118: MAPE: 155.34%\n",
      "Iteration 119: MAPE: 109.35%\n",
      "Iteration 120: MAPE: 129.31%\n",
      "Iteration 121: MAPE: 124.93%\n",
      "Iteration 122: MAPE: 111.93%\n",
      "Iteration 123: MAPE: 177.06%\n",
      "Iteration 124: MAPE: 122.07%\n",
      "Iteration 125: MAPE: 145.88%\n",
      "Iteration 126: MAPE: 138.76%\n",
      "Iteration 127: MAPE: 125.83%\n",
      "Iteration 128: MAPE: 157.35%\n",
      "Iteration 129: MAPE: 189.18%\n",
      "Iteration 130: MAPE: 123.42%\n",
      "Iteration 131: MAPE: 187.30%\n",
      "Iteration 132: MAPE: 131.41%\n",
      "Iteration 133: MAPE: 140.66%\n",
      "Iteration 134: MAPE: 118.56%\n",
      "Iteration 135: MAPE: 472.02%\n",
      "Iteration 136: MAPE: 739.98%\n",
      "Iteration 137: MAPE: 165.79%\n",
      "Iteration 138: MAPE: 168.34%\n",
      "Iteration 139: MAPE: 172.63%\n",
      "Iteration 140: MAPE: 109.32%\n",
      "Iteration 141: MAPE: 126.96%\n",
      "Iteration 142: MAPE: 321.10%\n",
      "Iteration 143: MAPE: 101.56%\n",
      "Iteration 144: MAPE: 348.21%\n",
      "Iteration 145: MAPE: 250.27%\n",
      "Iteration 146: MAPE: 108.85%\n",
      "Iteration 147: MAPE: 131.08%\n",
      "Iteration 148: MAPE: 217.11%\n",
      "Iteration 149: MAPE: 217.13%\n",
      "Iteration 150: MAPE: 113.32%\n",
      "Iteration 151: MAPE: 99.63%\n",
      "Iteration 152: MAPE: 167.66%\n",
      "Iteration 153: MAPE: 142.78%\n",
      "Iteration 154: MAPE: 2918.12%\n",
      "Iteration 155: MAPE: 243.14%\n",
      "Iteration 156: MAPE: 143.58%\n",
      "Iteration 157: MAPE: 130.28%\n",
      "Iteration 158: MAPE: 123.24%\n",
      "Iteration 159: MAPE: 123.12%\n",
      "Iteration 160: MAPE: 122.18%\n",
      "Iteration 161: MAPE: 124.64%\n",
      "Iteration 162: MAPE: 2840.24%\n",
      "Iteration 163: MAPE: 145.12%\n",
      "Iteration 164: MAPE: 134.80%\n",
      "Iteration 165: MAPE: 134.36%\n",
      "Iteration 166: MAPE: 480.30%\n",
      "Iteration 167: MAPE: 106.60%\n",
      "Iteration 168: MAPE: 2369.03%\n",
      "Iteration 169: MAPE: 106.38%\n",
      "Iteration 170: MAPE: 165.29%\n",
      "Iteration 171: MAPE: 117.21%\n",
      "Iteration 172: MAPE: 123.12%\n",
      "Iteration 173: MAPE: 194.21%\n",
      "Iteration 174: MAPE: 95.66%\n",
      "Iteration 175: MAPE: 149.84%\n",
      "Iteration 176: MAPE: 312.68%\n",
      "Iteration 177: MAPE: 131.76%\n",
      "Iteration 178: MAPE: 290.35%\n",
      "Iteration 179: MAPE: 151.13%\n",
      "Iteration 180: MAPE: 317.92%\n",
      "Iteration 181: MAPE: 119.26%\n",
      "Iteration 182: MAPE: 191.32%\n",
      "Iteration 183: MAPE: 129.14%\n",
      "Iteration 184: MAPE: 132.71%\n",
      "Iteration 185: MAPE: 289.35%\n",
      "Iteration 186: MAPE: 187.33%\n",
      "Iteration 187: MAPE: 136.04%\n",
      "Iteration 188: MAPE: 106.86%\n",
      "Iteration 189: MAPE: 123.37%\n",
      "Iteration 190: MAPE: 148.57%\n",
      "Iteration 191: MAPE: 133.67%\n",
      "Iteration 192: MAPE: 111.90%\n",
      "Iteration 193: MAPE: 159.14%\n",
      "Iteration 194: MAPE: 122.50%\n",
      "Iteration 195: MAPE: 138.36%\n",
      "Iteration 196: MAPE: 205.91%\n",
      "Iteration 197: MAPE: 202.62%\n",
      "Iteration 198: MAPE: 118.52%\n",
      "Iteration 199: MAPE: 102.85%\n",
      "Iteration 200: MAPE: 122.37%\n",
      "Iteration 201: MAPE: 64.77%\n",
      "Iteration 202: MAPE: 76.69%\n",
      "Iteration 203: MAPE: 170.41%\n",
      "Iteration 204: MAPE: 72.45%\n",
      "Iteration 205: MAPE: 80.78%\n",
      "Iteration 206: MAPE: 165.54%\n",
      "Iteration 207: MAPE: 174.14%\n",
      "Iteration 208: MAPE: 117.64%\n",
      "Iteration 209: MAPE: 127.69%\n",
      "Iteration 210: MAPE: 88.62%\n",
      "Iteration 211: MAPE: 92.97%\n",
      "Iteration 212: MAPE: 200.95%\n",
      "Iteration 213: MAPE: 95.28%\n",
      "Iteration 214: MAPE: 142.62%\n",
      "Iteration 215: MAPE: 60.51%\n",
      "Iteration 216: MAPE: 102.43%\n",
      "Iteration 217: MAPE: 78.47%\n",
      "Iteration 218: MAPE: 68.73%\n",
      "Iteration 219: MAPE: 76.64%\n",
      "Iteration 220: MAPE: 69.45%\n",
      "Iteration 221: MAPE: 73.57%\n",
      "Iteration 222: MAPE: 72.85%\n",
      "Iteration 223: MAPE: 88.50%\n",
      "Iteration 224: MAPE: 65.86%\n",
      "Iteration 225: MAPE: 87.35%\n",
      "Iteration 226: MAPE: 6242.31%\n",
      "Iteration 227: MAPE: 84.43%\n",
      "Iteration 228: MAPE: 77.81%\n",
      "Iteration 229: MAPE: 68.16%\n",
      "Iteration 230: MAPE: 67.28%\n",
      "Iteration 231: MAPE: 172.09%\n",
      "Iteration 232: MAPE: 417.19%\n",
      "Iteration 233: MAPE: 139.94%\n",
      "Iteration 234: MAPE: 72.57%\n",
      "Iteration 235: MAPE: 73.57%\n",
      "Iteration 236: MAPE: 66.49%\n",
      "Iteration 237: MAPE: 60.51%\n",
      "Iteration 238: MAPE: 99.81%\n",
      "Iteration 239: MAPE: 68.42%\n",
      "Iteration 240: MAPE: 87.28%\n",
      "Iteration 241: MAPE: 66.42%\n",
      "Iteration 242: MAPE: 120.81%\n",
      "Iteration 243: MAPE: 63.87%\n",
      "Iteration 244: MAPE: 64.54%\n",
      "Iteration 245: MAPE: 81.99%\n",
      "Iteration 246: MAPE: 107.56%\n",
      "Iteration 247: MAPE: 91.77%\n",
      "Iteration 248: MAPE: 114.46%\n",
      "Iteration 249: MAPE: 72.91%\n",
      "Iteration 250: MAPE: 148.96%\n",
      "Iteration 251: MAPE: 79.04%\n",
      "Iteration 252: MAPE: 192.66%\n",
      "Iteration 253: MAPE: 130.36%\n",
      "Iteration 254: MAPE: 74.80%\n",
      "Iteration 255: MAPE: 146.78%\n",
      "Iteration 256: MAPE: 140.09%\n",
      "Iteration 257: MAPE: 131.10%\n",
      "Iteration 258: MAPE: 81.88%\n",
      "Iteration 259: MAPE: 72.14%\n",
      "Iteration 260: MAPE: 91.50%\n",
      "Iteration 261: MAPE: 70.40%\n",
      "Iteration 262: MAPE: 72.66%\n",
      "Iteration 263: MAPE: 58.51%\n",
      "Iteration 264: MAPE: 61.95%\n",
      "Iteration 265: MAPE: 1025.60%\n",
      "Iteration 266: MAPE: 64.15%\n",
      "Iteration 267: MAPE: 64.44%\n",
      "Iteration 268: MAPE: 62.80%\n",
      "Iteration 269: MAPE: 187.81%\n",
      "Iteration 270: MAPE: 79.68%\n",
      "Iteration 271: MAPE: 87.16%\n",
      "Iteration 272: MAPE: 214.21%\n",
      "Iteration 273: MAPE: 71.10%\n",
      "Iteration 274: MAPE: 71.06%\n",
      "Iteration 275: MAPE: 81.88%\n",
      "Iteration 276: MAPE: 80.64%\n",
      "Iteration 277: MAPE: 59.30%\n",
      "Iteration 278: MAPE: 67.33%\n",
      "Iteration 279: MAPE: 88.84%\n",
      "Iteration 280: MAPE: 99.47%\n",
      "Iteration 281: MAPE: 71.71%\n",
      "Iteration 282: MAPE: 74.12%\n",
      "Iteration 283: MAPE: 75.63%\n",
      "Iteration 284: MAPE: 78.91%\n",
      "Iteration 285: MAPE: 57.93%\n",
      "Iteration 286: MAPE: 91.02%\n",
      "Iteration 287: MAPE: 161.79%\n",
      "Iteration 288: MAPE: 70.89%\n",
      "Iteration 289: MAPE: 78.40%\n",
      "Iteration 290: MAPE: 127.35%\n",
      "Iteration 291: MAPE: 87.14%\n",
      "Iteration 292: MAPE: 68.95%\n",
      "Iteration 293: MAPE: 67.64%\n",
      "Iteration 294: MAPE: 60.76%\n",
      "Iteration 295: MAPE: 80.92%\n",
      "Iteration 296: MAPE: 89.74%\n",
      "Iteration 297: MAPE: 82.09%\n",
      "Iteration 298: MAPE: 64.41%\n",
      "Iteration 299: MAPE: 57.62%\n",
      "Iteration 300: MAPE: 69.61%\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2918 - val_loss: 1.0108\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0201 - val_loss: 1.0097\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0183 - val_loss: 1.0195\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0144 - val_loss: 1.0149\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0138 - val_loss: 1.0069\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0131 - val_loss: 1.0081\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0117 - val_loss: 1.0140\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0110 - val_loss: 1.0104\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0103 - val_loss: 1.0035\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0102 - val_loss: 1.0111\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2959 - val_loss: 1.0272\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0223 - val_loss: 1.0361\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0208 - val_loss: 1.0278\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0193 - val_loss: 1.0399\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0179 - val_loss: 1.0164\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0161 - val_loss: 1.0099\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0163 - val_loss: 1.0103\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0162 - val_loss: 1.0102\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0164 - val_loss: 1.0151\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0165 - val_loss: 1.0475\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2763 - val_loss: 1.0692\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0151 - val_loss: 1.0147\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 1.0146\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0095 - val_loss: 1.0023\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0096 - val_loss: 1.0071\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0076 - val_loss: 1.0124\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0075 - val_loss: 1.0102\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0061 - val_loss: 1.0114\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0058 - val_loss: 1.0049\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0042 - val_loss: 1.0021\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2722 - val_loss: 0.9919\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0093 - val_loss: 1.0144\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0073 - val_loss: 0.9951\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0043 - val_loss: 0.9905\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0041 - val_loss: 0.9900\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0024 - val_loss: 1.0220\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0023 - val_loss: 1.0035\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0023 - val_loss: 0.9922\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0009 - val_loss: 0.9904\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0012 - val_loss: 0.9982\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.2829 - val_loss: 1.0092\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0222 - val_loss: 0.9959\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0190 - val_loss: 0.9933\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0175 - val_loss: 1.0124\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0168 - val_loss: 1.0108\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0126 - val_loss: 1.0002\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0140 - val_loss: 0.9953\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0121 - val_loss: 0.9994\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0122 - val_loss: 0.9943\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0107 - val_loss: 0.9941\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2518 - val_loss: 1.0390\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0148 - val_loss: 1.0351\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0101 - val_loss: 1.0496\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0081 - val_loss: 1.0244\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0091 - val_loss: 1.0302\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0064 - val_loss: 1.0353\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0040 - val_loss: 1.0195\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0043 - val_loss: 1.0266\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0044 - val_loss: 1.0250\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0039 - val_loss: 1.0412\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2546 - val_loss: 1.0244\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 1.0156\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0214 - val_loss: 1.0119\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0089\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0196 - val_loss: 1.0071\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0179 - val_loss: 1.0073\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0157 - val_loss: 1.0133\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0154 - val_loss: 1.0164\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0142 - val_loss: 1.0274\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0138 - val_loss: 1.0083\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3119 - val_loss: 1.0246\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0302 - val_loss: 1.0100\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0274 - val_loss: 1.0215\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0236 - val_loss: 1.0244\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0245 - val_loss: 1.0096\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0180\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0225 - val_loss: 1.0176\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0210 - val_loss: 1.0262\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0202 - val_loss: 1.0318\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0203 - val_loss: 1.0152\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2541 - val_loss: 1.0277\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0215 - val_loss: 1.0173\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0197 - val_loss: 1.0083\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0178 - val_loss: 0.9976\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0170 - val_loss: 1.0043\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 1.0004\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0136 - val_loss: 0.9963\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0134 - val_loss: 0.9963\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0115 - val_loss: 1.0186\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0123 - val_loss: 1.0093\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2772 - val_loss: 1.0192\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0160 - val_loss: 1.0084\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0111 - val_loss: 1.0100\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0096 - val_loss: 1.0188\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0076 - val_loss: 1.0078\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0088 - val_loss: 1.0108\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0073 - val_loss: 1.0066\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0069 - val_loss: 1.0161\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0049 - val_loss: 1.0090\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0057 - val_loss: 1.0083\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2886 - val_loss: 0.9951\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0232 - val_loss: 1.0101\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0206 - val_loss: 1.0042\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0194 - val_loss: 0.9981\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0168 - val_loss: 1.0065\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0173 - val_loss: 1.0251\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0164 - val_loss: 0.9886\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0145 - val_loss: 0.9913\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0152 - val_loss: 1.0090\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0143 - val_loss: 0.9984\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2774 - val_loss: 1.0300\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0257 - val_loss: 1.0161\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0217 - val_loss: 1.0078\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0210 - val_loss: 0.9958\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0174 - val_loss: 1.0170\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0191 - val_loss: 0.9907\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0014\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 0.9958\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 0.9935\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0161 - val_loss: 0.9998\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2524 - val_loss: 1.0309\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0199 - val_loss: 1.0133\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0167 - val_loss: 1.0213\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 0.9971\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0126 - val_loss: 0.9954\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0127 - val_loss: 0.9943\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0119 - val_loss: 1.0161\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0113 - val_loss: 0.9985\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0103 - val_loss: 0.9943\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0120 - val_loss: 0.9936\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2458 - val_loss: 0.9942\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0238 - val_loss: 0.9935\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0207 - val_loss: 1.0019\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0166 - val_loss: 1.0003\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0160 - val_loss: 1.0100\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0162 - val_loss: 1.0082\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0146 - val_loss: 0.9977\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0148 - val_loss: 1.0227\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0135 - val_loss: 1.0181\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0122 - val_loss: 1.0035\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2734 - val_loss: 1.0321\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0191\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0125 - val_loss: 1.0206\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 1.0137\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 1.0089\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0092 - val_loss: 1.0495\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0090 - val_loss: 1.0134\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0065 - val_loss: 1.0284\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0070 - val_loss: 1.0119\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0064 - val_loss: 1.0170\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2834 - val_loss: 1.0145\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0261 - val_loss: 1.0100\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0268 - val_loss: 1.0465\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0226 - val_loss: 1.0281\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0219 - val_loss: 1.0064\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0222 - val_loss: 1.0147\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0196 - val_loss: 1.0036\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0188 - val_loss: 1.0039\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0177 - val_loss: 1.0235\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0182 - val_loss: 1.0086\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.3132 - val_loss: 1.0439\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0165 - val_loss: 1.0345\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0115 - val_loss: 1.0500\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0095 - val_loss: 1.0240\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0074 - val_loss: 1.0418\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0073 - val_loss: 1.0186\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0049 - val_loss: 1.0190\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0045 - val_loss: 1.0239\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0058 - val_loss: 1.0183\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 3ms/step - loss: 1.0056 - val_loss: 1.0278\n",
      "625/625 [==============================] - 2s 3ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.2382 - val_loss: 1.0220\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0248 - val_loss: 1.0027\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0214 - val_loss: 1.0068\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0189 - val_loss: 1.0037\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0184 - val_loss: 1.0001\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0178 - val_loss: 1.0211\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0164 - val_loss: 1.0137\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0150 - val_loss: 1.0049\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0156 - val_loss: 1.0067\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0148 - val_loss: 1.0072\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3204 - val_loss: 1.0075\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0265 - val_loss: 0.9967\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0240 - val_loss: 0.9921\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0216 - val_loss: 1.0003\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0223 - val_loss: 0.9973\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0202 - val_loss: 1.0096\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0211 - val_loss: 0.9989\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0194 - val_loss: 0.9916\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0173 - val_loss: 1.0073\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0184 - val_loss: 1.0131\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2748 - val_loss: 1.0222\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0228 - val_loss: 1.0361\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0177 - val_loss: 1.0085\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0162 - val_loss: 1.0147\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0155 - val_loss: 1.0096\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0142 - val_loss: 1.0252\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0146 - val_loss: 1.0080\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0133 - val_loss: 1.0087\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0133 - val_loss: 1.0050\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.0134 - val_loss: 1.0084\n",
      "625/625 [==============================] - 1s 1ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 1.2668 - val_loss: 1.0032\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0200 - val_loss: 1.0094\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0158 - val_loss: 1.0002\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0137 - val_loss: 0.9991\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0129 - val_loss: 1.0066\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0112 - val_loss: 1.0003\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 0.9963\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0108 - val_loss: 0.9971\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0094 - val_loss: 1.0060\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0088 - val_loss: 0.9994\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 1.2791 - val_loss: 1.0190\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.0166 - val_loss: 1.0492\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.0135 - val_loss: 1.0092\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 12s 5ms/step - loss: 1.0097 - val_loss: 1.0123\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 14s 6ms/step - loss: 1.0098 - val_loss: 1.0125\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 15s 6ms/step - loss: 1.0081 - val_loss: 1.0240\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 15s 6ms/step - loss: 1.0071 - val_loss: 1.0295\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 18s 7ms/step - loss: 1.0070 - val_loss: 1.0114\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 12s 5ms/step - loss: 1.0058 - val_loss: 1.0077\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.0040 - val_loss: 1.0018\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.2758 - val_loss: 1.0389\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 1.0256 - val_loss: 1.0266\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 10s 4ms/step - loss: 1.0227 - val_loss: 1.0420\n",
      "Epoch 4/10\n",
      "2500/2500 [==============================] - 13s 5ms/step - loss: 1.0186 - val_loss: 1.0141\n",
      "Epoch 5/10\n",
      "2500/2500 [==============================] - 14s 6ms/step - loss: 1.0188 - val_loss: 1.0165\n",
      "Epoch 6/10\n",
      "2500/2500 [==============================] - 11s 4ms/step - loss: 1.0159 - val_loss: 1.0215\n",
      "Epoch 7/10\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 1.0174 - val_loss: 1.0214\n",
      "Epoch 8/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0163 - val_loss: 1.0197\n",
      "Epoch 9/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0151 - val_loss: 1.0191\n",
      "Epoch 10/10\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 1.0155 - val_loss: 1.0177\n",
      "625/625 [==============================] - 1s 2ms/step\n",
      "Epoch 1/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.2485 - val_loss: 1.0295\n",
      "Epoch 2/10\n",
      "2500/2500 [==============================] - 7s 3ms/step - loss: 1.0172 - val_loss: 1.0001\n",
      "Epoch 3/10\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 1.0176 - val_loss: 1.0049\n",
      "Epoch 4/10\n",
      "1957/2500 [======================>.......] - ETA: 8s - loss: 1.0154"
     ]
    }
   ],
   "source": [
    "# Number of iterations to obtain 100 sets of coefficients\n",
    "num_iterations = 100\n",
    "\n",
    "mape_list = []\n",
    "\n",
    "# Datasets\n",
    "data_types = [\"data1\", \"data2\", \"data3\", \"data4\"]\n",
    "\n",
    "# Run the estimation multiple times for each data type\n",
    "for data_type in data_types:\n",
    "    for i in range(num_iterations):\n",
    "        # Generate synthetic data\n",
    "        data = generate_data(data_type, 100000)\n",
    "\n",
    "        # Estimate using Neural Network and get MAPE\n",
    "        mape = neural_network_estimate(data)\n",
    "        \n",
    "        # Append the MAPE to the list\n",
    "        mape_list.append(mape)\n",
    "\n",
    "    # Print the MAPE for all iterations of the current data type\n",
    "    print(f\"Results for {data_type}:\")\n",
    "    for i, mape in enumerate(mape_list):\n",
    "        print(f\"Iteration {i + 1}: MAPE: {mape:.2f}%\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_data(data_type, n_samples):\n",
    "    n_samples = n_samples\n",
    "    \n",
    "    alpha = 3 \n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.6\n",
    "    beta3 = 0.7\n",
    "    gamma1 = 2\n",
    "    gamma2 = 3\n",
    "    \n",
    "    # Generate confounders\n",
    "    X1 = np.random.normal(0, 1, size=n_samples)\n",
    "    X2 = np.random.normal(0, 1, size=n_samples)\n",
    "    X3 = np.random.normal(0, 1, size=n_samples)\n",
    "    \n",
    "    if data_type == \"data1\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta2 * X2 + np.random.normal(loc=0, scale=0.5, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha +  gamma2* T + gamma1 * M + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data2\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, confounders, and noise\n",
    "        Y = alpha  + gamma2* T + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data3\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta1 * X1 - beta2 * X2 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcomee affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha + gamma2* T + gamma1 * M + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "    \n",
    "    elif data_type == \"data4\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Continuous Outcome influenced by intervention, confounders\n",
    "        Y = alpha + gamma2 * T + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3481419957.py, line 116)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 116\u001b[0;36m\u001b[0m\n\u001b[0;31m    mape = np.mean(np.abs(Y1 - ))\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "\n",
    "def generate_data(data_type, n_samples):\n",
    "    n_samples = n_samples\n",
    "    \n",
    "    alpha = 3 \n",
    "    beta1 = 0.5\n",
    "    beta2 = 0.6\n",
    "    beta3 = 0.7\n",
    "    gamma1 = 2\n",
    "    gamma2 = 3\n",
    "    \n",
    "    # Generate confounders\n",
    "    X1 = np.random.normal(0, 1, size=n_samples)\n",
    "    X2 = np.random.normal(0, 1, size=n_samples)\n",
    "    X3 = np.random.normal(0, 1, size=n_samples)\n",
    "    \n",
    "    if data_type == \"data1\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta2 * X2 + np.random.normal(loc=0, scale=0.5, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha +  gamma2* T + gamma1 * M + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data2\":\n",
    "        # Intervention affected by confounders\n",
    "        T = beta1 * X1 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcome affected by intervention, confounders, and noise\n",
    "        Y = alpha  + gamma2* T + beta1* X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    elif data_type == \"data3\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Mediator affected by intervention and confounders\n",
    "        M = gamma1 * T + beta1 * X1 - beta2 * X2 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        # Outcomee affected by intervention, mediator, confounders, and noise\n",
    "        Y = alpha + gamma2* T + gamma1 * M + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'Mediator': M, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "    \n",
    "    elif data_type == \"data4\":\n",
    "        # Binary intervention possibly influenced by confounders\n",
    "        prob_T = 1 / (1 + np.exp(-(X1 + X2)))  # Logistic function\n",
    "        T = (np.random.rand(n_samples) < prob_T).astype(int)\n",
    "    \n",
    "        # Continuous Outcome influenced by intervention, confounders\n",
    "        Y = alpha + gamma2 * T + beta1 * X1 + beta2 * X2 + beta3 * X3 + np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "        \n",
    "        return pd.DataFrame({'Intervention': T, 'X1': X1, 'X2': X2, 'X3': X3, 'Outcome': Y})\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown data type\")\n",
    "\n",
    "def prepare_data(df):\n",
    "    # If the data contains a 'Mediator' column, use it as an additional feature\n",
    "    if 'Mediator' in df.columns:\n",
    "        X = df[['Intervention', 'X1', 'X2', 'X3', 'Mediator']].values\n",
    "    else:\n",
    "        X = df[['Intervention', 'X1', 'X2', 'X3']].values\n",
    "\n",
    "    Y0 = df['Outcome'].values\n",
    "    Y1 = Y0 + 2.0 - 1.0  # Applying the treatment effect and bias as in the previous example\n",
    "    \n",
    "    return X, Y0, Y1\n",
    "\n",
    "# List of data types and sample sizes\n",
    "data_types = [\"data1\", \"data2\", \"data3\", \"data4\"]\n",
    "sample_sizes = [50, 100, 1000]\n",
    "\n",
    "for data_type in data_types:\n",
    "    for sample_size in sample_sizes:\n",
    "        \n",
    "        # Store treatment effects over the 100 iterations for each scenario\n",
    "        effects = []\n",
    "\n",
    "        for i in range(100):\n",
    "            # Generate data\n",
    "            df = generate_data(data_type, sample_size)\n",
    "            X, Y0, Y1 = prepare_data(df)\n",
    "            \n",
    "            # Define and compile the CFNN\n",
    "            input_layer = Input(shape=(X.shape[1],))\n",
    "            hidden_layer = Dense(64, activation='relu')(input_layer)\n",
    "            hidden_layer = Dense(64, activation='relu')(hidden_layer)\n",
    "            output_layer_0 = Dense(1)(hidden_layer)  # Potential outcome for T=0\n",
    "            output_layer_1 = Dense(1)(hidden_layer)  # Potential outcome for T=1\n",
    "\n",
    "            model = Model(inputs=input_layer, outputs=[output_layer_0, output_layer_1])\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "            # Train the CFNN\n",
    "            model.fit(X, [Y0, Y1], epochs=10, batch_size=32, verbose=0)  # verbose=0 to suppress logs\n",
    "\n",
    "            # Predict potential outcomes\n",
    "            Y0_pred, Y1_pred = model.predict(X)\n",
    "\n",
    "            # Calculate treatment effect\n",
    "            estimated_treatment_effect = np.mean(Y1_pred - Y0_pred)\n",
    "            effects.append(estimated_treatment_effect)\n",
    "            \n",
    "            mape = np.mean(np.abs(Y1 - ))\n",
    "        \n",
    "        print(f\"Data Type: {data_type}, Sample Size: {sample_size}\")\n",
    "        print(f\"Average Treatment Effect Over 100 Iterations: {np.mean(effects)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 20:47:00.028167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def train_CFNN(data, data_type):\n",
    "    # Extract X and Y from the data\n",
    "    X = data[['X1', 'X2', 'X3']].values\n",
    "    T = data['Intervention'].values\n",
    "    Y = data['Outcome'].values\n",
    "\n",
    "    # If mediator is present in the dataset, extract it\n",
    "    if 'Mediator' in data.columns:\n",
    "        M = data['Mediator'].values\n",
    "\n",
    "    # Define the CFNN model\n",
    "    input_layer = Input(shape=(X.shape[1],))\n",
    "    hidden_layer = Dense(128, activation='relu')(input_layer)\n",
    "    hidden_layer = Dropout(0.3)(hidden_layer)\n",
    "    hidden_layer = Dense(128, activation='relu')(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dense(64, activation='relu')(hidden_layer)\n",
    "    hidden_layer = Dropout(0.3)(hidden_layer)\n",
    "\n",
    "    # Adjusting output layers based on data type\n",
    "    if data_type in ['data1', 'data3']:\n",
    "        output_layer_0_Y = Dense(1)(hidden_layer)\n",
    "        output_layer_1_Y = Dense(1)(hidden_layer)\n",
    "        output_layer_0_M = Dense(1)(hidden_layer)\n",
    "        output_layer_1_M = Dense(1)(hidden_layer)\n",
    "        model = Model(inputs=input_layer, outputs=[output_layer_0_Y, output_layer_1_Y, output_layer_0_M, output_layer_1_M])\n",
    "    else:\n",
    "        output_layer_0 = Dense(1)(hidden_layer)\n",
    "        output_layer_1 = Dense(1)(hidden_layer)\n",
    "        model = Model(inputs=input_layer, outputs=[output_layer_0, output_layer_1])\n",
    "\n",
    "    # Using a custom learning rate schedule\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "    if data_type in ['data1', 'data3']:\n",
    "        # Train the CFNN with mediator outputs\n",
    "        model.fit(X, [Y*(1-T), Y*T, M*(1-T), M*T], epochs=50, batch_size=32, verbose=0, callbacks=[early_stop, reduce_lr])\n",
    "    else:\n",
    "        # Train the CFNN without mediator outputs\n",
    "        model.fit(X, [Y*(1-T), Y*T], epochs=50, batch_size=32, verbose=0, callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "    # Predict potential outcomes\n",
    "    outputs = model.predict(X)\n",
    "\n",
    "    if data_type in ['data1', 'data3']:\n",
    "        Y0_pred, Y1_pred, M0_pred, M1_pred = outputs\n",
    "    else:\n",
    "        Y0_pred, Y1_pred = outputs\n",
    "\n",
    "    # Calculate the estimated treatment effect\n",
    "    estimated_treatment_effect = np.mean(Y1_pred - Y0_pred)\n",
    "\n",
    "    # Calculate MAPE\n",
    "    mape = np.mean(np.abs((Y - Y0_pred.flatten() * (1-T) - Y1_pred.flatten() * T) / Y))\n",
    "    rmse = np.sqrt(np.mean(np.square((Y - Y0_pred.flatten()))))\n",
    "\n",
    "    return mape, rmse, estimated_treatment_effect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 19ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "16/16 [==============================] - 1s 9ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 14ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "16/16 [==============================] - 0s 8ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 8ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 10ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 1s 21ms/step\n",
      "16/16 [==============================] - 1s 10ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 11ms/step\n",
      "16/16 [==============================] - 1s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 3s 33ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 10ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 5s 53ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 1s 14ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 7ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 22ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 1s 5ms/step\n",
      "4/4 [==============================] - 1s 9ms/step\n",
      "4/4 [==============================] - 1s 7ms/step\n",
      "4/4 [==============================] - 1s 8ms/step\n",
      "4/4 [==============================] - 1s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 1s 24ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 1s 10ms/step\n",
      "4/4 [==============================] - 1s 14ms/step\n",
      "4/4 [==============================] - 1s 16ms/step\n",
      "4/4 [==============================] - 1s 13ms/step\n",
      "4/4 [==============================] - 1s 7ms/step\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 1s 9ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 1s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 1s 7ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 1s 19ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 1s 14ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "16/16 [==============================] - 1s 9ms/step\n",
      "16/16 [==============================] - 1s 9ms/step\n",
      "16/16 [==============================] - 0s 8ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 15ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 11ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 15ms/step\n",
      "16/16 [==============================] - 1s 16ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 13ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 21ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 2s 41ms/step\n",
      "32/32 [==============================] - 2s 19ms/step\n",
      "32/32 [==============================] - 1s 13ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 11ms/step\n",
      "32/32 [==============================] - 1s 13ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 11ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 10ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 17ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 21ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 2s 71ms/step\n",
      "16/16 [==============================] - 1s 9ms/step\n",
      "16/16 [==============================] - 1s 13ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 9ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "16/16 [==============================] - 0s 13ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 21ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 13ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 12ms/step\n",
      "16/16 [==============================] - 2s 25ms/step\n",
      "16/16 [==============================] - 2s 17ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 11ms/step\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 21ms/step\n",
      "16/16 [==============================] - 1s 10ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 11ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 10ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 13ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 1s 7ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 1s 4ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 10ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 1s 10ms/step\n",
      "32/32 [==============================] - 1s 5ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 2s 5ms/step\n",
      "32/32 [==============================] - 1s 9ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "32/32 [==============================] - 1s 17ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "4/4 [==============================] - 0s 23ms/step\n",
      "4/4 [==============================] - 1s 11ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 1s 39ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 2s 30ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "4/4 [==============================] - 1s 11ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 1s 6ms/step\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 1s 7ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 10ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 9ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 12ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 1s 6ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 7ms/step\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "16/16 [==============================] - 1s 8ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 1s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 1ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 3ms/step\n",
      "32/32 [==============================] - 0s 6ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 6ms/step\n",
      "32/32 [==============================] - 1s 12ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 1s 8ms/step\n",
      "     Data_Type  Sample_Size  Iteration      MAPE      RMSE  Causal_Effect  \\\n",
      "0        data1          100          1  1.690911  9.949997       4.685291   \n",
      "1        data1          100          2  1.062272  9.238076       4.200195   \n",
      "2        data1          100          3  1.893194  8.888567       4.255806   \n",
      "3        data1          100          4  2.691550  8.025768       3.068989   \n",
      "4        data1          100          5  1.365801  8.752829       2.804308   \n",
      "...        ...          ...        ...       ...       ...            ...   \n",
      "1195     data4         1000         96  0.730367  4.233007       1.970361   \n",
      "1196     data4         1000         97  0.625229  4.106360       1.703029   \n",
      "1197     data4         1000         98  0.595919  4.326134       1.667799   \n",
      "1198     data4         1000         99  0.552532  4.267975       1.983071   \n",
      "1199     data4         1000        100  0.498408  4.164627       1.866932   \n",
      "\n",
      "     Method  \n",
      "0      CFNN  \n",
      "1      CFNN  \n",
      "2      CFNN  \n",
      "3      CFNN  \n",
      "4      CFNN  \n",
      "...     ...  \n",
      "1195   CFNN  \n",
      "1196   CFNN  \n",
      "1197   CFNN  \n",
      "1198   CFNN  \n",
      "1199   CFNN  \n",
      "\n",
      "[1200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data_types = [\"data1\", \"data2\", \"data3\", \"data4\"]\n",
    "sample_sizes = [100, 500, 1000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for data_type in data_types:\n",
    "    for sample_size in sample_sizes:\n",
    "        for iteration in range(100):  # Train for 10 iterations\n",
    "            data = generate_data(data_type, sample_size)\n",
    "            mape, rmse, causal_effect = train_CFNN(data, data_type)\n",
    "            \n",
    "            results.append({\n",
    "                'Data_Type': data_type,\n",
    "                'Sample_Size': sample_size,\n",
    "                'Iteration': iteration + 1,\n",
    "                'MAPE': mape,\n",
    "                'RMSE' : rmse, \n",
    "                'Causal_Effect': causal_effect, \n",
    "                'Method': 'CFNN'\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Sample_Size</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Causal_Effect</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.690911</td>\n",
       "      <td>9.949997</td>\n",
       "      <td>4.685291</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1.062272</td>\n",
       "      <td>9.238076</td>\n",
       "      <td>4.200195</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.893194</td>\n",
       "      <td>8.888567</td>\n",
       "      <td>4.255806</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>2.691550</td>\n",
       "      <td>8.025768</td>\n",
       "      <td>3.068989</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.365801</td>\n",
       "      <td>8.752829</td>\n",
       "      <td>2.804308</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>96</td>\n",
       "      <td>0.730367</td>\n",
       "      <td>4.233007</td>\n",
       "      <td>1.970361</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>97</td>\n",
       "      <td>0.625229</td>\n",
       "      <td>4.106360</td>\n",
       "      <td>1.703029</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>98</td>\n",
       "      <td>0.595919</td>\n",
       "      <td>4.326134</td>\n",
       "      <td>1.667799</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>99</td>\n",
       "      <td>0.552532</td>\n",
       "      <td>4.267975</td>\n",
       "      <td>1.983071</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.498408</td>\n",
       "      <td>4.164627</td>\n",
       "      <td>1.866932</td>\n",
       "      <td>CFNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Type  Sample_Size  Iteration      MAPE      RMSE  Causal_Effect  \\\n",
       "0        data1          100          1  1.690911  9.949997       4.685291   \n",
       "1        data1          100          2  1.062272  9.238076       4.200195   \n",
       "2        data1          100          3  1.893194  8.888567       4.255806   \n",
       "3        data1          100          4  2.691550  8.025768       3.068989   \n",
       "4        data1          100          5  1.365801  8.752829       2.804308   \n",
       "...        ...          ...        ...       ...       ...            ...   \n",
       "1195     data4         1000         96  0.730367  4.233007       1.970361   \n",
       "1196     data4         1000         97  0.625229  4.106360       1.703029   \n",
       "1197     data4         1000         98  0.595919  4.326134       1.667799   \n",
       "1198     data4         1000         99  0.552532  4.267975       1.983071   \n",
       "1199     data4         1000        100  0.498408  4.164627       1.866932   \n",
       "\n",
       "     Method  \n",
       "0      CFNN  \n",
       "1      CFNN  \n",
       "2      CFNN  \n",
       "3      CFNN  \n",
       "4      CFNN  \n",
       "...     ...  \n",
       "1195   CFNN  \n",
       "1196   CFNN  \n",
       "1197   CFNN  \n",
       "1198   CFNN  \n",
       "1199   CFNN  \n",
       "\n",
       "[1200 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('results_cfnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Data_Type  Sample_Size  Iteration      MAPE      RMSE  Causal_Effect Method\n",
      "0     data1          100          1  1.690911  9.949997       4.685291   CFNN\n",
      "1     data1          100          2  1.062272  9.238076       4.200195   CFNN\n",
      "2     data1          100          3  1.893194  8.888567       4.255806   CFNN\n",
      "3     data1          100          4  2.691550  8.025768       3.068989   CFNN\n",
      "4     data1          100          5  1.365801  8.752829       2.804308   CFNN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "results_cfnn_df = pd.read_csv('results_cfnn.csv')\n",
    "\n",
    "# Display the first few rows to check the contents\n",
    "print(results_cfnn_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/n51_7s_n09dfndljqk4rv2zr0000gn/T/ipykernel_17555/3558166297.py:10: FutureWarning: Dropping invalid columns in DataFrameGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  averaged_df= results_cfnn_df.groupby(['Data_Type', 'Sample_Size']).agg(custom_mean).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Sample_Size</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Causal_Effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data1</td>\n",
       "      <td>100</td>\n",
       "      <td>50.5</td>\n",
       "      <td>2.009990</td>\n",
       "      <td>9.150372</td>\n",
       "      <td>3.451065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data1</td>\n",
       "      <td>500</td>\n",
       "      <td>50.5</td>\n",
       "      <td>8.443624</td>\n",
       "      <td>9.915427</td>\n",
       "      <td>7.513655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data1</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.5</td>\n",
       "      <td>8.840451</td>\n",
       "      <td>10.975158</td>\n",
       "      <td>11.673487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data2</td>\n",
       "      <td>100</td>\n",
       "      <td>50.5</td>\n",
       "      <td>2.812447</td>\n",
       "      <td>4.949719</td>\n",
       "      <td>1.103051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data2</td>\n",
       "      <td>500</td>\n",
       "      <td>50.5</td>\n",
       "      <td>3.793365</td>\n",
       "      <td>5.098381</td>\n",
       "      <td>2.153794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data2</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.5</td>\n",
       "      <td>6.175148</td>\n",
       "      <td>5.227159</td>\n",
       "      <td>3.342642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data3</td>\n",
       "      <td>100</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1.140254</td>\n",
       "      <td>7.841877</td>\n",
       "      <td>0.913744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data3</td>\n",
       "      <td>500</td>\n",
       "      <td>50.5</td>\n",
       "      <td>2.603616</td>\n",
       "      <td>7.548181</td>\n",
       "      <td>2.067969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data3</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1.428178</td>\n",
       "      <td>7.158942</td>\n",
       "      <td>3.459105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data4</td>\n",
       "      <td>100</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0.906619</td>\n",
       "      <td>4.863786</td>\n",
       "      <td>0.464721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data4</td>\n",
       "      <td>500</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0.804370</td>\n",
       "      <td>4.593455</td>\n",
       "      <td>1.008121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>data4</td>\n",
       "      <td>1000</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1.169607</td>\n",
       "      <td>4.232732</td>\n",
       "      <td>1.646921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data_Type  Sample_Size  Iteration      MAPE       RMSE  Causal_Effect\n",
       "0      data1          100       50.5  2.009990   9.150372       3.451065\n",
       "1      data1          500       50.5  8.443624   9.915427       7.513655\n",
       "2      data1         1000       50.5  8.840451  10.975158      11.673487\n",
       "3      data2          100       50.5  2.812447   4.949719       1.103051\n",
       "4      data2          500       50.5  3.793365   5.098381       2.153794\n",
       "5      data2         1000       50.5  6.175148   5.227159       3.342642\n",
       "6      data3          100       50.5  1.140254   7.841877       0.913744\n",
       "7      data3          500       50.5  2.603616   7.548181       2.067969\n",
       "8      data3         1000       50.5  1.428178   7.158942       3.459105\n",
       "9      data4          100       50.5  0.906619   4.863786       0.464721\n",
       "10     data4          500       50.5  0.804370   4.593455       1.008121\n",
       "11     data4         1000       50.5  1.169607   4.232732       1.646921"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Convert None values to NaN for correct aggregation\n",
    "results_cfnn_df = results_cfnn_df.where(pd.notna(results_cfnn_df), np.nan)\n",
    "\n",
    "# Custom aggregation function\n",
    "def custom_mean(series):\n",
    "    return np.nan if series.isna().any() else series.mean()\n",
    "\n",
    "# Group by 'Data_Type' and 'Sample_Size' and calculate custom mean for other columns\n",
    "averaged_df= results_cfnn_df.groupby(['Data_Type', 'Sample_Size']).agg(custom_mean).reset_index()\n",
    "\n",
    "averaged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzde3yT9d3/8XfSJD3QFihQWqRURMQheJgo4kRgQBEEt6lzw7nBdN46D7sRncehMOf5OPEw9UZBmcP5c7jdziF1DpRbccBEQRQP46ADLOfS0jZJc/3+SK8rTY9J2yRXe72ejwcPmitXkm/aXLmSz/fz+XxdhmEYAgAAAAAAAJLIneoBAAAAAAAAwHkISgEAAAAAACDpCEoBAAAAAAAg6QhKAQAAAAAAIOkISgEAAAAAACDpCEoBAAAAAAAg6QhKAQAAAAAAIOkISgEAAAAAACDpCEoBAAAAAAAg6QhKAQBsZ+HChXK5XHK5XFqxYkWj6w3D0NFHHy2Xy6WxY8c2eR979uxRenq6XC6X1q5d2+Q+M2fOtB7H5XIpPT1dQ4YM0W233abq6mprv7lz50bt1/Df1q1bO+BZdw31fy9paWnq2bOnTjjhBF122WVavXp1o/23bt0ql8ulhQsXRm1/8cUXddxxxykzM1Mul0vr16+XJM2fP19HH320fD6fXC6XDhw4kPgn1QY7duzQ3LlzrXG3ZsWKFVG/O5/Ppz59+uhb3/qWbrnlFm3bti1pY4lFw2OnuX8zZ87ssMfsalwul+bOndviPubxcf/991vbNm3apLlz56b8faelccycOVNHHnlk0scEAOh8PKkeAAAAzcnJydGCBQsaBZ5WrlypL774Qjk5Oc3e9vnnn5ff75ckLViwQCNGjGhyv8zMTL355puSpP379+sPf/iDfv3rX+uTTz7Riy++GLXvsmXL1L1790b3UVhYGM/T6vLOP/98XXvttTIMQ+Xl5dq4caOee+45PfXUU/rFL36h3/72t9a+hYWFevfddzVo0CBr2+7du/XjH/9YZ511lh5//HGlp6frmGOO0fr16/WLX/xCP/vZzzRjxgx5PJ4WXwOptGPHDs2bN09HHnmkTjzxxJhvd+edd2rcuHGqra3V3r179d577+mZZ57RQw89pKefflo/+tGPkjaWlsyZM0eXX365dflf//qXrrzySmv8pj59+nTI4yFi06ZNmjdvnsaOHZvSwE9L45gzZ47++7//OzUDAwB0KgSlAAC29YMf/EC///3v9dhjjyk3N9favmDBAo0aNUrl5eXN3vaZZ55Rfn6+iouL9Yc//EEPPvigMjMzG+3ndrt12mmnWZcnT56srVu36o9//KMefPBBHXHEEdZ1J598snr37t1Bz67jHD58WFlZWakehqVv375Rv9NJkyZp1qxZ+q//+i898sgjOvbYY/Xzn/9ckpSenh61ryR9+umnCgQCuuiiizRmzBhr+0cffSRJuvTSS3Xqqad2yFjt9rsbPHhw1O/jnHPO0bXXXqsJEyZo5syZOv744zV8+PAUjjBs0KBBUYFEM7Ow4fjReXTksVD/tQEAQEso3wMA2Nb06dMlSX/4wx+sbQcPHtTLL7+siy++uNnbvffee9q4caN+/OMf69JLL7VuEyvzS3V7Sqbqe/HFF1VSUqLCwkJlZmbqG9/4hm688UZVVlY2OfZp06apV69eysjI0KBBgzRr1izrerOU8F//+pfOP/989ezZ0/oCWF1drZtuukkDBw6Uz+fTEUccoSuvvLJRidubb76psWPHqlevXsrMzNSAAQN03nnn6fDhw9Y+TzzxhE444QRlZ2crJydHxx57rG6++eY2/w7S0tL06KOPqnfv3rrvvvus7Q3L92bOnKkzzjhDUjgoaZZojh07VhdddJEkaeTIkY1Kw9544w2NHz9eubm5ysrK0re+9S39/e9/jxpDS787wzD0+OOP68QTT1RmZqZ69uyp888/X//+97+j7mPs2LEaNmyY1qxZo9GjRysrK0tHHXWU7r77boVCIUnhUrxTTjlFkvTTn/7UKmVrrVSrOXl5eXryyScVDAb10EMPWds///xz/fSnP9XgwYOVlZWlI444QtOmTdOGDRusfVoby9q1a/XDH/5QRx55pDIzM3XkkUdq+vTp7X7tv/3223K5XFHHrum5556Ty+XSmjVrJIX/5tnZ2froo480fvx4devWTX369NFVV10V9ZqUYv87vf/++5o6dary8/OVnp6ufv366eyzz9ZXX33V4rhLS0v1ne98R/3791dGRoaOPvpoXXbZZdqzZ0/UfuZr6aOPPtL06dPVvXt39e3bVxdffLEOHjwYtW95ebkuvfRS9erVS9nZ2TrrrLP06aefxvy7rG/hwoX6/ve/L0kaN26c9fesX/7a3mMhltdEa+Noqnwv1venI488UlOnTtWyZcv0zW9+U5mZmTr22GP1zDPPRO13+PBhXXfddRo4cKAyMjKUl5enESNGNPmaAwDYF0EpAIBt5ebm6vzzz4/6MvKHP/xBbrdbP/jBD5q93YIFCyRJF198sX74wx8qKyvL2haLzz//XFLj0qPa2loFg8Gof7W1ta3e32effaYpU6ZowYIFWrZsmWbNmqU//vGPmjZtWtR+r7/+ukaPHq3t27frwQcf1N/+9jf96le/0tdff93oPs8991wdffTReumll/S73/1OhmHou9/9ru6//379+Mc/1l//+lfNnj1bixYt0re//W3V1NRICgeBzj77bPl8Pj3zzDNatmyZ7r77bnXr1s0qd1yyZImuuOIKjRkzRkuXLtUrr7yia665pskgWjwyMzM1YcIEbdmypdngwJw5c/TYY49JCpeyvfvuu3r88cf1+OOP61e/+pUk6dlnn9W7776rOXPmSJIWL16skpIS5ebmatGiRfrjH/+ovLw8TZo0qdGX8aZ+d5J02WWXadasWZowYYJeeeUVPf744/roo490+umnN/r979q1Sz/60Y900UUX6S9/+YsmT56sm266SYsXL5YkffOb39Szzz4rSfrVr36ld999V++++65+9rOftfl3d8opp6iwsFBvvfWWtW3Hjh3q1auX7r77bi1btkyPPfaYPB6PRo4cqc2bN8c0lq1bt2rIkCF6+OGH9frrr+uee+7Rzp07dcoppzQKxMRj9OjROumkk6y/ZX2PPvqoTjnlFCtYJkmBQEBTpkzR+PHj9corr+iqq67Sk08+2eg4j+XvVFlZqYkTJ+rrr7/WY489ptLSUj388MMaMGCADh061OK4v/jiC40aNUpPPPGEli9frltvvVXvvfeezjjjDAUCgUb7n3feeTrmmGP08ssv68Ybb9QLL7yga665xrrePC6ff/55XXvttVq6dKlOO+00TZ48Oa7fp+nss8/WnXfeKUl67LHHrL/n2WefLaljjoVYXhOtjaOhWN+fTB988IGuvfZaXXPNNfrzn/+s448/XpdccknU63/27Nl64okn9Itf/ELLli3T888/r+9///vau3dvm363AIAUMQAAsJlnn33WkGSsWbPG+Mc//mFIMjZu3GgYhmGccsopxsyZMw3DMIzjjjvOGDNmTNRtKysrjdzcXOO0006zts2YMcNwuVzG559/HrXvjBkzjG7duhmBQMAIBALG7t27jd/+9reGy+UyTjnlFGu/2267zZDU5L9BgwbF9dxCoZARCASMlStXGpKMDz74wLpu0KBBxqBBg4yqqqpmb2+O5dZbb43avmzZMkOSce+990Ztf/HFFw1JxlNPPWUYhmH8v//3/wxJxvr165t9jKuuusro0aNHXM/LJMm48sorm73+hhtuMCQZ7733nmEYhrFlyxZDkvHss89a+5h/85deeinqtvVfF6bKykojLy/PmDZtWtS+tbW1xgknnGCceuqp1rbmfnfvvvuuIcl44IEHorZ/+eWXRmZmpnH99ddb28aMGRM1ftPQoUONSZMmWZfXrFnT6Hm1pLnnXN/IkSONzMzMZq8PBoOG3+83Bg8ebFxzzTVtGkswGDQqKiqMbt26Gb/97W9jGntz4zf/Xu+//7617Z///KchyVi0aJG1bcaMGYakRo93xx13GJKMVatWGYYR+99p7dq1hiTjlVdeiXn8TTGP1W3bthmSjD//+c/WdeZrqeHxdsUVVxgZGRlGKBQyDMMw/va3v7X43G677bYWx2AeH/fdd5+17aWXXjIkGf/4xz+i9u2IY6Epzb0mmhuHYYT/psXFxdblWN+fDMMwiouLjYyMDGPbtm3WtqqqKiMvL8+47LLLrG3Dhg0zvvvd77Y6fgCAvZEpBQCwtTFjxmjQoEF65plntGHDBq1Zs6bF0r0//vGPKi8vj9rn4osvlmEYVsZIfZWVlfJ6vfJ6verTp49mzZqlyZMna+nSpY32feONN7RmzZqof6+88kqrz+Hf//63LrzwQhUUFCgtLU1er9fqlfTxxx9LCvdR+uKLL3TJJZcoIyOj1fs877zzoi6bzdobrnb2/e9/X926dbOyJE488UT5fD7913/9lxYtWtSo7EmSTj31VB04cEDTp0/Xn//853ZlzDRkGEaH3ZckvfPOO9q3b59mzJgRlcEWCoV01llnac2aNY0yvBr+7l599VW5XC5ddNFFUfdRUFCgE044odEKkAUFBY16Wh1//PEdVu7ZnIa/u2AwqDvvvFNDhw6Vz+eTx+ORz+fTZ599Zr2uWlNRUaEbbrhBRx99tDwejzwej7Kzs1VZWRnzfTRn+vTpys/Pj8qWmj9/vvr06dNkpmPDJu4XXnihJOkf//iHpNj/TkcffbR69uypG264Qb/73e+0adOmmMdcVlamyy+/XEVFRfJ4PPJ6vSouLpakJn8f55xzTtTl448/XtXV1SorK4sae3PPrSN1xLEgJeY1Eev7k+nEE0/UgAEDrMsZGRk65phjoo6xU089VX/729904403asWKFaqqqmrT2AAAqUWjcwCArblcLv30pz/VI488ourqah1zzDEaPXp0s/svWLBAGRkZOuuss6xeJccff7yOPPJILVy4UPPmzVNaWpq1f2ZmplUSkp6eruLi4qim6vWdcMIJcTc6r6io0OjRo5WRkaHf/OY3OuaYY5SVlaUvv/xS5557rvVFavfu3ZKk/v37x3S/DVf827t3rzweT6OSQ5fLpYKCAqukZdCgQXrjjTd077336sorr1RlZaWOOuoo/eIXv7BWy/rxj3+sYDCop59+Wuedd55CoZBOOeUU/eY3v9HEiRPjev4NmV8q+/Xr1677MZklW+eff36z++zbt0/dunWzLjf83X399dcyDEN9+/Zt8vZHHXVU1OVevXo12ic9PT3hX4q3b98e9XubPXu2HnvsMd1www0aM2aMevbsKbfbrZ/97Gcxj+XCCy/U3//+d82ZM0ennHKKcnNz5XK5NGXKlHY/n/T0dF122WV64IEHdN999ykQCOiPf/yjZs+erfT09Kh9PR5Po99rQUGBJFmv3Vj/Tt27d9fKlSt1xx136Oabb9b+/ftVWFioSy+9VL/61a/k9XqbvH0oFFJJSYl27NihOXPmaPjw4erWrZtCoZBOO+20Jn8fDcdsPi9zX/O4bO65daSOOBakxLwmYn1/MsVyjD3yyCPq37+/XnzxRd1zzz3KyMjQpEmTdN9992nw4MFtGicAIPkISgEAbG/mzJm69dZb9bvf/U533HFHs/t9+umnWrVqlSRFzbLX9/rrr2vKlCnWZbfbrREjRnTsgOt58803tWPHDq1YsSJqJbmGzX3NL2utNWI2uVyuqMu9evVSMBjU7t27o774GYahXbt2RfXvGT16tEaPHq3a2lqtXbtW8+fP16xZs9S3b1/98Ic/lBRuiv3Tn/5UlZWVeuutt3Tbbbdp6tSp+vTTT63MkXhVVVXpjTfe0KBBg2IOvrXGDBLOnz+/2VXfGgYxGv7uevfuLZfLpbfffrtRsERSk9uS7Z///Kd27dqlSy65xNq2ePFi/eQnP7F6+5j27NmjHj16tHqfBw8e1KuvvqrbbrtNN954o7W9pqZG+/bt65Bx//znP9fdd9+tZ555RtXV1QoGg7r88ssb7RcMBrV3796oYMSuXbskRQIU8fydhg8friVLlsgwDH344YdauHChfv3rXyszMzPquda3ceNGffDBB1q4cKFmzJhhbTd7zLWFeVw299w6UkccC4l6TcTz/hSrbt26ad68eZo3b56+/vprK2tq2rRp+uSTT9o8VgBAclG+BwCwvSOOOEK//OUvNW3atKgviw2Zzcyffvpp/eMf/4j699prr8nr9TZawSnRzC99Db9EP/nkk1GXjznmGKtMsWHT31iMHz9ekqxm26aXX35ZlZWV1vX1paWlaeTIkVZ51b/+9a9G+3Tr1k2TJ0/WLbfcIr/fr48++ijusUnhJvFXXXWV9u7dqxtuuKFN99GUb33rW+rRo4c2bdqkESNGNPnP5/O1eB9Tp06VYRj6z3/+0+Tthw8fHve4GmbMtMe+fft0+eWXy+v1RjXRdrlcjV5Xf/3rX/Wf//wnprG4XC4ZhtHoPv7nf/4npgb+sSgsLNT3v/99Pf744/rd736nadOmNRsw/v3vfx91+YUXXpAUXvFQatvfyeVy6YQTTtBDDz2kHj16NPkar7+v1PqxGo9x48a1+Nzaorm/Z0ccC/G8JuJ5jbfl/Skeffv21cyZMzV9+nRt3ry50aqNAAD7IlMKANAp3H333S1eHwwG9dxzz+kb3/hGs6ucTZs2TX/5y18azdbHat26derevXuj7UOHDm225O/0009Xz549dfnll+u2226T1+vV73//e33wwQeN9n3sscc0bdo0nXbaabrmmms0YMAAbd++Xa+//nqjL7UNTZw4UZMmTdINN9yg8vJyfetb39KHH36o2267TSeddJJ+/OMfS5J+97vf6c0339TZZ5+tAQMGqLq62grUTZgwQZJ06aWXKjMzU9/61rdUWFioXbt26a677lL37t1jymj4+uuvtXr1ahmGoUOHDmnjxo167rnn9MEHH+iaa67RpZde2up9xCo7O1vz58/XjBkztG/fPp1//vnKz8/X7t279cEHH2j37t164oknWryPb33rW/qv//ov/fSnP9XatWt15plnqlu3btq5c6dWrVql4cOH6+c//3lc4xo0aJAyMzP1+9//Xt/4xjeUnZ2tfv36tVq2+Nlnn2n16tUKhULau3ev3nvvPS1YsEDl5eV67rnndNxxx1n7Tp06VQsXLtSxxx6r448/XuvWrdN9993XKAutpbGceeaZuu+++9S7d28deeSRWrlypRYsWBBTplWs/vu//1sjR46UpCb7ukmSz+fTAw88oIqKCp1yyil655139Jvf/EaTJ0/WGWecISn2v9Orr76qxx9/XN/97nd11FFHyTAM/elPf9KBAwdaLD899thjNWjQIN14440yDEN5eXn63//9X5WWlrb5uZeUlOjMM8/U9ddfr8rKSo0YMUL/93//p+eff77N9zls2DBJ0lNPPaWcnBxlZGRo4MCB6tWrV7uPhdzc3JhfEy2No6FY35/iMXLkSE2dOlXHH3+8evbsqY8//ljPP/+8Ro0apaysrLjvDwCQIilorg4AQIuaWmWtKfVX33vllVcMScbDDz/c7P7mClDm6l3m6nutaWn1PUlGaWlpi7d/5513jFGjRhlZWVlGnz59jJ/97GfGv/71ryZXRHv33XeNyZMnG927dzfS09ONQYMGRa2kZo5l9+7djR6nqqrKuOGGG4zi4mLD6/UahYWFxs9//nNj//79Uff/ve99zyguLjbS09ONXr16GWPGjDH+8pe/WPssWrTIGDdunNG3b1/D5/MZ/fr1My644ALjww8/bPV3Vf/34na7jdzcXGP48OHGf/3Xfxnvvvtuo/3bu/qeaeXKlcbZZ59t5OXlGV6v1zjiiCOMs88+O+o+WvrdGYZhPPPMM8bIkSONbt26GZmZmcagQYOMn/zkJ8batWutfcaMGWMcd9xxjW7bcLUxwzCMP/zhD8axxx5reL3eVldaM5+z+c/j8Ri9evUyRo0aZdx8883G1q1bG91m//79xiWXXGLk5+cbWVlZxhlnnGG8/fbbxpgxYxqtStncWL766ivjvPPOM3r27Gnk5OQYZ511lrFx40ajuLjYmDFjRrPjbW78za0eeOSRRxrf+MY3mrzOPA4//PBDY+zYsUZmZqaRl5dn/PznPzcqKioa7d/a3+mTTz4xpk+fbgwaNMjIzMw0unfvbpx66qnGwoULW30emzZtMiZOnGjk5OQYPXv2NL7//e8b27dvb/T3a+61ZL5Gt2zZYm07cOCAcfHFFxs9evQwsrKyjIkTJxqffPJJm1ffMwzDePjhh42BAwcaaWlpjY6f9h4L8bwmmhtHU8dDLO9PhhFefe/ss89uNK6Gr+sbb7zRGDFihNGzZ08jPT3dOOqoo4xrrrnG2LNnT/O/UACA7bgMo4OXwQEAAADqfPjhhzrhhBP02GOP6Yorrmh0/cyZM/X//t//U0VFRQpGBwAAUonyPQAAAHS4L774Qtu2bdPNN9+swsJCzZw5M9VDAgAANkOjcwAAAHS422+/XRMnTlRFRYVeeukl+vwAAIBGKN8DAAAAAABA0pEpBQAAAAAAgKQjKAUAAAAAAICkIygFAAAAAACApGP1PUmhUEg7duxQTk6OXC5XqocDAAAAAADQaRmGoUOHDqlfv35yu5vPhyIoJWnHjh0qKipK9TAAAAAAAAC6jC+//FL9+/dv9nqCUpJycnIkhX9Zubm5KR5NY4FAQMuXL1dJSYm8Xm+qhwPYHscMEB+OGSB2HC9AfDhmgNh1peOlvLxcRUVFVrylOQSlJKtkLzc317ZBqaysLOXm5nb6FyaQDBwzQHw4ZoDYcbwA8eGYAWLXFY+X1lok0egcAAAAAAAASUdQCgAAAAAAAElHUAoAAAAAAABJR08pAAAAAADQ5YRCIfn9/lQPI2aBQEAej0fV1dWqra1N9XBa5PV6lZaW1u77ISgFAAAAAAC6FL/fry1btigUCqV6KDEzDEMFBQX68ssvW20Qbgc9evRQQUFBu8ZKUAoAAAAAAHQZhmFo586dSktLU1FRkdzuztG5KBQKqaKiQtnZ2bYes2EYOnz4sMrKyiRJhYWFbb4vglIAAAAAAKDLCAaDOnz4sPr166esrKxUDydmZrlhRkaGrYNSkpSZmSlJKisrU35+fptL+ez9LAEAAAAAAOJg9mPy+XwpHknXZgb8AoFAm+/DNkGpu+66Sy6XS7NmzbK2GYahuXPnql+/fsrMzNTYsWP10UcfRd2upqZGV199tXr37q1u3brpnHPO0VdffZXk0QMAAAAAADvpDH2ZOrOO+P3aIii1Zs0aPfXUUzr++OOjtt9777168MEH9eijj2rNmjUqKCjQxIkTdejQIWufWbNmaenSpVqyZIlWrVqliooKTZ061fad6gEAAAAAAJws5UGpiooK/ehHP9LTTz+tnj17WtsNw9DDDz+sW265Reeee66GDRumRYsW6fDhw3rhhRckSQcPHtSCBQv0wAMPaMKECTrppJO0ePFibdiwQW+88UaqnhIAAAAAAECHGDt2bFRVWVeS8kbnV155pc4++2xNmDBBv/nNb6ztW7Zs0a5du1RSUmJtS09P15gxY/TOO+/osssu07p16xQIBKL26devn4YNG6Z33nlHkyZNavIxa2pqVFNTY10uLy+XFK6DbE8tZKKYY7Lj2AA74pgB4sMxA8SO4wWID8cMUiEQCMgwDIVCIYVCoVQPJ2aGYVj/Nxx3U9uasmLFCo0fP1579+5Vjx494nr8O++8U6+99prWr18vn8+nffv2tbh/KBSSYRgKBAKNGp3HesynNCi1ZMkS/etf/9KaNWsaXbdr1y5JUt++faO29+3bV9u2bbP28fl8URlW5j7m7Zty1113ad68eY22L1++3Nad+UtLS1M9BKBT4ZgB4sMxA8SO4wWID8cMksnj8aigoEAVFRXy+/2pHk7c6rcsksKrCfr9fiuhpiWHDx+27iPeFfwOHTqkqVOn6pvf/Kaef/75Vh/P7/erqqpKb731loLBYJPjaE3KglJffvml/vu//1vLly9XRkZGs/s1bJxlGEarzbRa2+emm27S7Nmzrcvl5eUqKipSSUmJcnNzY3wGyRMIBFRaWqqJEyfK6/WmejiA7XHMAPHhmAFix/ECxIdjBqlQXV2tL7/8UtnZ2S3GG+zGMAzt2rVLN954o5YuXaqcnBxde+218ng88vl8ys3N1eLFi/XII49o8+bN6tatm8aNG6eHHnpI+fn52rp1q6ZNmyZJOvLIIyVJP/nJT/Tss89q2bJluvPOO7Vx40alpaXptNNO08MPP6xBgwZZj3/XXXdJkhYuXKjFixe3Gh+prq5WZmamzjzzzEa/51gCaFIKg1Lr1q1TWVmZTj75ZGtbbW2t3nrrLT366KPavHmzpHA2VGFhobVPWVmZlT1VUFAgv9+v/fv3R2VLlZWV6fTTT2/2sdPT05Went5ou9frtfUbpd3HB9gNxwwQH44ZIHYcL0B8OGaQTLW1tXK5XHK73XK73TIMQ1WB1CyGlulNi3mVulAopFtvvVUrVqzQ0qVLVVBQoJtvvlnr1q3TiSeeKLfbrWAwqNtvv11DhgxRWVmZrrnmGl188cV67bXXVFxcrJdfflnnnXeeNm/erNzcXGVmZsrtdquqqkqzZ8/W8OHDVVlZqVtvvVXnnXee1q9f3yijyrzcWqaV2+2Wy+Vq8viO9XhPWVBq/Pjx2rBhQ9S2n/70pzr22GN1ww036KijjlJBQYFKS0t10kknSQqnhq1cuVL33HOPJOnkk0+W1+tVaWmpLrjgAknSzp07tXHjRt17773JfUIAAAAAAMB2qgK1Gnrr6yl57E2/nqQsX2yhl4qKCi1evFgLFy7UxIkTJUmLFi1S//79rX0uvvhi6+ejjjpKjzzyiE499VRVVFQoOztbeXl5kqT8/PyonlLnnXde1GMtWLBA+fn52rRpk4YNG9bWp9duKQtK5eTkNHri3bp1U69evazts2bN0p133qnBgwdr8ODBuvPOO5WVlaULL7xQktS9e3ddcskluvbaa9WrVy/l5eXpuuuu0/DhwzVhwoSkPycAAAAAAIC2+OKLL+T3+zVq1ChrW15enoYMGWJdfv/99zV37lytX79e+/bts5qfb9++XUOHDm3xvufMmaPVq1drz549UbdzZFAqFtdff72qqqp0xRVXaP/+/Ro5cqSWL1+unJwca5+HHnpIHo9HF1xwgaqqqjR+/HgtXLiwUed3AAAAAADgPJneNG369aSUPXaszNX3mlNZWamSkhKVlJRo8eLF6tOnj7Zv365Jkya12tB92rRpKioq0tNPP61+/fopFApp2LBhKW8Eb6ug1IoVK6Iuu1wuzZ07V3Pnzm32NhkZGZo/f77mz5+f2MEBAAAAAIBOx+VyxVxCl0pHH320vF6vVq9ebTUq379/vz799FONGTNGn3zyifbs2aO7775bRUVFkqS1a9dG3YfP55MU7qtl2rt3rz7++GM9+eSTGj16tCRp1apVSXhGrbP/XwVAwgVqQ7rrtU80+pjeGjckP9XDAQAAAADHyc7O1kUXXaQbbrhBffr0Ud++fXXLLbdYDccHDBggn8+n+fPn6/LLL9fGjRt1++23R91HcXGxXC6XXn31VU2ZMkWZmZnq2bOnevXqpaeeekqFhYXavn27brzxxkaPv337du3bt0/bt29XbW2t1q9fLykcLMvOzk7Ic265lToAR1izdZ+e+b8teqj001QPBQAAAAAc69e//rVGjx6tc845RxMmTNAZZ5yhk08+WZLUp08fLVy4UC+99JKGDh2qu+++W/fff3/U7Y844gjNmzdPN954o/r27aurrrpKbrdbS5Ys0bp16zRs2DBdc801uu+++xo99q233qqTTjpJt912myoqKnTSSSfppJNOapSN1ZHIlAKgKn84tfOwPzXLpAIAAAAAwtlSzz33nJUdJUm//OUvrZ+nT5+u6dOnR92mYS+qOXPmaM6cOVHbJkyYoE2bNrV4u4ULF2rhwoXtGX7cyJQCoEBtKOp/AAAAAAASjaAUAPlrwxHyQJCgFAAAAAAgOQhKAbCCUWZwCgAAAACARCMoBUDBUCjqfwAAAAAAEo2gFADK9wAAAAAASUdQCoAVjApQvgcAAAAASBKCUgCssj1/bajRsqAAAAAAACQCQSkAURlStSGCUgAAAACAxCMoBUD+er2kKOEDAAAAACQDQSkACtRGglL+WpqdAwAAAIBdjB07VrNmzUr1MBKCoBQABeuV7AUISgEAAABAp7RixQq5XC4dOHAgrttt3bpVl1xyiQYOHKjMzEwNGjRIt912m/x+f2IGWseT0HsH0CnUL98LUr4HAAAAAI7yySefKBQK6cknn9TRRx+tjRs36tJLL1VlZaXuv//+hD0umVIAorKjyJQCAAAAgNSorKzUjBkzlJ2drcLCQj3wwANR1y9evFgjRoxQTk6OCgoKdOGFF6qsrExSONtp3LhxkqSePXvK5XJp5syZkqRly5bpjDPOUI8ePdSrVy9NnTpVX3zxhXW/Z511lp599lmVlJToqKOO0jnnnKPrrrtOf/rTnxL6fAlKAaCnFAAAAICuyzAkf2Vq/hnxVaLceuutWrFihZYuXarly5drxYoVWrdunXW93+/X7bffrg8++ECvvPKKtmzZYgWeioqK9PLLL0uSNm/erJ07d+q3v/2tpHCwa/bs2VqzZo3+/ve/y+1263vf+55Coea//x08eFB5eXlx/rLjQ/kegKiSPTKlAAAAAHQpgcPSnf1S89g375B83WLataKiQosXL9bChQs1ceJESdKiRYvUv39/a5+LL77Y+vmoo47SI488olNPPVUVFRXKzs62gkj5+fnq0aOHte95550X9VgLFixQfn6+Nm3apGHDhjUayxdffKH58+c3ytTqaGRKAYjKjqKnFAAAAAAk3xdffCG/369Ro0ZZ2/Ly8jRkyBDr8vvvv6/vfOc7Ki4uVk5OjsaOHStJ2r59e6v3feGFF+qoo45Sbm6uBg4c2OztduzYobPOOkvf//739bOf/awDnlnzyJQCQPkeAAAAgK7LmxXOWErVY8fIaKXUr7KyUiUlJSopKdHixYvVp08fbd++XZMmTWp1lbxp06apqKhITz/9tPr166dQKKRhw4Y1ut2OHTs0btw4jRo1Sk899VTMY28rglIAosv3ggSlAAAAAHQhLlfMJXSpdPTRR8vr9Wr16tU68sgjJUn79+/Xp59+qjFjxuiTTz7Rnj17dPfdd6uoqEiStHbt2qj78Pl8kqTa2lpr2969e/Xxxx/rySef1OjRoyVJq1atavT4//nPfzRu3DidfPLJevbZZ+V2J764jqAUgKjsqADlewAAAACQdNnZ2brooot0ww03qE+fPurbt69uueUWKzg0YMAA+Xw+zZ8/X5dffrk2btyo22+/Peo+iouL5XK59Oqrr2rKlCnKzMxUz5491atXLz311FMqLCzU9u3bdeONN0bdbseOHRo7dqwGDBig+++/X7t377auKygoSNhzpqcUgKjyvUALqy8AAAAAABLn17/+tUaPHq1zzjlHEyZM0BlnnKGTTz5ZktSnTx8tXLhQL730koYOHaq7775b999/f9TtjzjiCM2bN0833nij+vbtq6uuukput1tLlizRunXrNGzYMF1zzTW67777om63fPlyff7553rzzTfVv39/FRYWWv8SiUwpAFHZUZTvAQAAAEBqZGdn67nnnosqnfvlL39p/Tx9+nRNnz496jYNe1HNmTNHc+bMido2YcIEbdq0qdnbzZw5UzNnzmzv8ONGphQABSnfAwAAAAAkGUEpAPLXz5Ri9T0AAAAAQBIQlAIQ3VOKoBQAAAAAIAkISgGgfA8AAAAAkHQEpQBENzonUwoAAAAAkAQEpQDIT/keAAAAACDJCEoBaNBTivI9AAAAAEDiEZQCoCDlewAAAACAJCMoBYDyPQAAAABA0hGUAhzOMIyoQJSfoBQAAAAA2MbYsWM1a9asVA8jIQhKAQ5XGzJk1GsjFaSnFAAAAAB0SitWrJDL5dKBAwfivu0555yjAQMGKCMjQ4WFhfrxj3+sHTt2dPwg6yEoBThcMBQdhKJ8DwAAAACcZ9y4cfrjH/+ozZs36+WXX9YXX3yh888/P6GPSVAKcLiG5XoEpQAAAAAgNSorKzVjxgxlZ2ersLBQDzzwQNT1ixcv1ogRI5STk6OCggJdeOGFKisrkyRt3bpV48aNkyT17NlTLpdLM2fOlCQtW7ZMZ5xxhnr06KFevXpp6tSp+uKLL6Lu+5prrtFpp52m4uJinX766brxxhu1evVqBQKBhD1fT8LuGUCnEAhGB6H8Qcr3AAAAAHQdhmGoKliVksfO9GTK5XLFvP+tt96qFStWaOnSpSooKNDNN9+sdevW6cQTT5Qk+f1+3X777RoyZIjKysp0zTXXaObMmXrttddUVFSkl19+Weedd542b96s3NxcZWZmSgoHu2bPnq3hw4ersrJSt956q773ve9p/fr1crsb5yvt27dPv//973X66afL6/V2yO+iKQSlAIdrWL4XDJEpBQAAAKDrqApWaeQLI1Py2O9d+J6yvFkx7VtRUaHFixdr4cKFmjhxoiRp0aJF6t+/v7XPxRdfbP181FFH6ZFHHtGpp56qiooKZWdnKy8vT5KUn5+vHj16WPued955UY+1YMEC5efna9OmTRo2bJi1/YYbbtCjjz6qw4cP67TTTtOrr74a93OOB+V7gMP5g5TvAQAAAECqffHFF/L7/Ro1apS1LS8vT0OGDLEuv//++/rOd76j4uJi5eTkaOzYsZKk7du3t3rfF154oY466ijl5uZq4MCBTd7ul7/8pd5//30tX75caWlp+slPfiLDSFw1DZlSgMM1DEJRvgcAAACgK8n0ZOq9C99L2WPHqrXgT2VlpUpKSlRSUqLFixerT58+2r59uyZNmiS/39/ibadNm6aioiI9/fTT6tevn0KhkIYNG9bodr1791bv3r11zDHH6Bvf+IaKioq0evXqqEBZRyIoBThcoJbyPQAAAABdl8vlirmELpWOPvpoeb1erV69WkceeaQkaf/+/fr00081ZswYffLJJ9qzZ4/uvvtuFRUVSZLWrl0bdR8+n0+SVFtba23bu3evPv74Yz355JMaPXq0JGnVqlWtjscMktXU1LT7uTWHoBTgcA0zpSjfAwAAAIDky87O1kUXXaQbbrhBffr0Ud++fXXLLbdYjcgHDBggn8+n+fPn6/LLL9fGjRt1++23R91HcXGxXC6XXn31VU2ZMkWZmZnq2bOnevXqpaeeekqFhYXavn27brzxxqjb/fOf/9Q///lPnXHGGerZs6f+/e9/69Zbb9WgQYMSliUl0VMKcLxGQSnK9wAAAAAgJX79619r9OjROuecczRhwgSdccYZOvnkkyVJffr00cKFC/XSSy9p6NChuvvuu3X//fdH3f6II47QvHnzdOONN6pv37666qqr5Ha7tWTJEq1bt07Dhg3TNddco/vuuy/qdpmZmfrTn/6k8ePHa8iQIbr44os1bNgwrVy5Uunp6Ql7vmRKAQ7XsHzPT6YUAAAAAKREdna2nnvuOSs7Sgo3HzdNnz5d06dPj7pNw15Uc+bM0Zw5c6K2TZgwQZs2bWr2dsOHD9ebb77Z7vHHi0wpwOEaZkrRUwoAAAAAkAwEpQCHo3wPAAAAAJAKKQ1KPfHEEzr++OOVm5ur3NxcjRo1Sn/729+s62fOnCmXyxX177TTTou6j5qaGl199dXq3bu3unXrpnPOOUdfffVVsp8K0Gk1LN+j0TkAAAAAIBlSGpTq37+/7r77bq1du1Zr167Vt7/9bX3nO9/RRx99ZO1z1llnaefOnda/1157Leo+Zs2apaVLl2rJkiVatWqVKioqNHXq1KjlDwE0zwxC+dLCbwf0lAIAAAAAJENKG51PmzYt6vIdd9yhJ554QqtXr9Zxxx0nSUpPT1dBQUGTtz948KAWLFig559/XhMmTJAkLV68WEVFRXrjjTc0adKkxD4BoAswg1JZ6WnyHw4pWEv5HgAAAAAg8WzTU6q2tlZLlixRZWWlRo0aZW1fsWKF8vPzdcwxx+jSSy9VWVmZdd26desUCARUUlJibevXr5+GDRumd955J6njBzors3yvm89Td5lMKQAAAABA4qU0U0qSNmzYoFGjRqm6ulrZ2dlaunSphg4dKkmaPHmyvv/976u4uFhbtmzRnDlz9O1vf1vr1q1Tenq6du3aJZ/Pp549e0bdZ9++fbVr165mH7OmpkY1NTXW5fLycklSIBBQIBBIwLNsH3NMdhwbOr9qf/h1leGNlO919tcaxwwQH44ZIHYcL0B8OGaQCoFAQIZhKBQKKdSJVhc3DMP6vzOMOxQKyTAMBQIBpaWlRV0X6zGf8qDUkCFDtH79eh04cEAvv/yyZsyYoZUrV2ro0KH6wQ9+YO03bNgwjRgxQsXFxfrrX/+qc889t9n7NAxDLper2evvuusuzZs3r9H25cuXKysrq31PKIFKS0tTPQR0Qet3uSSlyX+4QpJL1f5Ao95tnRXHDBAfjhkgdhwvQHw4ZpBMHo9HBQUFqqiokN/vT/Vw4nbo0KFUDyEmfr9fVVVVeuuttxQMBqOuO3z4cEz3kfKglM/n09FHHy1JGjFihNasWaPf/va3evLJJxvtW1hYqOLiYn322WeSpIKCAvn9fu3fvz8qW6qsrEynn356s4950003afbs2dbl8vJyFRUVqaSkRLm5uR311DpMIBBQaWmpJk6cKK/Xm+rhoIv5+p1t0pbN6pefpy+37Jcht6ZM6dz92DhmgPhwzACx43gB4sMxg1Sorq7Wl19+qezsbGVkZKR6ODEzDEOHDh1STk5Oi4k2dlFdXa3MzEydeeaZjX7PZkVaa1IelGrIMIyo0rr69u7dqy+//FKFhYWSpJNPPller1elpaW64IILJEk7d+7Uxo0bde+99zb7GOnp6UpPT2+03ev12vqN0u7jQ+cUUvjNrlt6+LUVDBlKS/PI7bb/m2BrOGaA+HDMALHjeAHiwzGDZKqtrZXL5ZLb7ZbbbZtW2q0yS/bMsZvGjh2rE088UQ8//HCKRtY0t9stl8vV5PEd6/Ge0r/OzTffrLfffltbt27Vhg0bdMstt2jFihX60Y9+pIqKCl133XV69913tXXrVq1YsULTpk1T79699b3vfU+S1L17d11yySW69tpr9fe//13vv/++LrroIg0fPtxajQ9AywLB8Btfpi9SAxzoBPXLAAAAAIBoK1askMvl0oEDB9p8HzU1NTrxxBPlcrm0fv36DhtbU1KaKfX111/rxz/+sXbu3Knu3bvr+OOP17JlyzRx4kRVVVVpw4YNeu6553TgwAEVFhZq3LhxevHFF5WTk2Pdx0MPPSSPx6MLLrhAVVVVGj9+vBYuXNioyRaAppmr7XWrH5SqNZRuuzxKAAAAAECiXX/99erXr58++OCDhD9WSjOlFixYoK1bt6qmpkZlZWV64403NHHiRElSZmamXn/9dZWVlcnv92vbtm1auHChioqKou4jIyND8+fP1969e3X48GH97//+b6N9ADQvEAqv8JDli0ShgrVkSgEAAABAslVWVmrGjBnKzs5WYWGhHnjggajrFy9erBEjRignJ0cFBQW68MILVVZWJknaunWrxo0bJ0nq2bOnXC6XZs6cKUlatmyZzjjjDPXo0UO9evXS1KlT9cUXXzR6/L/97W9avny57r///sQ+0Tqdp7gSQEKY5XvpXrfMNlJ+glIAAAAAugjDMBQ6fDgl/wzDiGust956q1asWKGlS5dq+fLlWrFihdatW2dd7/f7dfvtt+uDDz7QK6+8oi1btliBp6KiIr388suSpM2bN2vnzp367W9/Kykc7Jo9e7bWrFmjv//973K73fre975n9bGSwtVsl156qZ5//nllZWW187ceGwp0AIczy/d8aW550tzyB0MK1Mb3xgkAAAAAdmVUVWnzN09OyWMP+dc6uWIM8FRUVGjx4sVauHChVUW2aNEi9e/f39rn4osvtn4+6qij9Mgjj+jUU09VRUWFsrOzlZeXJ0nKz89Xjx49rH3PO++8qMdasGCB8vPztWnTJg0bNkyGYWjmzJm6/PLLNWLECG3durWNzzg+ZEoBDmeW73nT3PKlhd8SzOwpAAAAAEByfPHFF/L7/Ro1apS1LS8vT0OGDLEuv//++/rOd76j4uJi5eTkaOzYsZKk7du3t3rfF154oY466ijl5uZq4MCBUbebP3++ysvLddNNN3Xws2oZmVKAw5kBKG+aW960cP1ekNX3AAAAAHQRrsxMDfnXutZ3TNBjx6q1Ur/KykqVlJSopKREixcvVp8+fbR9+3ZNmjRJfr+/xdtOmzZNRUVFevrpp9WvXz+FQiENGzbMut2bb76p1atXKz09Pep2I0aM0I9+9CMtWrQo5ucRD4JSgMOZ5XveNJe8dZlS/iDlewAAAAC6BpfLFXMJXSodffTR8nq9Wr16tY488khJ0v79+/Xpp59qzJgx+uSTT7Rnzx7dfffd1gJva9eujboPn88nSaqtrbW27d27Vx9//LGefPJJjR49WpK0atWqqNs98sgj+s1vfmNd3rFjhyZNmqQXX3xRI0eO7PDnaiIoBTic2T8qnClVV75Ho3MAAAAASKrs7GxddNFFuuGGG9SnTx/17dtXt9xyi9zu8Pe0AQMGyOfzaf78+br88su1ceNG3X777VH3UVxcLJfLpVdffVVTpkxRZmamevbsqV69eumpp55SYWGhtm/frhtvvDHqdgMGDGg0FkkaNGhQVE+rjkZPKcDhIplSkfI9glIAAAAAkHy//vWvNXr0aJ1zzjmaMGGCzjjjDJ18crhJe58+fbRw4UK99NJLGjp0qO6++27df//9Ubc/4ogjNG/ePN14443q27evrrrqKrndbi1ZskTr1q3TsGHDdM011+i+++5LxdNrhEwpwOHMAJSnXvkeq+8BAAAAQPJlZ2frueees7KjJOmXv/yl9fP06dM1ffr0qNs07EU1Z84czZkzJ2rbhAkTtGnTphZvV9+RRx7Zao+rjkCmFOBwZgDKR/keAAAAACCJCEoBDuenfA8AAAAAkAIEpQCHCzax+h5BKQAAAABAohGUAhyu6dX36CkFAAAAAEgsglKAw0WtvuchUwoAAABA15CMRt1O1hG/X4JSgMMF6pfvuekpBQAAAKBzS0tLkyT5/f4Uj6RrO3z4sCTJ6/W2+T48HTUYAJ2TVb7niZTv+SnfAwAAANBJeTweZWVlaffu3fJ6vXK7O0c+TigUkt/vV3V1ta3HbBiGDh8+rLKyMvXo0cMKArYFQSnA4axMKXekfC9IphQAAACATsrlcqmwsFBbtmzRtm3bUj2cmBmGoaqqKmVmZsrlcqV6OK3q0aOHCgoK2nUfBKUAh7OCUh6XvGmU7wEAAADo/Hw+nwYPHtypSvgCgYDeeustnXnmme0qiUsGr9fbrgwpE0EpwOGiVt9zs/oeAAAAgK7B7XYrIyMj1cOIWVpamoLBoDIyMmwflOoo9i1SBJAU0eV74Uwpf5BMKQAAAABAYhGUAhwuunyvrqdUiKAUAAAAACCxCEoBDmYYRlT5ni+N8j0AAAAAQHIQlAIcLBiKBJ+8aW550ijfAwAAAAAkB0EpwMHqr7LnTYuU77H6HgAAAAAg0QhKAQ4WCEZnSlk9pSjfAwAAAAAkGEEpwMEC9Rqae9yuej2lyJQCAAAAACQWQSnAwayV99JccrlckZ5SBKUAAAAAAAlGUApwMLN8zyzbo6cUAAAAACBZCEoBDua3MqXCbwU+ekoBAAAAAJKEoBTgYMFQdFDK66F8DwAAAACQHASlAAeLlO+Fg1EeN+V7AAAAAIDkICgFOFjD8r1ITynK9wAAAAAAiUVQCnCw+qvvSZKvrnwvSKYUAAAAACDBCEoBDmY2NG+YKeUnUwoAAAAAkGAEpQAHCzQo36OnFAAAAAAgWQhKAQ7mb6Z8j6AUAAAAACDRCEoBDtZc+V6Q8j0AAAAAQIIRlAIcrGH5XqSnFJlSAAAAAIDEIigFOFjD8j3zf8r3AAAAAACJRlAKcLDmMqUCQYJSAAAAAIDEIigFOJjVU8rTICgVoqcUAAAAACCxCEoBDmZlSrnN8j23td0wCEwBAAAAABKHoBTgYP5G5Xvh4JRhSLVkSwEAAAAAEoigFOBgzZXvSVKglqAUAAAAACBxCEoBDmaW7/nSmghKhWh2DgAAAABIHIJSgIOZ5Xseq6eUy7qOFfgAAAAAAIlEUApwsEAwunzP5XJZASrK9wAAAAAAiURQCnCwYCi60Xn9n83SPgAAAAAAEoGgFOBgZuDJ646U7ZklfASlAAAAAACJlNKg1BNPPKHjjz9eubm5ys3N1ahRo/S3v/3Nut4wDM2dO1f9+vVTZmamxo4dq48++ijqPmpqanT11Verd+/e6tatm8455xx99dVXyX4qQKfkb1C+J0k+j5kpRfkeAAAAACBxUhqU6t+/v+6++26tXbtWa9eu1be//W195zvfsQJP9957rx588EE9+uijWrNmjQoKCjRx4kQdOnTIuo9Zs2Zp6dKlWrJkiVatWqWKigpNnTpVtbW1qXpaQKdhZUrVK9/zuCnfAwAAAAAkXkqDUtOmTdOUKVN0zDHH6JhjjtEdd9yh7OxsrV69WoZh6OGHH9Ytt9yic889V8OGDdOiRYt0+PBhvfDCC5KkgwcPasGCBXrggQc0YcIEnXTSSVq8eLE2bNigN954I5VPDegUzJ5Svnqr7nk94Z/9BKUAAAAAAAlkm55StbW1WrJkiSorKzVq1Cht2bJFu3btUklJibVPenq6xowZo3feeUeStG7dOgUCgah9+vXrp2HDhln7AGieWb7naaLReZDyPQAAAABAAnlSPYANGzZo1KhRqq6uVnZ2tpYuXaqhQ4daQaW+fftG7d+3b19t27ZNkrRr1y75fD717Nmz0T67du1q9jFrampUU1NjXS4vL5ckBQIBBQKBDnleHckckx3Hhs7NHwxKktwKWa8vs+l5VY2/077mOGaA+HDMALHjeAHiwzEDxK4rHS+xPoeUB6WGDBmi9evX68CBA3r55Zc1Y8YMrVy50rre5XJF7W8YRqNtDbW2z1133aV58+Y12r58+XJlZWXF+QySp7S0NNVDQBezq8wtya2PNnyojJ0fSJIqK9IkufTO6n/qwObOnS3FMQPEh2MGiB3HCxAfjhkgdl3heDl8+HBM+6U8KOXz+XT00UdLkkaMGKE1a9bot7/9rW644QZJ4WyowsJCa/+ysjIre6qgoEB+v1/79++PypYqKyvT6aef3uxj3nTTTZo9e7Z1uby8XEVFRSopKVFubm6HPr+OEAgEVFpaqokTJ8rr9aZ6OOhCnt/xT+ngAZ1y8jd11nHh4+rZr97TV5UHdeI3T9aEb+SneIRtwzEDxIdjBogdxwsQH44ZIHZd6XgxK9Jak/KgVEOGYaimpkYDBw5UQUGBSktLddJJJ0mS/H6/Vq5cqXvuuUeSdPLJJ8vr9aq0tFQXXHCBJGnnzp3auHGj7r333mYfIz09Xenp6Y22e71eW//h7T4+dD7Bul7mGb7Ia8vnSZMkGS53p3+9ccwA8eGYAWLH8QLEh2MGiF1XOF5iHX9Kg1I333yzJk+erKKiIh06dEhLlizRihUrtGzZMrlcLs2aNUt33nmnBg8erMGDB+vOO+9UVlaWLrzwQklS9+7ddckll+jaa69Vr169lJeXp+uuu07Dhw/XhAkTUvnUgE4hULfCnrf+6nt1PwdYfQ8AAAAAkEApDUp9/fXX+vGPf6ydO3eqe/fuOv7447Vs2TJNnDhRknT99derqqpKV1xxhfbv36+RI0dq+fLlysnJse7joYceksfj0QUXXKCqqiqNHz9eCxcuVFpaWqqeFtBpmCvs+ZpYfc8fJCgFAAAAAEiclAalFixY0OL1LpdLc+fO1dy5c5vdJyMjQ/Pnz9f8+fM7eHRA12dmQ3maCEoFajt3k3MAAAAAgL25W98FQFflb6J8z8yaCobIlAIAAAAAJA5BKcDBIj2lIm8FnroAFeV7AAAAAIBEIigFOJjVU8pD+R4AAAAAILkISgEOZpbvedz1V9+rK99j9T0AAAAAQAIRlAIcrKnyPV9d+V6AoBQAAAAAIIEISgEO1lT5nrkSn5/yPQAAAABAAhGUAhwqFDIUDIUDT02V75EpBQAAAABIJIJSgEMFQpGgk9fTuHyPnlIAAAAAgEQiKAU4VP3V9XxpjVffo3wPAAAAAJBIBKUAh6qfCVW/0bmH8j0AAAAAQBIQlAIcyl8XdHK5pLSonlKsvgcAAAAASDyCUoBDmeV79bOkpMhKfEHK9wAAAAAACURQCnCoQDCcCeVrEJSK9JQiUwoAAAAAkDgEpQCHCtatvmeW65k8bsr3AAAAAACJR1AKcCh/MFye52mmfI+gFAAAAAAgkQhKAQ5lBp2aK98L0FMKAAAAAJBABKUAh2qufC8SlCJTCgAAAACQOASlAIdqrnzPk0ZPKQAAAABA4hGUAhzKDDp5G/aUMjOlgpTvAQAAAAASh6AU4FCRnlLNlO+FyJQCAAAAACQOQSnAocxG5g0zpbyU7wEAAABIgP2Vfn3nsf/Tone2pnoosAmCUoBDmUEnT3OZUpTvAQAAAOhA/9y6Tx98eUAvrfsy1UOBTRCUAhyquZ5SrL4HAAAAIBFqguHvGDUBvmsgjKAU4FCRnlKU7wEAAABIvJpAbfj/IN81EEZQCnCo5ntKuaOuBwAAAICOYGVKBWtTPBLYBUEpwKFa7SlFphQAAACADhQJSvFdA2EEpQCHaq18LxgyZBhkSwEAAADoGGaGFD2lYCIoBThUs+V7HnejfQAAAACgvarrglHVwVomwCGJoBTgWM2V79XPnKKED0BnUuWv1f2vb9bG/xxM9VAAAEATzEwpw2ACHGEEpQCHMgNODTOlPG5Xo30AoDN485MyPfqPz/Vg6aepHgoAAGhC/bI9mp1DIigFOJY5M+HzRL8NpLldctXFpfwEpQB0IuXVAUnSobr/AQCAvdRvcE6zc0gEpQDHimRKRZfvuVwuK3sqSEotgE6kOlBb9z8fcgEAsKP62VEEpSARlAIcy+op5W78NmD2laJ8D0BnEllmmnIAAADsKCpTKsD5GgSlAMcKBJsu35Mizc8JSgHoTMiUAgDA3qJ7SnG+BkEpwLGaK98Lbwu/NfiDlO8B6DzMYBSZUgAA2BPle2iIoBTgUIFQOODUcPU9KVK+FwxxogDQeZgfdMmUAgDAnqIypSjfgwhKAY4VqJuZ8DQRlPJSvgegEyJTCgAAe6t/jq4mUwoiKAU4lhlw8jVRvuehfA9AJ2R+0K0JhmQYvH8BAGA3NDpHQwSlAIdqqXzPy+p7ADohsyTAMCQ/718AANhOVFCKTCmIoBTgWC2V75nZU/SUAtCZ0DwVAAB7q58dxbkaEkEpwLFaKt9j9T0AnVH9BufVlAQAAGA70ZlSnKtBUApwLDMo1VT5nodG5wA6oahMKVbgAwDAdqJ7SnGuBkEpwLECtfSUAtC11M+UYvYVAAD7odQeDRGUAhzKDDh5mijf89UFpYK1lO8B6Dzql+xVM/sKAICt1IYMa2JcYgIJYQSlAIeK9JRqPlOK1asAdCb0qQAAwL4anpuZQIJEUApwrJbK9+gpBaAzqp8pRZ8KAADspeG5mQkkSASlAMdqqdG5j55SADqh+plS1XzQBQDAVhr2kKKnFCSCUoBjRYJSjXtKRRqd01MKQOdBphQAAPbVMDOKczWkFAel7rrrLp1yyinKyclRfn6+vvvd72rz5s1R+8ycOVMulyvq32mnnRa1T01Nja6++mr17t1b3bp10znnnKOvvvoqmU8F6HRaXH3PQ/kegM7FMAwypQAAsLHGmVKcq5HioNTKlSt15ZVXavXq1SotLVUwGFRJSYkqKyuj9jvrrLO0c+dO699rr70Wdf2sWbO0dOlSLVmyRKtWrVJFRYWmTp2q2lpe5EBzrEwpTxM9pdyU7wHoXBp90GX2FQAAW2ncU4pzNSRPKh982bJlUZefffZZ5efna926dTrzzDOt7enp6SooKGjyPg4ePKgFCxbo+eef14QJEyRJixcvVlFRkd544w1NmjQpcU8A6MSsoJS7cfmez0P5HoDOhQ+6AADYW6PyPc7VUIqDUg0dPHhQkpSXlxe1fcWKFcrPz1ePHj00ZswY3XHHHcrPz5ckrVu3ToFAQCUlJdb+/fr107Bhw/TOO+80GZSqqalRTU2Ndbm8vFySFAgEFAgEOvx5tZc5JjuODZ1TbchQyIw3GbWNXltpCl9ZEwh2ytcdxwwQn65wzFRU10Rdrqzxd+rnA/vqCscLkEwcMzBVVvujLlf7O+d3jUTqSsdLrM/BZRiGLVIhDMPQd77zHe3fv19vv/22tf3FF19Udna2iouLtWXLFs2ZM0fBYFDr1q1Tenq6XnjhBf30pz+NCjJJUklJiQYOHKgnn3yy0WPNnTtX8+bNa7T9hRdeUFZWVsc/OcBm/LXSL/8Zjknfc2pQGWnR1//tS5eWfZWmb/UN6YKjmMEAYH97qqXb34/MtU0pqtWk/rb4iAMAACRt3O/S059EvngUZxuaPZyWO13V4cOHdeGFF+rgwYPKzc1tdj/bZEpdddVV+vDDD7Vq1aqo7T/4wQ+sn4cNG6YRI0aouLhYf/3rX3Xuuec2e3+GYcjlalyWJEk33XSTZs+ebV0uLy9XUVGRSkpKWvxlpUogEFBpaakmTpwor9eb6uGgCzhUHZT++aYk6ezJZym9QV+pbSv/rWVffa5+/Ys0ZcpxqRhiu3DMAPHpCsfMZ2UV0vvvWJcHDDxaUyYOTuGI0FV1heMFSCaOGZhcG3dJn3xoXc7slqMpU05P4YjspysdL2ZFWmtsEZS6+uqr9Ze//EVvvfWW+vfv3+K+hYWFKi4u1meffSZJKigokN/v1/79+9WzZ09rv7KyMp1+etMv8PT0dKWnpzfa7vV6bf2Ht/v40In4I9kDWek+uRv0lcrwhd8aakPq1K85jhkgPp35mKk1ooPrgU7+/gX768zHC5AKHDOoVfg7R7rHrZpgSP5ag9dEM7rC8RLr+FO6+p5hGLrqqqv0pz/9SW+++aYGDhzY6m327t2rL7/8UoWFhZKkk08+WV6vV6WlpdY+O3fu1MaNG5sNSgFOZzY5T3O7GgWkJMmbVtfoPETpC4DOoWHz1OoA5QAAANiJuShJbmY4WEGjc0gpzpS68sor9cILL+jPf/6zcnJytGvXLklS9+7dlZmZqYqKCs2dO1fnnXeeCgsLtXXrVt18883q3bu3vve971n7XnLJJbr22mvVq1cv5eXl6brrrtPw4cOt1fgARLNW3ktrusTVCkpxogDQSVSz+h4AALZmnptzMzzafaim0YQSnCmlQaknnnhCkjR27Nio7c8++6xmzpyptLQ0bdiwQc8995wOHDigwsJCjRs3Ti+++KJycnKs/R966CF5PB5dcMEFqqqq0vjx47Vw4UKlpTXo3gxAkhSoDWdAed1NJ0uawSozeAUAdkemFAAA9maeq61MqQDfNZDioFRrC/9lZmbq9ddfb/V+MjIyNH/+fM2fP7+jhgZ0aVamlKe5oFR4u5+gFIBOgkwpAADszSrfy6B8DxEp7SkFIDX8wdjK94K19JQC0Dk0zIwiUwoAAHuxyvfqMqX8tSGF6GHreASlAAcK1r35m8GnhqyeUmRKAegkGs62MvsKAIC9mBNGuRmRgi0qM0BQCnCgSKNzekoB6BrMD7pZvnA/yRoypQAAsBVzwqh7XaaURF8pEJQCHCkQY/men/I9AJ1Eww+6ZEoBAGAvZqPzbukepbnD30OqWYHP8QhKAQ7kbzVTyuwpxZc6AJ2DmSlFUAoAAHsyz83pHrfS6xZcIlMKBKUABzIbmDcXlPJ5KN8D0Lk0bJ5Ko3MAAOzFDECle9MiQSkypRyPoBTgQJGeUk2X73ncZqNzyvcAdA5kSgEAYG9mACqcKVXXA5LzteMRlAIcKNbyPVbDANBZNOwpRaYUAAD2ElW+5yVTCmEEpQAHirV8j55SADqLGjKlAACwtUhQKo2eUrAQlAIcqLXyPTNYRfkegM7CXL3HDErVhgz64gEAYCNmFnO6l/I9RBCUAhwo0Er5nofyPQCdjDnT2iPLG9nGB10AAGyjydX3KN9zPIJSgAP5WynfMzOoyDIA0FmYmVK5GZGgFH2lAACwDzMAleFNs3pKVVO+53gEpQAHCraSKeWr224Y4RIYALA7M1Mqw+uWz5p95YMuAAB2YZ6r0z1uZVjle0wgOR1BKcCBYu0pVX9fALAzM1Mq3ZumDI85+8oHXQAA7CKq0bmXCSSEEZQCHKi18j1PvWAVfaUAdAb1Z1/TvWlR2wAAQOqZWVHhnlKcqxFGUApwoNYanXvd9TKlmL0A0AlU1+tTkWH2qaAkAAAAWzAMI5Ip5aXROSIISgEOZPWU8jRdvud2u+Rxh68L0lMKQCcQlSnF7CsAALYSqDVk1H2tSPek1QtKca52OoJSgAMFzPI9d/NvAWYWlZ8TBYBOwOwfleGNfNAlUwoAAHuof06OKrXnu4bjEZQCHMjfSvmeFOkrRaNzAJ1BdbDeij70lAIAwFbqn5PDWc11mVIsSuJ4BKUAB2qtfE+SfHUBKzOrCgDsyjAMK6uzfqYUfSoAALAH85zs87jlcrko34OFoBTgQPGU75EpBcDu6n+gDTc6J1MKAAA7Mc/VGXXBKPNcXU2mlOMRlAIcKFK+13ymlJlFRVAKgN01WxJAphQAALZgLUhSF4wiUwomglKAAwWCZvleC5lSbsr3AHQOZvPUNLdL3jR3vdlXPugCAGAH5kSRGYyyVsolKOV4BKUABwqG6sr3Wmh0bl4XJFMKgM1Zs6/WB10ypQAAsJOaYINztZdzNcIISgEOFIijfM9PUAqAzZmZUmaGFJlSAADYSyQo1aB8j3O14xGUAhzIXKUqlkwpyvcA2J3ZJJVMKQAA7Mk6V3sp30M0glKAA0UypWLpKcWJAoC9WSv6mM1TyZQCAMBWGpXvMYGEOgSlAAcye0r5WgpKsfoegE6CTCkAAOytxjpXmxNIrL6HMIJSgAOZ5XuelnpKUb4HoJNouMw0PaUAALCXSFZzdPmeObEE5yIoBThQTOV7aZTvAegcrEbnZEoBAGBLDRudZ5AphToEpQAHMsv3Wg5KUb4HoHMgUwoAAHszJ4oipfZ1jc45VzseQSnAgQLW6nuU7wHo/MiUAgDA3iITSI3P1YbB9w0nIygFOJC/NpZMKcr3AHQODTOlIh90ef8CAMAOGpbvmf+HjEgVB5yJoBTgQHH1lOJLHQCba5gpRfkeAAD20qh8z+uudx3naycjKAU4ULAuKOWjpxSALqC6hZIAAACQeta5ui5Dqv73kBpW4HM0glKAA5l9ojyx9JQinRaAzdVYmVLRjc5pngoAgD1YmVJ1E0hut8sKTJEp5WwEpQCHMQxDfsr3AHQhjZqnesmUAgDATszAk1lqL9EDEmEEpQCHqd9IsKXyPR/lewA6iUaZUh56SgEAYCcNFyUJ/xz+LlJN+Z6jEZQCHCZYGwlKeT3Nl+956gJW/lrK9wDYmxl8Msv2yJQCAMBeGjY6D/9cV25PppSjEZQCHMZfL/PJ4269fC9IphQAm2vYp8LMlArUGqqlLx4AAClnBp7MQJRUbxKJTClHiysoNWXKFB08eNC6fMcdd+jAgQPW5b1792ro0KEdNjgAHa9+OZ63xUbnlO8B6BysTClPdKaURLYUAAB2EAlKkSmFaHEFpV5//XXV1NRYl++55x7t27fPuhwMBrV58+aOGx2ADmeW73nTXHK5mg9K+epOGAHK9wDYXMNMqfqzsPSVAgAg9cxsqPoTRzQ6hxRnUMowjBYvA7A/M/OppdK9+tf7yZQCYHNm4MkMRqW5XVa2J5lSAACkXpPlex56QIKeUoDjmEGmlkr36l9PTykAdlfdxOwrK/ABAGAfVqZU/fK9ugVKajhXO1pcQSmXq3G5T0vlPwDsx8yU8nlaPvwp3wPQWZizrxlNNU9l9hUAgJSzMqUo30MDnnh2NgxDM2fOVHp6uiSpurpal19+ubp16yZJUf2mANhTpKdUy0Ep83rK9wDYXVOZUulkSgEAYBtNTiDVBaWqWX3P0eIKSs2YMSPq8kUXXdRon5/85CftGxGAhDKDTJ5Wyvc8blbfA9A5tJgpxQddAABSruGiJJKU4WX1PcQZlHr22Wc79MHvuusu/elPf9Inn3yizMxMnX766brnnns0ZMgQax/DMDRv3jw99dRT2r9/v0aOHKnHHntMxx13nLVPTU2NrrvuOv3hD39QVVWVxo8fr8cff1z9+/fv0PECXUEgaPaUaiVTqm7mIkj5HgCbM2dYM5rIlOKDLgAAqVUbMqyWIDQ6R0NxNzrftm2bnn76aT3++OPatGlTux585cqVuvLKK7V69WqVlpYqGAyqpKRElZWV1j733nuvHnzwQT366KNas2aNCgoKNHHiRB06dMjaZ9asWVq6dKmWLFmiVatWqaKiQlOnTlVtLS9uoCHzhOBrJShlXk+mFAC7i/SpiHzQNQNUlAQAAJBa/noTRFGNzplAguLMlHrrrbc0ZcoUHT58OHxjj0eLFi3S9OnT2/Tgy5Yti7r87LPPKj8/X+vWrdOZZ54pwzD08MMP65ZbbtG5554rSVq0aJH69u2rF154QZdddpkOHjyoBQsW6Pnnn9eECRMkSYsXL1ZRUZHeeOMNTZo0qU1jA7qqQCi28j16SgHoDEIhw/qwm+GheSoAAHZTPxMqevU9s9Sec7WTxZUpNWfOHI0bN05fffWV9u7dq4svvljXX399hw3m4MGDkqS8vDxJ0pYtW7Rr1y6VlJRY+6Snp2vMmDF65513JEnr1q1TIBCI2qdfv34aNmyYtQ+AiFjL98ygFZlSAOysfuA8OlPKbHROphQAAKlkLjqS5nbJk9bUBBLnaieLK1Nqw4YNeuutt9SvXz9J0gMPPKCnn35a+/fvV8+ePds1EMMwNHv2bJ1xxhkaNmyYJGnXrl2SpL59+0bt27dvX23bts3ax+fzNXr8vn37WrdvqKamJmqlwPLycklSIBBQIBBo1/NIBHNMdhwbOp9qf/h15HG7WnxNuY3wySMQDHW61x7HDBCfznzMHDocGXOaUatAoG6F0brFGg7X2PPcjs6rMx8vQCpwzKCiOvzdO93jjnodeOoKN6r8QV4fdbrS8RLrc4grKHXgwAHl5+dbl7t166asrCwdOHCg3UGpq666Sh9++KFWrVrV6DqXK7rMyDCMRtsaammfu+66S/PmzWu0ffny5crKyopj1MlVWlqa6iGgC1i72yUpTQf379Vrr73W7H47DkuSRxVV1S3uZ2ccM0B8OuMxc6BGkjxyy9Dy1yNtAfbtdkty6/0PN6rHng2pGh66sM54vACpxDHjXDvrvle4QsGo7xVf7Ax/L9m6/Su99tr2VA3PlrrC8WK2fWpNXEEpSdq0aVNUBpJhGPr444+jGo8ff/zxcd3n1Vdfrb/85S966623olbMKygokBTOhiosLLS2l5WVWdlTBQUF8vv9jbK1ysrKdPrppzf5eDfddJNmz55tXS4vL1dRUZFKSkqUm5sb19iTIRAIqLS0VBMnTpTX6031cNDJVf3rP9LnH6kwP19Tpnyz2f227KnUPR/8n9xpXk2Z0rl6s3HMAPHpzMfMtn2HpX+tUqbPE/Ve9fbSj7Ruz380aPAQTRlzVApHiK6mMx8vQCpwzGDjf8qlD1YrJytDU6aMsbYfXPOllm79WL3yCzRlyompG6CNdKXjxaxIa03cQanx48fLMKKXiJ86dapcLpeVnRTrqneGYejqq6/W0qVLtWLFCg0cODDq+oEDB6qgoEClpaU66aSTJEl+v18rV67UPffcI0k6+eST5fV6VVpaqgsuuECStHPnTm3cuFH33ntvk4+bnp6u9PT0Rtu9Xq+t//B2Hx86h1BdKzmfN63F11Nmuk9SeLW+zvq645gB4tMZj5laI/yelt7gPS0rPfwRJxBSp3tO6Bw64/ECpBLHjHPVKlzBlNHoXB3+vlHTib9vJEpXOF5iHX9cQaktW7a0aTDNufLKK/XCCy/oz3/+s3JycqwMrO7duyszM1Mul0uzZs3SnXfeqcGDB2vw4MG68847lZWVpQsvvNDa95JLLtG1116rXr16KS8vT9ddd52GDx9urcYHIMJsXO5rpdG52Qg9GKLROQD7Mpuj1l95T2L1PQAA7MI8F6d70qK2Z1ir79Ho3MniCkoVFxe3us/69etj2k+SnnjiCUnS2LFjo7Y/++yzmjlzpiTp+uuvV1VVla644grt379fI0eO1PLly5WTk2Pt/9BDD8nj8eiCCy5QVVWVxo8fr4ULFyotLfpFDyASlPKmtdyXzWutvmfE1McNAFLBXNEnw9vwgy6r7wEAYAfmBFK6t+EEUlrd9UwgOVnc5XtNOXjwoH7/+9/rf/7nf/TBBx/EVb7XGpfLpblz52ru3LnN7pORkaH58+dr/vz5sQ4ZcKxAbfi487SWKVUv6yBQa8jnISgFwH7MD7o+MqUAALClmoCZKcW5Go21/K20FW+++aYuuugiFRYWav78+ZoyZYrWrl3bUWMDkACRTKlWglLu+kEpThQA7IlMKQAA7K3azJRqUL4XCUpxrnayuDOlvvrqKy1cuFDPPPOMKisrdcEFFygQCOjll1/W0KFDEzFGAB0oaPWUiq18L3yb1rMaASAVzKATs68AANhTs5lSdRNI5vVwprgypaZMmaKhQ4dq06ZNmj9/vnbs2EHJHNDJ+GMs30tzu2S2kfKTKQXApsygU8NMKeuDLkEpAABSymp03qinFBNIiDNTavny5frFL36hn//85xo8eHCixgQggWIt33O5XPKmueUPhijfA2BbrWVKUb4HAEBqRVbKpXwPjcWVKfX222/r0KFDGjFihEaOHKlHH31Uu3fvTtTYACRAIMbyPUnyus0V+AhKAbCnZjOlWNEHAABbsMr3GmZKkdUMxRmUGjVqlJ5++mnt3LlTl112mZYsWaIjjjhCoVBIpaWlOnToUKLGCaCDmKvvtZYpJUVW4AvQUwqATTWXKZXhJVMKAAA7sMr3GmRKZdSdu/3BkEIhvm84VZtW38vKytLFF1+sVatWacOGDbr22mt19913Kz8/X+ecc05HjxFABzKznlrrKSVFAldkSgGwKzKlAACwt5pgM6X29c7d9LB1rjYFpeobMmSI7r33Xn311VdasmSJXK7WS4IApE6kp1Trx6qPoBQAm6upy4TK8JIpBQCAHUUypZru/yixAp+TxdXo/OKLL251n169erV5MAASz+op5Wk9Ju1Jo6cUAHtrriSATCkAAOwh0lMq+lztcbvkdkkhw8ym8qZgdEi1uIJSCxcuVHFxsU466SQZRtM1n2RKAfYWV0+pNHpKAbC3ajKlAACwtepmyvdcLpfSPWmqCtQyieRgcQWlLr/8ci1ZskT//ve/dfHFF+uiiy5SXl5eosYGIAGsnlLuGFbfo3wPgM1FGp03yJRiRR8AAGzBypRqolIj3euuC0oxieRUcfWUevzxx7Vz507dcMMN+t///V8VFRXpggsu0Ouvv95s5hQAe4mnfM9L+R4Am4s0Om+QKcWKPgAA2EKk0Xlao+vMQFU1PaUcK+5G5+np6Zo+fbpKS0u1adMmHXfccbriiitUXFysioqKRIwRQAdqS/meP8gXOgD21FqmlMSKPgAApJLV/9HbRKYUPSAdr12r77lcLrlcLhmGoVCIFxHQGcRXvhfeJ8jxDcCmmvugm1EvG5S+UgAApE5zi5KEt4XP1zWcqx0r7qBUTU2N/vCHP2jixIkaMmSINmzYoEcffVTbt29XdnZ2IsYIoAOZQSlvTOV79JQCYG/NZUp50txKqwu+M/sKAEDqWOV7TWRKZdAD0vHianR+xRVXaMmSJRowYIB++tOfasmSJerVq1eixgYgAQJ1pXi+eFbfo3wPgE0111NKCmdLVfprrQarAAAg+VpsdG5mStHo3LHiCkr97ne/04ABAzRw4ECtXLlSK1eubHK/P/3pTx0yOAAdL1BXihdbT6lwlgH9WADYlZkpleFtoiTAm6ZKf621FDUAAEi+Fsv3vO6ofeA8cQWlfvKTn8jlar0PDQD7snpKpcXSUyp8kggSlAJgU5EPuk1nSkkiUwoAgBSKlNq30Oicc7VjxRWUWrhwYYKGASBZ4inf81k9pSjfA2BP5hLSzWVKSSJTCgCAFGqp1J7yPbRr9T0AnY/V6DyGoJSH8j0ANlfT4uwrmVIAAKSa1ei8pdX3KN9zLIJSgMNEglKxl++x+h4Au4rMvraQKcUy0wAApIRhGJFS+yYzpVh9z+kISgEOY5bixdbo3OwpRfkeAPupDRlWJmfLK/rwQRcAgFQI1Boy6r5KtNjonAkkxyIoBThMPOV7Pg+ZUgDsy18v2NRUplQGmVIAAKRU/V5RLU0gVTOB5FgEpQAHMQxDwZCZKdV6+Z7HTU8pAPZVP9hEphQAAPZT/xzc5Eq5XnP1PSaQnIqgFOAg9VfR88RRvkemFAA7Mj/oetyuJt/TyJQCACC1zHO1z+OWy9V4UpwJJBCUAhykfnDJF0f5Hj2lANiRGWxqqnRP4oMuAACpVt3CKrnh7TQ6dzqCUoCD1A9Kxbb6HuV7AOzLWs2nmQ+6GXXNU8mUAgAgNWoC5rm6mQkks9F5kHO1UxGUAhzELN9zuaQ0dyw9pczyPTKlANhP65lSzL4CAJBKZrCp+Uwpc/U9ztVORVAKcBBr5T130zXdDXnN1ff4QgfAhlorCSBTCgCA1DInhsxzckNMIIGgFOAgVlAqhtI9SfLV7RcMcZIAYD9W+R6ZUgAA2FKk1L61/o9MIDkVQSnAQaygVDNZBQ2Zq+/5Kd8DYEOxZkrxQRcAgNSoMc/VzWVKWVnNTCA5FUEpwEHM3lBmr6jWmEusU74HwI5iLgnggy4AACnR6qIkVlYzE0hORVAKcBAzU8oXZ/legNX3ANhQJFOq6ZIAMqUAAEitVsv3rHM13zeciqAU4CBtLd8LhCjfA2A/sWZKURIAAEBqtFZqT1YzCEoBDmKW75nBptZ4Kd8DYGPmB92MZhudkykFAEAqtb4oCedqpyMoBTiImSnlccdWvuehfA+AjbXap8JLphQAAKlkBptazZRiEtyxCEoBDmL1lIqxfM9nZkoRlAJgQzVkSgEAYGtmWV6zpfb0lHI8glKAg/iDbSzfq6WnFAD7qW4lUyqdTCkAAFKq1Ubndefw2pChIBPhjkRQCnCQYKiu0XmMq+95yZQCYGNkSgEAYG+xlu+F9+U7hxMRlAIcxFp9L+ZMKXpKAbAvMwOKnlIAANhTrJlSUmQBEzgLQSnAQQKU7wHoQszZVzKlAACwJ7OnVHozPaXcbpfVx5ZMKWciKAU4iL82zvI9D+V7AOwrnkwpwyC4DgBAslW3Ur5X/zqCUs5EUApwELN5oIfyPQBdgNWnorlMqXqzsn7exwAASDorU6qZ8j2p/gp8ZDY7EUEpwEHMMjxfrEEpd3i/kBFeEQMA7KTaWma66Q+6GTRPBQAgpVprdB6+Lny+rqEHpCMRlAIcpK3lexLZUgDsp7WSAG+aS666tzuapwIAkHxWo/NmekpJlO85HUEpwEGCtfE2Oo8ErwhKAbCbmlYypVwul5UtxewrAADJZwaaMloo3/OxMImjEZQCHCRgZUrFV74Xvi3lewDsJabmqfSpAAAgZWoCZv/Hls7VTCA5GUEpwEECcZbvud0upblpdg7AnlrLlJIiM7PVfNAFACDp/MEYGp3XTS5VM4HkSCkNSr311luaNm2a+vXrJ5fLpVdeeSXq+pkzZ8rlckX9O+2006L2qamp0dVXX63evXurW7duOuecc/TVV18l8VkAnYc/zkyp8L4EpQDYU0zNU8mUAgAgZayeUi02Oq87VzOB5EgpDUpVVlbqhBNO0KOPPtrsPmeddZZ27txp/Xvttdeirp81a5aWLl2qJUuWaNWqVaqoqNDUqVNVW8uHT6CheHtK1d+X8j0AdhNLphQfdAEASB1rAqmF8j3zPE6jc2fypPLBJ0+erMmTJ7e4T3p6ugoKCpq87uDBg1qwYIGef/55TZgwQZK0ePFiFRUV6Y033tCkSZM6fMxAZxZv+Z4k+aygFCcJAPYSS08p84MuJQEAACSfWT4fS/keWc3OlNKgVCxWrFih/Px89ejRQ2PGjNEdd9yh/Px8SdK6desUCARUUlJi7d+vXz8NGzZM77zzTrNBqZqaGtXU1FiXy8vLJUmBQECBQCCBz6ZtzDHZcWzoXGoCQUmS22XE/Hry1PWUOlzt7zSvQY4ZID6d8ZipDRlWBmeaQs2O3VcXhK+stuc5Hp1PZzxegFTimHE2M9DU0rnanDA/XMO5uisdLzF/30zwONpl8uTJ+v73v6/i4mJt2bJFc+bM0be//W2tW7dO6enp2rVrl3w+n3r27Bl1u759+2rXrl3N3u9dd92lefPmNdq+fPlyZWVldfjz6CilpaWpHgI6uW1fuiW59dnmT/Ra+ccx3SbgT5Pk0ltvr9K2nIQOr8NxzADx6UzHTE2tZH6MWfnmG0pvZgL20IHw+957a/+l0DbKkNFxOtPxAtgBx4zzhAwpUBs+V7+94k1le5ve7+sd4XP1xk2f6LVDsX1H6eq6wvFy+PDhmPazdVDqBz/4gfXzsGHDNGLECBUXF+uvf/2rzj333GZvZxiGXK7my5NuuukmzZ4927pcXl6uoqIilZSUKDc3t2MG34ECgYBKS0s1ceJEeb3NHMlADF47uF7aW6YThh2nKSMHxHSbhz9dpX01h3XKaaM0orhn6zewAY4ZID6d8ZjZV+mX/rlCknTO2ZOtlUIb+vO+97X54G5947jhmjKifxJHiK6qMx4vQCpxzDhXlb9WWv13SdLZZ5WoW3rT4Yd/vfaJ3vl6u4qPOlpTJg5O5hBtpysdL2ZFWmtsHZRqqLCwUMXFxfrss88kSQUFBfL7/dq/f39UtlRZWZlOP/30Zu8nPT1d6enpjbZ7vV5b/+HtPj7Yn9mrPMMX+2vJV1f/bcjd6V5/HDNAfDrTMRNyhcuRvWkuZaT7mt0vs+4DcCCkTvPc0Dl0puMFsAOOGeepDEQylLMz0+VpZrGlTF/4dcG5OqIrHC+xjj+lq+/Fa+/evfryyy9VWFgoSTr55JPl9XqjUtt27typjRs3thiUApzK34bV9zx1Nd5+Gp0DsJFYGqeGrzebp/IeBgBAMpnn3jS3q9mAlESjc6dLaaZURUWFPv/8c+vyli1btH79euXl5SkvL09z587Veeedp8LCQm3dulU333yzevfure9973uSpO7du+uSSy7Rtddeq169eikvL0/XXXedhg8fbq3GByAiaK6+18JKVQ2ZAaxgLb1YANiH+cE1o4UlpsPX162+FyAoBQBAMtVYE0gtn6vT687lnKudKaVBqbVr12rcuHHWZbPP04wZM/TEE09ow4YNeu6553TgwAEVFhZq3LhxevHFF5WTE+m2/NBDD8nj8eiCCy5QVVWVxo8fr4ULFyotreWZU8CJAmZQqpneK03x1QWlAmRKAbCR+DOlmH0FACCZzHNva0GpjLpzOVnNzpTSoNTYsWNlGM1nX7z++uut3kdGRobmz5+v+fPnd+TQgC6pLeV7Xg/lewDspyZQ90E3xkwpPugCAJBcMU8g1Z3LzXM7nKVT9ZQC0D6BYPzlex63mSlF+R4A+6gOxpcpVc0HXQAAksrKlGplAimdTClHIygFOEgwVBeUSou9fC/SU4qTBAD7MGdTY+0pxQddAACSqyYYY08pSu0djaAU4CCBNpTv+erK9+gpBcBOzEypDDKlAACwpciiJKyUi+YRlAIcxG+W78XTU6puXz/lewBspDrGnlKUBAAAkBqxr76XFrU/nIWgFOAgbSnfi/SU4iQBwD5qYsyUyvCSKQUAQCrUxNn/kfI9ZyIoBThIe8r36CkFwE5iXX2PTCkAAFLDanQeY0+pajKlHImgFOAgAcr3AHQR8WZKscw0AADJZWVKMYGEFhCUAhzEX9v21fco3wNgJ/SUAgDA3qxzdawTSJTvORJBKcBBgqFwtpMvjkwpT10AK8AXOgA2YmVKtbKiDz2lAABIjbgbnfN9w5EISgEOURsyVFsXlPLE01Oqbl8zoAUAdhCZfSVTCgAAO4o0Oo+tp5Q/GJJh8J3DaQhKAQ5Rv/yuLeV7fsr3ANiIGZQiUwoAAHuyGp23cq6uH7RiEsl5CEoBDhEdlIq/0TnlewDsJPbZVzKlAABIhciiJLGdq+vfBs5BUApwiGC91fPiC0rV9ZQiUwqAjUQancfaPJX3MAAAksnqKdXKudqb5pKrrpCDZufOQ1AKcAgzqOR2SWnuNqy+R08pADYS7+xrbcgguA4AQBJZ5XutnKtdLpe1jxnIgnMQlAIcwuwJFU+WVP39Kd8DYCexZkqle+lTAQBAKsRaah/exyy3J1PKaQhKAQ5hlu/54g5KUb4HwH5iz5SKXE+zcwAAkieyUm7LE0hS/YVJ+M7hNASlAIcwg0qeOFbek+plStVSvgfAPqpj7FMRVRJAphQAAEljZUp548mU4lztNASlAIdod/kemVIAbMRM728tU0qKZEuRKQUAQPLEV75nTiBxrnYaglKAQ5iZTvEHpSjfA2A/sa7oU38fmqcCAJA8kUbnsZyryWp2KoJSgEME64JKvhhmKurzeijfA2A/ZtZTRgwlAVafCmZfAQBImsgEUhzle0wgOQ5BKcAhzPI9jzvOnlJuyvcA2E+k0XkMs6980AUAIOki5XuxnKsp33MqglKAQ1C+B6ArsVb0IVMKAABbipTvxdNTiu8cTkNQCnCIQN0bvJfyPQCdXLA2pGAo/J5EphQAAPZkZTWz+h5aQFAKcIhgqC4oFWf5no/V9wDYTP0PrPFkSlESAABA8lhZzfE0OmelXMchKAU4hL+N5XseyvcA2ExUUIpMKQAAbMcwjHo9pWKYQCJTyrEISgEO0ebyvTTK9wDYiznz6k1zKS2G7E8ypQAASK5ArSGj7usDmVJoCUEpwCHM8j1fGuV7ADq3eFbekyIfhqvJlAIAICnqTwTFUmpPo3PnIigFOIRZvudxtzVTihMEAHuIZ+U9iUwpAACSLbrUnkbnaB5BKcAh2lq+F+kpZcgwKOEDkHrxNE6tvx+ZUgAAJIcZXPJ53HK5Wq/UiGRKMYHkNASlAIcwM528cZbv1W+Mbi7BDgCpFM8S01K9PhV80AUAIClqrAmkOM/VTCA5DkEpwCHMgJIvztX36u9PCR8AOyBTCgAAe4usvBffuZryPechKAU4hL/uDd4Td6ZUZP9AkEwpAKkXb6YUPaUAAEiuSFAqxkypuv2qWX3PcQhKAQ4RKd+L77Cvv9y6n0wpADZAphQAAPYW76IkkVJ7ztVOQ1AKcAgzKBVv+Z7L5bJuEwxxkgCQenH3lKJ5KgAASRVv+V6GVb7HudppCEoBDhGoDZfexVu+J0VK+CjfA2AHNXFmSmV4yZQCACCZ2tzonEwpxyEoBThEW8v3JMlbdzKhfA+AHZApBQCAvcXfU6ouU4oJJMchKAU4RHuCUh63O+o+ACCV4u0pRaYUAADJFZlAirX/IxNITkVQCnCIYF35Xrw9pcK3cUXdBwCkkhlcij9TiqAUAADJYAaX4s6U4lztOASlAIcwS+/a1FOK8j0ANmJ+0I119tXcr4ZlpgEASAqzDC891kwpeko5FkEpwCHa1VMqjfI9APZhZkrFPvvKB10AAJIp/p5SdedqJpAch6AU4BCBdpTvedx1q+8RlAJgA1ZJQLyZUvSpAAAgKarjXX2vrnyvmgkkxyEoBTiElSnlib98z1d3MqGnFAA7aGumFI3OAQBIjkimVKwTSOFzdW3IUJCJcEchKAU4hBmUMlfSi4dZvkdPKQB20OaeUmRKAQCQFJGs5vgypcK35TuHkxCUAhzCLN9rW08pyvcA2EdbM6UCtYZqQ2R8AgCQaPH2lPLV24+glLMQlAIcwgwo+dpQvkejcwB2YvapiDdTSiJbCgCAZDBX34v1XJ3mdlkT4ZyrnYWgFOAQZqZUe8r3AvSUAmADbV3RR6KvFAAAyWCV78V4rg7vW1duz7naUQhKAQ5hNTqnfA9AJxdvppTb7bJWHmX2FQCAxIu30Xl4X/NczXcOJyEoBThEh5TvcYIAYAP+YHwlARIr8AEAkEzxZjXX35cJJGdJaVDqrbfe0rRp09SvXz+5XC698sorUdcbhqG5c+eqX79+yszM1NixY/XRRx9F7VNTU6Orr75avXv3Vrdu3XTOOefoq6++SuKzADqHYLsanVO+B8A+zEypuD7oevmgCwBAsljn6hhX3wvvm1Z3WyaQnCSlQanKykqdcMIJevTRR5u8/t5779WDDz6oRx99VGvWrFFBQYEmTpyoQ4cOWfvMmjVLS5cu1ZIlS7Rq1SpVVFRo6tSpqq3lQydQn78uU6ptPaXqyvdCnCAApF5NmzKl+KALAECytK98j+/yTuJJ5YNPnjxZkydPbvI6wzD08MMP65ZbbtG5554rSVq0aJH69u2rF154QZdddpkOHjyoBQsW6Pnnn9eECRMkSYsXL1ZRUZHeeOMNTZo0KWnPBbC7jinfI1MKQOq1K1MqwAddAAASraZN52oanTtRSoNSLdmyZYt27dqlkpISa1t6errGjBmjd955R5dddpnWrVunQCAQtU+/fv00bNgwvfPOO80GpWpqalRTU2NdLi8vlyQFAgEFAoEEPaO2M8dkx7Gh87D6QRmhuF9LdYlSqrbpMdIQxwwQn852zJizr2mu2N/P0uuC65XV/k7zPGFPne14AVKNY8aZzKBUPOdqX92XjsM1zj1Xd6XjJdbnYNug1K5duyRJffv2jdret29fbdu2zdrH5/OpZ8+ejfYxb9+Uu+66S/PmzWu0ffny5crKymrv0BOmtLQ01UNAJ1YTSJPk0qqVK/RReny3/XKbW5Jbmz/7Qq/5P0vE8BKCYwaIT2c4ZmoNKRgKf3x5+x9vqps3tttVVYTfA995b40OfUbWJ9qvMxwvgJ1wzDjLgUPh8+66f67Wnk2x3ebQ/vB3jn+ue1/Gdmefq7vC8XL48OGY9rNtUMrkckWXGhmG0WhbQ63tc9NNN2n27NnW5fLychUVFamkpES5ubntG3ACBAIBlZaWauLEifJ6Y/z0DdRjGIZmrQ6/sZVMGK8+OfFFpT4u/Uz/2LlFA4qP1JQpxyZiiB2KYwaIT2c6ZipqgtLqNyVJUydPUqYvtl4Vf9i1Rlsr9mvYCSdpyvCCRA4RXVxnOl4AO+CYcaZff7hC8vv17TNHa0hBTky3+cv+9/XJwd069rjhmjKif2IHaFNd6XgxK9JaY9ugVEFB+APjrl27VFhYaG0vKyuzsqcKCgrk9/u1f//+qGypsrIynX766c3ed3p6utLTG38p93q9tv7D2318sK9gbUhG3WRDVoYv7tdRujf8VlFruDrVa5BjBohPZzhmQjWRPhPZmelyu2Prk5fhC7+PBUKy/XNE59AZjhfATjhmnMVfV2rfLTM95r+7ea4Ocq7uEsdLrONP6ep7LRk4cKAKCgqi0tb8fr9WrlxpBZxOPvlkeb3eqH127typjRs3thiUApwmUBtJfzWblsfDV9eg0GyWDgCpUl33IdeX5o45ICVJGXWr/5j9qAAAQOJEVt+Lo9G5tfoe52onSWmmVEVFhT7//HPr8pYtW7R+/Xrl5eVpwIABmjVrlu68804NHjxYgwcP1p133qmsrCxdeOGFkqTu3bvrkksu0bXXXqtevXopLy9P1113nYYPH26txgdACoQib+yetPhX3/PUffHzE5QCkGLWaj7e+ALs5v7VrL4HAEBC1YYM63tDfEEpJpCcKKVBqbVr12rcuHHWZbPP04wZM7Rw4UJdf/31qqqq0hVXXKH9+/dr5MiRWr58uXJyIjWpDz30kDwejy644AJVVVVp/PjxWrhwodLSYusxAThBoN4bu9cdf6aUmV0VrHV2w0EAqVcdMD/kxneeJ1MKAIDk8Nc716Z7Yz9fmwEsJpCcJaVBqbFjx8owmv+S63K5NHfuXM2dO7fZfTIyMjR//nzNnz8/ASMEugazfM/jdsVV7mLyUr4HwCZqguEPqhltzJSq4YMuHOCtT3frYFVA007ol+qhAHAg81wtxZcpleFlAsmJbNvoHEDHMYNJbeknJUm+upI/glIAUi2SKRXf+xkfdOEUoZChny9ep8OBWp12VK+4V9wFgPYyz7VuV6QNSCwiPaWYQHIS2zY6B9BxzGBSW/pJSZKnruTPT/kegBSLZErFV75HSQCc4kBVQJX+WhmGtPNgVaqHA8CBauqV2rtccQSlrKxmJpCchKAU4ABm+Z6vjZlSZvlekEwpAClGphTQst2Hapr8GQCSpc2l9vR/dCSCUoADUL4HoKsgUwpoWf1AVBlBKQApYAaV4l2UhPI9ZyIoBTiAFZTytK18zwxmUb5nY1X7pW3vSC0sHgF0BTVtzJSKfNAluI6urexQtfUzmVIAUsEMKqXHnSnFudqJCEoBDmCW73ndbTvkPXVBqQAnCPt6dbb07GRpy8pUjwRIqOq2ZkrV7U+mFLo6yvcApFpbS+3Nc3XKe0oZhvTlP6WaQ6kdh0MQlAIcoL3le9668r1giKCUbZV9HP7/602pHQeQYOYH1baW7zH7iq6OoBSAVLMypdpYvled6vK9z9+QFkyU/nZjasfhEASlAAfwt7N8z2yQHqB8z74O7Yz+H+iizEyntjY6J1MKXd3uipomfwaAZGl3qX2qM6W+3lj3/4bUjsMhCEoBDhCsCyZ52li+Z/WUIsPAngJVUvWB8M8EpdDFmZlOZEoBTYtudF7dwp4AkBhWo/M4e0pFVspN8QTSoV3h/w/+J7XjcAiCUoADmOV7vjaW73ko37M388QpSeUEpdC1tTdTiqAUurqG5XsGC2AASLL2lu+l/FxdviP8/+E9UoDgfqIRlAIcoL2r71G+Z3P1g1KHdqRuHEASRGZf29ingvI9dHH1S/aqAyFV1ARTOBoAThTJao63fM8mE0h8tk4qglKAA1ir77W50Tmr79la/ZNl+c7wiiFAF0WmFNC8mmCtDhwOSJLS3OGJKJqdA0i2SE+peFfKNXtKpbp8r17lQTlBqUQjKAU4gJkp1eaeUnVf/syG6bCZ+rM5wXr9pYAuqLqdPaXIlEJXtqfCLymc4VzUM1OSVEZQCkCSRcr32tjoPJUTSKFQdFCKvlIJR1AKcACrp1Qby/e8brOnFBk4ttSwuTl9pdCF1ZApBTTLzIrqk5Ou/JyMqG0AkCxWqX3cQanIuTpl/fAO75VC9cqeywlKJRpBKcABzFXz2lu+VxsyVEtgyn7qZ0pJrMCHLq29mVL+YEgh3sfQRZkBqN456eqTkx61DQCSxSq1j/dcXa8HVcoqNBr2kCIolXAEpQAHMDOc2lu+J0WyrmAjBKXgIGamVLzNU+sHsShFRldlZUpl1wtKVRCUApBcbc+UiuxfHUjRubphxQE9pRKOoBTgAGaD8jaX76VFbkdQyobMk2XeUXWXCUqh66oOtrF5atQHXfpKoWuqX75HphSAVIk0Oo8v3OBLc8tV97XD7EuVdObkblr4PZRMqcQjKAU4gBlIanP5Xr0Mq2AtZS+2YhiRTKl+3wz/z9K16MLaminlSXPLU9cfj75S6KrKDlVLig5K0egcQLJFGp3HN4Hkcrkizc5TlSllBqUKTwj/T6PzhCMoBThAoK58r61BKbfbZS0tTaaUzdQckgKV4Z+PqAtKkSmFLqymjZlS4duwAh+6NjKlANhBjdX/Mf7vHvWbnaeEWYHQf0T4/8N7pEB1asbiEASlAAcwy/c8aW0r35MiJXz0YrEZM0sqvbuUN6huG5lS6Lqq25gpJUUarpIpha7K7B+Vn5OuPtkEpQCkRkdMIKWufK/us3X+NyRPZt02PlsnEkEpwAHM7CZfGzOlpEiWVYDyPXsxU4xzC6WcgvDPZEqhC2vPB90MMqXQxdXPlMqvy5TaV1nDyrkAksoq32vTBJIZlEpx+V5OPym3X/hnmp0nFEEpwAH8te0r36t/2yCZUvZinTgLIifOyt1SbSB1YwISiEwpoGmGYUStvtcrO11ulxQypL2VZEsBSJ62NjoP3yYt6j6Srv6Eb/cjwj/TVyqhCEoBDhBsZ6Pz8G0p37MlKyhVKGX1ltxeSYZU8XVKhwUkSoeUBKTqgy6QQIdqgtbx0ScnXWlul/K61TU7LycoBSB5qtvY6Dx8mxSW7wVrpMN7wz/nFEq5dUEpVuBLKIJSgANEVt9rT08pyvdsyax7zymQ3G5K+NClBWpDVhlSezKlKN9DV2RmSeVkeJRR91q3mp1XEJQCkDzty5RKYfmeOdmbli5l9iQolSQEpQAHCHRg+R6r79lM/Uyp+v/TkBFdUP0PqOaX7nhkpPKDLpBgZjaUGYiq/zPNzgEkk5XV3I7V91IygWRO9uYWSi4XPaWShKAU4AD+DizfIyhlM+UNglK5hdHbgS6k/gfUtizcQKYUujIzG8pcdU+S1eycoBSAZKppR/leRiobnZvBJ/Nzdff+4f8PfpX8sTgIQSnAAcyeUh7K97oeq3yPTCl0feYHVJ/HLbc7/vczMqXQlZmBp/zcDGsbmVIAUiHS/7Edjc5TWb5nTfaSKZUMBKUABzADSW3JLDBZQSm+zNmHYUSvvifVC0rtSs2YgAQyM5za8iFXIlMKXVv9lfdM5s8EpQAkk9lTqi2l9mbJX01KyvcaBqXqekod3iMFqpM/HocgKAU4AOV7XdThfVIoEP45u2/4f2Z00IWZwaS2fMiVyJRC12YFpegpBSCFDMOoV77XyRqdm+0vzHYYmT0lT2b4Z6oQEoagFOAAwY5cfS9E+Z5tmLM53fpIHl/4ZytTip5S6HraUw4gRWZfyZRCV2T1lGoqKMXqewCSJBgyZH5daEtPKVuV77lcUndzBT6CUolCUApwgA5dfY8MA/toWLon1cuU2hku7wO6kPZnSqXwgy6QYE1lStHoHECy1Z/4advqe2amlA3K96TIZ+uD/0n+eByCoBTgAIEOKd8zG53zZc42mjpxmj8HKqWa8uSPCUggMqWA5u0+FO53EtVTqi4oVVET1GF/MCXjAuAs9Sd+2rZSrtlTKsnfOQyjcfmeJOXWrcBXTlAqUQhKAQ7g75DyPXpK2Y618l69TClflpTRPfxzOSV8sLdQyFBFTexflGvIlAKaFKwNaW+lX1J0plR2usdaXp1sKQDJYK2Um9a2lXIj5XtJnkCqPiAFq8I/N5UpRVAqYQhKAQ4QNMv32phdINXPlKIkzDaaypSqf5mGjLC5a/64XiffXqov9x2OaX/zg25GG8oBpBSv6AMk0L5KvwxDcrukvG4+a7vL5aLZOYCkqmnvSrmeFGVKmZO9GT0kb2ZkOz2lEo6gFOAAVvmem/K9LsXKlGouKLUrueMB4rTqsz2qCYa0btv+mPavtj7oti1TKqXNU4EEKqsLOPXOTldag8wEs5yPoBSAZLBK7ds4gWRmQyf9XG0GnczMKFNuXVDq4FfJHY+DEJQCHMAKSnnaXr7n81C+ZzvmybNhUMpKM2ZGB/ZVURO0yo22JylTyrxdSpqnAgnU1Mp7pvycjKh9ACCRIv0f2zqBlKJzdXOTvXyuTjiCUoAD+IPtb3Tuqcuy8lO+Zx9N9ZSS6mVK0VMK9rVtb2W9n2MLSnVUplR1sksCgARrauU9E+V7AJLJKt9rb6l9sjOlDjU32VuXKXV4jxSoTu6YHIKgFOAAwVBdT6kOKN8LkillD7VBqbIs/HOjk2fdZRqdw8a21wtEbd9X2cKeEWYwiUwpIJoVlMpuPihVVk5QCkDitT9Tqq58L9kTSE2tvCdJmT0lT12PKfq1JgRBKcABOqJ8z0v5nr1U7paMkORKk7r1jr4upy7NmBMnbGxbvZK9WDOlzGASmVJAtJgypSjfA5AE1R3V6Dxl5XsNKhBcrkiz84OswJcIBKWALs4wDGvFvPaU7/lYfc9erJX3CiR3gy/oZEqhE6gfiCo7VKMqf+sfPs1gUvtLAsiUQtfSUlAqn/I9AEkUyZRqa1AqRY3OrfK9fo2vo69UQhGUAro4s3RP6qieUmQY2EL9oFRDZjlfZVm4zA+woYYle1/ubz1bikwpoGn0lAJgF5HV99p4rk5VT6nmyvckKbd/3T6swJcIBKWALq5+uZ03rf3le/SUsgkrKNXEibNbn3BZnxGK9J0CbMbMlPLULV8fSwkfPaWAppmleeZKe/WZQak9FTUKhch2BpBYkQmk9pXvmWWASdFSr1aJTKkEIygFdHGBYMdkSlG+ZzPN1b1L4XI+czslfLAhfzCkHQeqJEnfHNBTUvRqfM0xZ00zyJQCorSUKdWrW3hbMGRo/2F/UscFwHnMBuVtDUpleFNQvldZVq9Xa5/G1zfXUyoUkl65Qnr7wcSPsQsjKAV0cfXL7cyMhLYwA1qU79lES+V7UmSWh2bnsKH/HKhSyJAyvWn6ZnE4KLV9XyyZUu1bZppMKXRFh/1BVdSES7WbCkr5PG71zPJKotk5gMSzJpDaWr5nNjpPZqZUeQu9WiUpty4oVd4gKLXrA2n976V/3CnVBhI7xi6MoBTQxQVD4RODL80tl6vtQSlPXelfINn13WialSnVRDNGiWbnsDUzK2pAXpaKe2XVbYulp1THZUoZBlmf6Br2HApnP2V609TN1/SxYZb10VcKQKK1v3wvBZlSrU32WkGpBpO9uzeH/w8FpH1bEjM2ByAoBXRxZvmepx39pKRIplSQfhT2UN5aplRdsIpMKdiQmRU1oFeWivPCQakvk5gpJZH1ia6j7FC1pHCWVHOTT5262fmbd0hPfEs6vC/VIwEQg8jqe+3LlAqGjOT1sm2pV6sU6Sl1eI8UqI5sN4NSkrRns9A2BKWALs784tWeflJS/Z5SfJGzhVZPnmRKwb7MrKjivCwNqMuU+nL/YdW2EvQ2U/nbmykl0VcKXUdL/aRMnTYoZRjSmv+Rvt4offFmqkcDIAZWT6k2TiClp2ICyfxcndtMBUJmT8mbVbdvvQnfPZ9Gft5NUKqtbB2Umjt3rlwuV9S/goJIVoBhGJo7d6769eunzMxMjR07Vh999FEKRwzYT6CDglJWTynK91IvWCNV1c0Y01MKnZAVlOqVpcLumfKmuRSoNbTzYFWLt4ssM9229zNvmktmaz36SqGrMPtE9cluPShV1tmCUhVlkfPd13zGBzqD6naW7/nqfWepSdYEUmsVCC5XJGBVv9n57k8iP9cPUCEutg5KSdJxxx2nnTt3Wv82bNhgXXfvvffqwQcf1KOPPqo1a9aooKBAEydO1KFDh1I4YsBegnWr5XnbWb5n9ZQiUyr1zH5SaenhmZumWEGpXckZExCH7fvqekr16qY0t0tFPcOzj9tb6Stllu+1tXmqy+WK9KogUwpdREyZUtmdNFNq98eRn8s+bn4/ALYRWX2vbedqT5rbWpwpaX2lzEnc5nq1So37SgX90X2kyJRqM9sHpTwejwoKCqx/ffqEl2g0DEMPP/ywbrnlFp177rkaNmyYFi1apMOHD+uFF15I8agB++jo8j16StmAlWJcGJ65aYo5m0P5HmzGMAyrp5TZT6qo7v9trfSVivSpaPv7WTor8KGLMQNN+S0EpfJzO2lQqn4gqmxT6sYBIGbtbXRe/7bVyVqBz1pAqJlMKaleUOqr8P/7vpCMeuPb86kUYsKrLWwflPrss8/Ur18/DRw4UD/84Q/173//W5K0ZcsW7dq1SyUlJda+6enpGjNmjN55551UDRewnUj5Xsc0Oqd8zwZa6ydV/zr/IamG7FHYR9mhGlUHQkpzu3REz0xJslbg295KUKq9mVJSpB8VPaXQVcSVKVXR2YJS9QJRB7Yl/Xz2edkh7TjQclkxgGjtLbUP3zbJK/CVt9JTqv51ZqaUmRlVeILk9kqBw5GAFeLiSfUAWjJy5Eg999xzOuaYY/T111/rN7/5jU4//XR99NFH2rUrHM3s27dv1G369u2rbdu2tXi/NTU1qqmJnJTLy8slSYFAQIFAoIOfRfuZY7Lj2GB/1f7w68brdrXrNeRS+MugPxiy/Wuxqx8z7gP/UZqkULd81Tb3HN3p8qTnyFVzSIF9X0q9Byd1jOhcknnMfPF1+Jxb2D1DCtUqEKpV/x7h5eq37q5ocQzmh9M0tf19yOcJB+grq/1d9j0CiWW3c8zX5eGVoHpmeZodU4/M8Be8svJq24w7Fmlfb4qaQQ/u/EjGEScn5bF3H6rRtPmr1CcnXW/MOqPZlQ3ROrsdM0isan9QkuR1tf1vbmZKVVbXKBDI6LCxNclfKW/NQUlSILOP1MyY3dkF4c/fB75UbSAg99ebwpf7DJUrUC3Xns0K7toko1sLk8Yx6ErHS6zPwdZBqcmTJ1s/Dx8+XKNGjdKgQYO0aNEinXbaaZLU6ARhGEarJ4277rpL8+bNa7R9+fLlysrK6oCRJ0ZpaWmqh4BO6KP9Lklpqqw4pNdee63N97PlkCR5dPBQRbvuJ5m66jEz9D/vaLCkLXuqtbGFv8W3XTnK0SH98++vaE/OcckbIDqtZBwz75WF35OyQpXWe0nZvvC2DVt36bXX/tPk7QxDqvKnSXLp/95aoY2+tj1+oCp8H2/937vatZFyZLSdXc4xX+4Jv6Y//WCNqr9oep/KgCR5VF4d1J9ffU3tSGBIHsPQlJ0b5ZZU5e2pzMB+bXjzj9re6+ukPPyH+1yqCqRp+74qvfDK39Sz+UQ0xMguxwwSa2dZ+D1p04YPlL5zfZvuI1gTvo8Vb/+fvsztyNE11q16lyZICrrT9dobbzXbGqPvwR06TVL5V59o5Wuv6eQtK9Vf0sd7QuoZzFU/SR+//Wf9e3PHZKR2hePl8OGWM+BNtg5KNdStWzcNHz5cn332mb773e9Kknbt2qXCwkg0sqysrFH2VEM33XSTZs+ebV0uLy9XUVGRSkpKlJub4Fd9GwQCAZWWlmrixInyer2pHg46Ge+mMumT9eqd10NTpoxs8/1s/E+5Ht64Wr6MTE2ZcmYHjrDjdfVjJu3P/yuVSUceP0oDTpvS/H77/0faukMjvzFAxvHN7wck85jZ/Mbn0hf/1jePGaApU4ZKkgZ/XaH/2fyODtZ6NXlySZOTS/5gSMbqNyRJUyZNVPfMto3zf7av1s7/lOuEb47QuCF92v5E4Fh2OseEQoaufe8NSYa+M+nb4QzEJhiGodvef0OBWkMjzhinI3pkJnegbXHwK3nXV8twe+Q7/lxp3QIdX+DRsInJOZ999vfPpc3htiGFQ0/Rt3m/aDM7HTNIvGe+fE8qP6jTTjlZ47+R36b7ePzf72h3dYW+ecpIfWtQrw4eYTTXtlXSx1Jaj/6acvbZze/4dbH07wfV3VWhKVOmyPP0vZKkId+aJtfO96VVa3RcnzQdO6V971Fd6XgxK9Ja06mCUjU1Nfr44481evRoDRw4UAUFBSotLdVJJ50kSfL7/Vq5cqXuueeeFu8nPT1d6emNpzu8Xq+t//B2Hx/sKVT35c7nSWvX6yczI3zbQK3RaV6HXfaYqQiXL6d176+0lp5f93BDRs/hr6Wu+HtAh0vGMfPVgXCp0cDe2dZjDcwPTwgdqg6qMiD17NZ4DNW1kRTw7Mx0edvYVyrTG/7oU2u4uub7A5LGDueYfZV+awGSgh7d5G2hsXB+Tob+c6BK+6tqdWSfTvDa3/eZJMnVa7DSjjhJWiel7f6k5fNeB/rk6wrr58/KKjVpWAu9ZhATOxwzSDx/3crfWRm+Nv+9zd6RSTlXH94tSXLl9mv5sfIGhPc7vFdewy/t+1yS5CkYKoXC2VHufZ/L3UHj7QrHS6zjt3Xy7nXXXaeVK1dqy5Yteu+993T++eervLxcM2bMkMvl0qxZs3TnnXdq6dKl2rhxo2bOnKmsrCxdeOGFqR46YBvBuhNDe1ffM29vNk5HCsWyQogUaXZu7g/YgLnCntncXJIyfWnWymHNNTuv35i8I1bfq2b1PXQBZpPznlle+Vo5LnrndLIV+Mwm5/nfkPoOrdv2cfP7d7CPdkRm+D/eyYIhQKxqAh2x+l4SG53HsoCQJGX2lLx1n122r5aC1VJautTzSKn3MeHtuz8J9xtAXGydKfXVV19p+vTp2rNnj/r06aPTTjtNq1evVnFxsSTp+uuvV1VVla644grt379fI0eO1PLly5WTk5PikQP24e+o1ffcBKVswwpKtXLybLhKCGAD2/dWSpIG5HWL2l7cK0tlh2q0bd9hnVDUo9HtzCWmfR53uxoOWx90WX0PXYAZYMrPab0RsLkCX1lnCUrt/iT8f/5Qqc+x4Z8ry6TKPVK33gl96L0VNdp5sNq6/PHO2EpQANRffa/tK+WaE0g1yZhAslbea+VztcsV/my993PpizfD23oPltxpdQsKuaSq/eH3qGzKfeNh66DUkiVLWrze5XJp7ty5mjt3bnIGBHRCASso1c5MqboVq8zMK6RIzSHJXzdjG3Om1M7EjgmIUXl1QPsPh8vwBvSKXlhkQF43rdm63wpaNWRmSmW0Y+ZVqpcpFSBTCp3f7opw4KRPTutduPt05kwpX7dwNsL+reFsqYGjE/rQZpZUXjef9lX6tWVvpQ77g8ry2fqrE2ALZiCpfZlSdUGpZEwgWZlSMZTo5h4RDkr9e0X4spkh5c2UegyQDmyT9mwmKBUnW5fvAWi/QN1sRUt9JmJhBrX8tSEZpKWmzqG6VYfSc6X07Jb3NWd8yglKwR627w2X5vXO9ik7PfrLnVnOt21v0+V71ofcdsy8SlJGMksCgAQrKw8HmGIJSpklsrsrOkFQKlQr7d4c/jn/G3X/myV8mxL+8GZQatRRvdQnJ12GIW3eRQkfEAszkNQR5XtJmUCyglKtTPZK4aCUJH29Mfx/nyGR68yfzfcuxIygFNDFmQ1Qve52lu/Vy7Qy7xMpcKiuFC+WE6c541PxdfgDPpBiZsBpQF5Wo+usoFQrPaUy2rmWfSRTiqAUOj8z66nLZUrt3xru1+LJCGdISUkOSh2UJA3tl6tvFIYXYthECR8Qkw4p3zMzpZIxgWSV78WQKVW3iJClflDKzJra82nHjMtBCEoBXZy/o8r36vWkoq9UCsXa5FySuvWRXG7JqJUqyhI7LiAG2/aFS/OKe3VrdF1RXaDqy2aCUmamlJnp1FaRTCkCtej8zKwns19USzpVUMpsaN5nSLhfixTJmEpCs/NNdZlSx/XL1TcKw71q6SsFtC4UMqzvHu0ptzcDWgkPShlGnJlSDQJXvetnStX1viNTKm4EpYAuLhCsy5TqoPI9SQrQVyp1Yl0hRJLSPFJ23+jbASm0vaVMqbptu8qrm0zXt8oByJQCLF02U8oMPJnZUfV/Lvs4oatbVdYEtaWut91x/bpraF2mFCvwAa3z15u47phMqQRPIB3eK4XCvS6VHUtQqn/kZ5db6jUoctnMmiJTKm4EpYAuLhgKnxx87cyU8rjJlLKFeDKlJJqdw1a212VBFfdqHJTK6xbuM2UY0lf7G2dLmYEqMqWAiLiCUtmRoJTte0OaJXpm5oEk9TpacnukmnLp4FcJe+iPd5bLMMI9uPrkpFvle5/sLFeI9gVAi+o3Jm9XTylvkhqdmytUd+sjeXyt718/U6rnQMlT773XLN8r/49UTWZlPAhKAV2cOWPhaWdPKZfLZQW2CEqlUDwrhEiRk6d50gVSyOwp1VRQyuVyWRlUTTU7j/So6JhMKRqdo63+vH6H/rLNbYsAhVW+F0emlL82pPKqYELH1W5NZUp5fJEvfQks4TObnA87orsk6aje3eTzuFXpr9WXTQTMAURU1034uF3t++6RnqxFSeKd7K3fU8rsd2fK7BGpUNjzWXtH5igEpYAurqPK9yTJU9dXyrxPpEB5HHXvEplSsA1/MKSdB6skSQPyGveUklpega+jMqXMmdukrOiDLqc6UKtf/WWT/r7DrXe37EvpWGqCtTpwOFx2kh9DUCrDm6bcjPCql7srqhM6tnYJ+qW9dV/ozD5SJquvVOKanZtNzo/rF86Q8qS5dUzf8Gq39JUCWhZZeS9NLld7glJJKt/7/+3ddXxcZdbA8d+9o3FtU0vdXaFCW7RA0cVZKLqCw7Is+rI4xRdYtMuiizsUa6lRd/embZK2cc8kGbvP+8edmSSNNNakLef7aT+ZzNw7c2cy18495zyhAYQaeLHXGVt52xFV8/FQs3PpK9UYEpQS4hjnbaFG51Wfw2tIhkGbaUxPKYDowHTFEpQSbWtfQRmGgnC7hcTI2lPkg5lSabU0O2+pTClnazVPFcekNakFoX5ky3e3bVAqt9QDmAORxITZGjRPMFsq+0juK5WfAoYP7FEQ06X6Y63Q7HxzlSbnQQM6BEfgk75SQtQnGERqdlZza42+Fxp5r4HH1VUDbfbImo8H+0pJs/NGkaCUEMe4YE8pWzPL96BKUErK99qGUk3oKRW48lMi5XuibaXmVzY5r+vqadeEuoNSkikljgSLduWGbrd1plSon1Sko8EZCUdFs/NgFlT7/tVPAKFKs/PNh+WlPT6DHVlm4GlQp5jQ/QM7BZudS6aUEPUJXUBqZoVGsEn6Yd9XN/Zib1WOWoJSidLsvCkkKCXEMc7TguV7dinfa1vlBeAPnEg0OCgVmE4ypUQbS6unn1RQt0BZX2pg5KuqJFNKHAkWp+SFbm/cX0ypu+16MzWmyXlQ+yhntXmPSKF+UgNqPhYMSuXsAH/Lf/Y7s0vw+hXRTitd4sJC9w/oKEGpY5orDz67CnbObuslOeqFMqVa6ALS4e8p1cigVFmVixG2Wo5nJFOqSSQoJcQxriXL96yB5/BIplTbCGZJhSdUH+2jPsFG58F5hWgjlU3Oa+8nZT5mHuClF5TXaCIdvFraYge6LXz19YOlexn12Gw27S9q0ecVR46iMi8b9xUCEGFV+A3FyjbMlmpKUOroyJSqpcl5UGw380TQ74aCPS3+0sHSvYGdoqtlnwXL9/YVlFNU7m3x1xVtbPU7sOVbmP1QWy/JUS/YU8rZUheQDvvoe40MSlXNgKqoZX8fDEoV7AHfEbydPcJIUEqIY1wwKBXMcmoOW+A5fBKUahuhZoyNSDEOTusuAk/N7BMhWktavvn9C/aNqk3HGCdWXcPjM8gsrt6IOXi1NHig2lSHI1PKMBSvzkshz+Xhk5VpLfa84siydHcehjJHYxsabwZNl6TkHmKuw+fYD0rVkiml69Cuv3k7q+VL+LaE+knFVLs/JtxG51gzc2qbZEsde3bPN39mb4aSrDZdlKNdZfleS2VKtVL5XkN7SlXNgKptZOvIJHDEgDIgL6X5y/c7IUEpIY5xXr954GxtyUbnfinfaxON7ScF4IyubMQoJXyiDaU2oHzPatHpHCiZObivVGWmVMs0T23JPhUr9+aHgmi/7Wi7IIU4vBYH+klN6BVP35hgUCqvvlkOq+AIeu0iGxGUCkybU3qEBqW85ZC/27zdrpagFFTpK9Xyzc4PHnmvqgEdzZG2pITvGONxQfryyt/3LGi7ZTkGVJbvHQWNzn1uKAvssxs6+l61oNT+mo9rGrQLjMCXs615y/c7IkEpIY5xLVm+Z7dKo/M2Fap7b0RQCiqzpaTZuWgjhqFCQaZg36i6hEbgyzs4KHXkZkp9v6Fy3UrLL2NvrmQlHouCQanxvRLoHW0GpbZkFFPg8rTJ8oQypaKdDZ4nNPpe8REalMrZDigIi4fI9rVPkxQMSm1p0Zc2DFVnphRU7SslI/AdU1KXgr/KOhzMmhJNEtxXN3/0vVbo/1gayIqz2CE8vmHz5B4iKAXS7LwJJCglxDGuMijV/PI9a2AEP+kp1UZCmVKNHCEkmJIsmVKijWSXuHH7DKy6RqfY+k+gg5lUqfnVAzstffW1pTKlvH6DHzea62a00wrAwp05LfLc4sixv7Cc3bkudA2O7xFHtB16t4tAKVi+p22ypbKrjL7XUO2jj/BMqWBmQfuBNUfeCwqW9bVwptTePBcujx+HVadXu5rB81BQKlMypY4pu+eZP+O6mz9T5pmjHYsmabFG57ZWKN8rrnKxt4EjmJJTJdBUlgfeiprThDKlpNl5Q0lQSohjnC9QamdvwfI9n5TvtY3GNmMMCqYkS6aUaCPB0fQ6x4UdspS4cgS+oyNTaklKHvkuDwkRdv40sScAC6SE75gTzJIalhxLlNMGwLie5pX1tirha1JPqUAAK9/lOTKznoPZT7X1kwoKlu/lp5jlfi0k2OS8f4eoWrdTwaDU9swS6a15LNkdKNeb9A+wOMxjJclwabLKnlItVL53OBudh3q1NrB0z+OCooP6RtaWLSWZUo0mQSkhjnHBrKaW6Ckl5XttrLHD1gYFy/0kU0q0kdRA6V59Tc6DugYypQ7uKXU4MqVUC1wN/26deVA7dUhHTupnlhstTcmV7eQxJhiUOqF3Yui+sYGg1NI2CEoppUJBqfaNCErFhduxBLKe80rbpuywXqEm5/3rniYyCcLizEbCLXjSVznyXs3SPYBu8eGE2y24fQZ786RE95hQmg1ZG83bfU6HrmPN21LC12TBIFLz99WtUL7X2F6twe1NeAIk9DFv19bsPDgCX+5OMA5zo/ZjhASlhDjGtWT5XjBTSsr32khTGp0DRAczpSQoJdpGWgOanAeFekodHJRqoUwpR2B+Q4HPaF5QqsLrZ9Zmc708d3gnBnWKJj7CjsvjZ01qQbOeWxw5lFKVTc6rBKWO6x6PpsHO7FKyS2op4TiMSty+0MlaYiPK93RdIzHSDhyhI/CFglID655G06D9oOrTt4D6mpyD+dn162A2O98ifaWODXt+M392GAKR7aDniebvKfPabJGOdi1WvncYBiWpIRhQim5ok/NAUKpd/8p5asuUiu0KVif43VCY2vzl/B2QoJQQx7hgUKolyveCPaUkA6Bu5Z6Wyb6owfBXNmRsdKZUsNG5BKVE20htYJNzqAxKFZZ5KSr3hu5v6UwpaP7B7oIdOZS4fXSMcTKqaxy6roUyaX6TvlLHjO1ZJeSWegizWRjRNTZ0f2y4LRTAaO1sqWBAKcphJczeuJO/9lFmX7fWDqQdUkUxFKWbt9vVkykFVfpKtUyzc6WqNjmvPSgFVZudS1+pY0Kwn1QwGNXrJPPn3kXg99Y6i6hfMFjubG6j81BPKePwHFdD4ysQgk3OE/tCTBfzdm1BKd1SmUklfaUaRIJSQhzjgv2fWqJ8z2aVnlL1WbAjh0EP/cwrc3e1/JO7ckH5QdPrHpGoLqGrORKUEm0jLVDq0rUBmVIRDmso86PqCHwt1VOqalCquWUB3603r7KeM6wTeiBoP6lvOwAW7pS+UseKRYG/5XE94mtc/R/XMwFou6BUY/pJBQXnOeIypYInb1EdDz0SVjAoldUyQamsYjd5Lg8WXQsFnmozUIJSxw6lIGW+eTsYlOow1CwN9ZTA/tVttWRHtVBPqRbq/wiHsUKjsQMIBbdR7fpVHlsX1TECnzQ7bxQJSglxjPO0YPleMNtKMqVq9/r8XRgK3l2yt+WboAabMUYmmVdgGiO4sy3NBEP+dqL1hTKlGhCUqjpd1RH4gplSzb36qmlaZQPVZgSlXG4fc7aa2YvnDK1M/Z/Ux8yU2ri/iHzXEdizRzRabf2kgsb3Mu9r7WbnwYBSYlOCUpFHaFAqmPV0qCwpqCzva6HyvWDpXq92EfUGvoMBq2BWlTiK5aVA8T6w2KHrePM+3QI9Jpu3pYSvSdzels9qPmx9pULle40MSiX2hejO1Z/jYNLsvFEkKCXEMa6yp1RLjL5nBrakp1RNu3NKWbY7H4A8l4fFLX2C0tR+UmAGstDA8IFLSopE6yoq91JYZpZBNKTROZgNhaH6CHwVoeapzbv6aj5H83tV/Lo1iwqvQY/ECAZ3rsysaB/tpH+HKJSCRbskW6qx3tv8Hn+a9SeK3EVtvSgAeHwGy/eY2/YJtQSlxvSIx6JrpOWXsa+grMbjh0t2E5qcB4UypUqPtKBUA/pJBQUzpYr3QUXzvyubQ6V7tTc5D+rfIQpNMz//vCPt8xONEyzdSz4e7FX2TcESPml23iQVLdTovGrbkcMyAp9SjSvf83kgf7d5u13/KkGpfbVPL5lSjSJBKSGOccFSO3szdw5QWQLo9Un53sE+WZle7fdv19WRzttUTR15D8BirSz5K6njio4Qh0mwBC8x0kG43dqgeZIDQan0Ks3OK1ooU8p8jsCoPs040P0+WLo3tCOaVj0TNVjC99sOCQI3hsvr4pW1r7A8Yznf7PqmrRcHgHXphZR5/CRE2OkfaHJdVaTDyrAuZiCjNUv4js3yvWBQasChpw2LrTwpzN7W7Jc+VJPzoAiHNRQ03yrNzo9uwaBTsHQvKPj7vpVmnzPRKC3V6Lx6VvNhaHbuLgZv4BijIcfW+bvNNhr2KLN0L6YRmVKHqyfWMUSCUkIc44JZTcEm5c0RvGrhkxKwatw+P1+sNq+U/HVyTwB+2ZTZsiOGNCdTCip3uNJXSrSyYAleQ0v3qk5bNVPK3ZKZUoHAVkUTD3QLyzwsCASczhlWc9SeSX2CfaVyDl+D1mPQ3LS5VPjN5ts/7P6hjZfGFMx2G987MdQ37GDBEr6jJSgVzK7KPtKCUo3JlIIqzc43N/ulg5lSAw8RlAJpdn5M8Ptgz0LzdjAzKiiuO8T1MAMQqYtbfdGOdpU9pZofZmiJUvs6BY+HnTHVM+XqEmpy3sccATTYU6osD7zlNadP6AWaxQx+BY/hRZ0kKCXEMU7K9w6/WZuzyHd5SIp2cNeUfnSJC8Pl8fNroN9MiwhlSjVw2NqDBXeeMgKfaGXBwFK3BpbuQWVQKi2QKaWUatlMKWvzMqV+2ZyJ16/o3yGKPkk1s2dGd4/DadPJKnazI6u0Wcv6e1I1ELU1fyu7i3a34dKYKvtJJdQ5zfhe5mNLUvJaLQgZLL0L9odqjCMyU8qVVznCbLt+DZsnFJRqXl+pojIv+wrMk8pBHesv3wMJSh0TMtaBu8gMSHQcXvPxYLaU9JVqtFBQqgUqNBwtkNVcp8ZWIFRtcg7gjAVb4LimtmwpqwPie5i3c6WE71AkKCXEMc7bguV7Ninfq9XHK9IAuKaHncybbuI6p5lB8e26FiyVC17RaW6mlASlRCsLlu81ZOS9oK7xEQAcKCrH7fPj9atQ9vuRkClVddS92jhtFo7vYQYqpISvYXLLc1masRSAPnHmUNo/7fmpLReJkgov69ILgdr7SQWN7BaH3aKTWVzBnlxXndO1pJYq3ztiMvmCpXuxXcER2bB52g8yfzYzKLU5wyzd6xIXRky47ZDTh5qdS1Dq6BUMNvWYVPvgMaG+UhKUaqyWKt8zn6N5++p6NTcopWkNb3YufaUOSYJSQhzDDEPhN8wDzpbIlLLK6Hs17Ml1sSQlD02DU1fNpHTBAsb98C4oxfzt2RQFGjw3W2OHrT1YtJTvibbRlPK9xEg74XYLSsG+gvJqB6QtURLQnEyp7JKKUJnWuXUEpQAmBkbh+22nBKUa4pe9v2AogyGJQ7h+8PWAmTnVlkGT5bvz8RuK7gnhdImr+/vrtFkY2S0WaL1R+JoTlEoMZFeVe/24PIfhZK8pGlu6B5WZUlmbm9WzZUuoyfmhS/cABnQ0syNTckrxHK5RwcThFeondVLtj/eYBGhmP6CiFu4Reoxzt1Cj86rPcVgypUIj7zWwAiFUvlclkzM4b3Ed3xFpdt5gEpQS4hjmrdL7yWppiZ5S5nNIT6lKn6w0s6ROTw7D/+ss8860vUxVZnnPT5taKAhU0txMqWD5njQ6F60rlCkVyH5qCE3TQiP1peWXVTsgbZmSgKY3T/1xQwaGguHJsaGG7LWZHGh2vmJPfsv2lztG/bj7RwDO6nkWJyWfRJg1jPSSdDblbmqzZQr2k6ovSyqoNftK+Q1FvqvpQakIh5UIuxmYPWJK+EJBqQY0OQ9q1w/QoDwfSrOb/NINHXkvqHNsGNFOK16/Yld2KUop7vtqI2e8+Buvzd9FdklFk5dFtAKPC9KXm7cPbnIeFBYHnUaYt2UUvkYJlu8FBxRpjtCgJIclU6oRvVoNP+TuNG9XLS+O6WL+rCsoVbXZuaiXBKWEOIYFS/eg+tCqTRXMtvJI+R5gDhX+xSqzwflVRZtQ7sqD+0syVgHwTUuMwufzQFlgaHnJlBJHEbfPT0axeYLWmEwpoDIolVcWCuo4rHqNke6aojmZUt9vMNeh+rKkAHq3j6RjjBO3z2D5nvzGL+TvSHpxOhtyN6BrOqd3P51wWzgnJp8IwI97fmyz5arsJ9WQoJRZrrlsdx6GcXj3kXmlbgwFugYJEY0PSgG0j3YCkF18hARQgkGpdo0IStnCIL5nYP4tTX7pTfsbNvJekKZp9K/SV+r7DRl8vCKNbZklPPPzdsZPn8uN/1vNbztyDvt3QTRB6hIwvBDTtfL7U5tQCd/8VlmsY0Vl+d4R3ui8MeV7hWngqwCLHWK7Vd4fzJSqK5uuiZlSS3fn8d4O/cgbjOIwkqCUEMcwb5WNeMs0Opfyvapmb8kiz+UhKdJG+7kzAYjtbZYqJa1bQrTbxfI9+WQU1TIqR2MEm79a7BAe37TnCPWUkkwp0XrS88tRCiLsFhIi7I2at+oIfO5Qk/PmX3mFpveU2ldQxurUAjQNzhpa/4GspmmhEr6F0leqXj/sMRucj+04lsQw8zM7u+fZgNlXym+0fqZZVnEFO7NL0TQY16vuJudBQ7vEEm63kOfysCO75LAuW/BEJSHSgaWJI+sGG6QHG6a3KaUqg0qNyZQCSAqU+zWxr1S5x09KjjkYQUMzpQAGBoJSS3fn8ej35uh/Zw/tyMiusfgMxU+bMrnq7RVMfm4er87bdeQE/45wZR4f5Ye7pDQYZOp1otkXqC7BLKrd85tVHvp707Kj7wUzpdq4fC+Y6ZTQByzWyvsP2VMqEJRyZUN5QYMWy+3z89B3W1mTp/PfRXsbNM+xQIJSQhzDguV7mkaTD1yrskn5XjXBBuc3RubjTU9HtxkkDS/GGecBr5frSjehFMxc38zspKqle03NEgkGpSqKwFPWvOURooHSAv2kuiZENDrDqWtCROg5KlqwRwU0PVNqZiBL6vge8SQFMk3qMylQwid9peqmlAqNuje1x9TQ/eM6jSPWEUteRR7LM5e3+nIFs6SGdI4hNvzQAVW7VWd0d/OiwZJdh7eErzkj7wUdUSPwlWZBRSFoeuVJXEMFe1Blb27SS2/LLMZQkBBhJym64Z9nMCj1xep95JZ66NM+khcuGc5XN03g5zsmcs347kQ5raTnl/PsL9sZ99Rc/vrBKuZvzw71+hTVFZZ5OPm5BUx5cQElFS3Uj7M2wSbndZXuBSUfb46u5spuVibe701lZnPLDUriPhwl8I0p3ws1OT9o+xQKSu2rfT5HFEQHSvxyGlbC98b83ezJKyPaprjlpHoy+Y4xEpQSool8foPFu3IP746zmYLley2RJVX1eaR8D1LzXCzalYumwYRNcwCI6VGG3ms8sb3NoM+J238Dpfh2fTNL+Bo7QkhtnDGVQ9fKCHyilaQG+kl1q6f3Ul2C8xzWTKlGHuh+Hxh179xhnRs0/YReiWga7MgqJbNIMiVqszV/K3uL9+KwODil6ymh+226jSndpgCV/aZaU2P6SQUFS/gOd7Pz5jQ5DzqiglLBE/74XmA7dLC3mmBmVRMzpYL9pAZ2im5U4Dw4Al/Q9AuGhEY57t8hmofPHcSK+0/l+YuHMapbHH5D8cvmLK55ZyUnPjcvVDIoKr02P4XM4grS88t5Y0HK4XmRkqzKAGaPyfVPa3VAt/Hm7RQZha+hQplSR3L5nuGvrEKIakimVC1NzgFiDpEpBZWBrNxDl/DtyXXx6vxdAFzQ3SDKeejRQI8VEpQSogl8foPbP13HFW8t59xXFoca+R5pguV7LdFPCqR8r6pPVqYDcFaSjm/xYgDihkfDFV8QM34QutXAkZ3FyLwUNu0vZld2adNfrDFXc+qiaVVK+CQoJVpHKCjVyH5SQLVG5y2dKdWUkoCUnFI2HyjGqmucObhh62JchJ2hXWKBIyNbyus3ml9O3MKCWVInJp9IpD2y2mNn9TwLgF/TfqXC13pBPaVUo/pJBQWDUst35+E7jPvJlgxKHRE9S5rS5DwolCm1DZqQxd3YJudB3RIrt2mnDmgfypKrKsxu4cJRXfjyxvH8csckrhnfnehA9tS1765kX8GReezYFvYXlvPukr2h3/+zcM/h+Xz2/Gb+7DAUIhqwbodK+CQo1VCVo++1QKbU4SrfK80G5TezMyPaHXr6OjOlAgGtsjzw1rFvDQayDtFXSinFg99swuMzmNg7geEJv68EAAlKCdFIfkNx52fr+WFDBu0pYG9uCRe8vuSIvOoVLLOztcDIewA2qwSlwGxw/vkqMyh19f75oBTh7d04Ln0c7OHoZz9JdHdz5/SX7IUAfNechuctkSkFVYaulaBUc323/gAXvr6E7ZmHt3dMq/C40DZ+hs3X8u8lLT8w8l4TglKd48Kw6Bpun0F64HlaOlOqMSP6BLOkJvZJJK4R/bEmB/pK/dbGfaUMQ3H9e6sY/9Rcft6U2abLEuQ3/Py05yegeule0PD2w+kY0RGX18Vv+35rteVKySklq9iNw6ozqltcg+cb1CmGKKeVErcvFOw4HI7ZTKmmBKXie5n9Fr0uKEpr9OxbDpjHboM7N6zJedBbC/eEbp9ziEEPAPp1iOLhcwex6N6T6d8hipwSN9e+s5Ki8iM3276lVGzfzu4JJ5D0xRd1TvP8rO14fAadYpx0iQvD4zN49pfGNYdukN0NLN0L6hlodp66BHxHwLpyhFNKVTY6b5GeUk0fKbdewePqyKTqPaJqo1Rl6V27/tUfc8aCLTCycF3ZUsFAVvYWWPM+LH7JzNQ6yHfrD7BoVy4Oq85D5wxocreOo5UEpYRoBL+h+Mfn6/lu/QGutM5hhfNmXo9+j9xSN5fNWMaSwJXVI0WwzM7aUplSgb5UPv/vK3p/sDlbs8gt9ZAUZiFmrllWEjc+GQaeb06QfBxxpx0HQLddm4lxl/Dt+gOopjbKDGVKNTMoJc3OW8Sm/UXc9dl6VqcWcMen647uIK1hwGdXYf3uJibueLzFs+hS88yeUt3iIxo9r82i0ynWLOXZnmUGzFo6U6qigT2llFJ8FwhKNeQEtKqJgb5Si3bltmkvmRkLd/PbjhyUgge+3ki+y9NmyxK0KmsVOeU5RNujmdh5Yo3HdU3nzB5nAq07Ct+inea+fEz3+EYFQi26xtieZrbU0t2Hr4QvFJQ6VnpKZW8zfzYlKGWxVmYiZDWu74/Pb7AtcGGhMZlSO7NKeD1QYgOwr6Dh2YfRThvvXDuGpGgHO7NLueGD1XgORxPnI4RSisxHH8MoLiZm5SrKli6rMc3WjGK+XmteuDtQVBH6PL9dd4B16YUtuTCVTc4bGpRqP9DMpPGWQfqKlluWY5TPUAR3cy1SvhcqtW/hdaQxF3tLs8BdZGZVJfSu/pimVbngW8fF5+D2KWUufHcrzP4nzJ9ebZKiMi+PzTS3X7ee3LtJLQ+OdhKUEqKBDENxz5cb+GrtfoZbdvOo/X0AzvDM5taOWyh1+7j6nRWhq+lHguDJckuX73mO5pPwFvBRoMH5w97f8Lt8WMP8RN3yUrUm5M4rn8aZ4AUDbto3k9S8Mtbva2I2XfDqS7MzpQLzS6ZUkxWVe7npwzWhdWBrRjFvzD9MvS9aw5KXYdevAES5M7B+cG7dQxs3kmEo0gMnF00p34PKYNbOLLP89VABgsyiCu77agMLD1Eq52xkptSWjGJ257hwWHVOG5jUoHmChifHEuWwUljmbbOM2g37CnkukHUQG24jz+Xhn99uapNlqSpYujel+xRsltp7ZwQzqH7b9xvFnsOXfVTVokCj8sb0kwo63H2lisq9HAiUYDYrU+pIGX3PMCAnGJQa2LTnCPWValxQKiXHhdtnEOmwNvgk0DAU9321MdSzE8z9QGN0jAnj7WvGEGG3sHR3Hvd+uaHpF62OcMUzf6B89erQ7znTp6M81QPiT/+8rc7B7R6fuaXlPpu8XWbgwFKlV9Sh6Hr1UfhEvaqW2bVEZnNl+d5hypRqyHF1sOwurrvZZ+xg9fWVKi+Elf+p/F0LnI/99ixs/zl097OztpFb6qFXuwj+POn309y8KglKCdEAhqG4/+uNfLF6H3G6i49iXkc3vKE65Dvdr3PpADtev+LWj9fy9qI9h3jG1hEMSkn5XstJzy9j4c5cLPjpv+Q7AGJP6IfWZXj1CRN6EXfaGAAm71mDRfn4tqklfC3RUwokU6qZlFLc/cV60vLLSI4P49HzBgHw8tyd7Mg6Csv40pbDnEcB8E+6B5c9Ea1gD7w7FQobXwZzsMziCjw+A6uu0TGmkc2LA4Jlfw3JlCoq93L12yv4eEU6f35/Vb1/k8ZmSgWzpE7u377RjUdtFp3xvc1AxaGCZU3h9vl5fOYW7vxsXajMsSqX28ftn6zDZyjOHNyB9687DouuMXNDBj9tbLsAtdvv5tdUMyBaW+leUL/4fvSO7Y3X8DIndc5hXy6f32B5IMupMf2kgsYFglIr9+S3eAbMN2v3M+aJX1mbVghA+2YEpYLz5pW623Y0uKJ08JSaJXjxTTwZCwSl/Flb2JVd0uAgxuZA6d6AjlHoDRyh+OOVaaxKLSDCbmH6BUOAxgelwMzMeu3KUVh0ja/W7udfsxs2MtfRxHC5yH72WQBir70GX0QE3j17yP/fh6FplqTkMn975XbRYdVDDeMBVqUW8FNLlRsHm5V3PR5sYQ2fL1jCJ32lDqnqKHktcUE8dAGppTOlghdnoxsRlDq4yXlQcAS+oioj8CkFG7+AV8bA5q8r7//j53DcX8zbX/8F8vewNq2AD5ebx1xP/GFIi/TiOhpJUEq0qgU7crj67RUsSTmyytzqo5TiwW838cnKdHRN8WO3Twgv229GzG9cCkmD0cryeMr+NleP7QrAozO38NRP29r8ylfLj76nBZ739xuU+mSlueN40j6bigN+0BSxf3+u1mmjb30e3aZQpYqbc7/h+/UZTWt+2+Lle0dGP5mjzduL9/LL5izsFp1X/ziSaWO7ceqA9nj9Zlnv4Wxs3OLK8uGL68xGn0MuxjjhLhb3uR8V1wMK9sI7Z5k/myHY5LxLXFiTS4iDzc6DJUZ1XXmt8Pr58/urQsGrCq/BzR+uoczjq3X6xmRKKaWYud48gD23kaV7QRP7mBcwftvRsvu+ojIzEPfWoj18tWY/p/1rAa/O21UtGPLI95vZk+uiY4yT6RcMYWiXWG6YbJ78/983m9qsjG/hvoWUeEtICk9iVNKoeqcNNjwPZlY1VnGFt8H74w37iyhx+4gNtzGwU+P6DAH0bR9FQoSdcq+f9fsKGz1/bZRS/HvOTu74dF21v+036/ZjNDGglBDpQNfAUJDnasNsqWCWVEIfqCNbri5KKbZnlvBzjhkI3LlpJae+8Bt3fb6hQccpjW1ynl1cwVM/mct71+n9OKV/e8AcMauxI3kCTO7bjifOHwzAy3N38VlgAJVjRe6bM/BlZ2NLTib+5pvJPdMsxc199VW82dkYhgp9nkG3ndKHv51avZn09J+2tkymTGNL94KC0x9YC+UFzV+OY5i7ygBLDQ301uewNTpvTKZUcNS8docISgUzpfJS4IPz4cvrwZVdveSvvACmPAFdjoOKItSnV/LIV6tQCi4c2SVU/v17JEGp3yFDGfyy9xdSi1Nb9XUX7szhz++tYsGOHK55eyWzNh/5J8ZKKR7+bjMfLk9D0+DbkevomDHHvKJ38XsQ2Q7+8CboNrTtP/Jwt/X843Rzo/XGghT+/vn6Ng3gBF+7xXpKBZ7n99pTyus3+GzVPmIo5YT1ZnPeqFF9sHWvfUelJ3QiZqJ5wHlu6mJKSksa32fE4zJr2aH5mVLS6LzJVqcWMP1Hc4SoB88ewNAusWiaxuPnDyHKaWX9viL+24oZkk09EQXMK3jf3gzF+8zMhLP/BZpGuT0R35Xfmo2Di9LMwFT+7ia/TFq+2U+qa0Lj+0kFHVxSU1vjVL+h+Nun61ixJ58oh5X/XX887aPMfi3//HZzrc/bmEypNWkF7C8sJ8Ju4aTASWhjTQ70lVqTVkBJRcs0Nk7PL+OC1xezbHc+kQ4ro7vFUeE1mwNPfXkhy3bnMXPDAT5btQ9Ng39dOpzYcLNB+22n9KFfUlSblvEFA0xTe0xF1+rfRwX7Sq3IXEF2WXaDX8MwFC/+uoPhj8zirJcXhTKg6rM40E9qXM8ELE04qdJ1jbHBEr5dzS/h8/oN7vlyA88HMmkuP65r6LGPV6Rz3XsryWtCCZ5F14iPaPm+UntzXUz773L+8fl6VuzJP3QwsJFNzgtcHr5bf4B/fL6ecdPncvqLv/HYCvM1erIfKz6+XLOPv36wmnJP/YGMYKZUQ4OPj3y/hZIKH8O6xHDVuO60i3KQEGHHUDR50IvLjuvKLSeZJ633f73xsGRTtgVPair577wDQNJ996I7HBSPGolj6BAMl4uc55/nh40ZbKjS1qBvUiR/ntiTP0/sUa3xfHp+Oe9VGZmvSfw+2GsOPBPKfKoiPb+Mf3y+ng+WpdYMgMV0hsS+oAzYs7B5y9Eaygth6Wuwc3arv7SnJIeLLfPpYG3GiNNVHPZG540p36szKBU4ts7fDfOmw2tjzQCoxQEnPQA3LoFR1wSeaxtY7XDxuxCeiJa1iSvzXiY2zMr9U/vX/vy/ExKU+h16ftXz3LXgLi7/4XJ2Fzb9hKMxlu/O48/vr8LjN0iMdODxG9z44Rq+WrPv0DO3EaUUj87cwntLU9E0ePtkP0O2vGA+eMZT0Gm4ebvDYDjpfgC0n+/j5hF2nrloqJmSvWY/f3pvFS537VfrD7fKnlItVL53LPWU8pabJ+ZvnWqOqtIAc7Zmk1Pi5gHrF5SmmCe1cTfeW+88sbc8bL7cfp2bvN/y7bpGls4Fs5rskeBs/FX7akKZUhlNGjr7qOX3wfafzNT9JmQv5rs83PLRGnyG4uyhHblybLfQYx1inDx4ltkH5fnZO0jJqX4gppRiW2Zxix1Q7cgq4ex/L6T3Az8y9sk5nPfqYm74YDUPf7eZNxak8M3a/SzbnUdqXj1X7pe9Dtt/DATX3wVHVOVj0Z3gmh/MA/DifWZgKndX7c9zCMFMqeY07Dx41L6D09qVUjzy/WZ+2pSJ3aLz5lWjOKFPIi9fPgJdgy9W7wuNlFlVYzKlvg9kSU0Z1KHJPTKS48PpnhCOz1AsbYFeQ+vSC/nDa4tJyTEzoD6/YRyf3zCOf106jIQIO7uyS7lsxjJu+WgtADed2KvaFViH1cKzFw9tszK+Yk9xaDS9YBZUfTpHdmZE+xEoFD/v+fmQ04MZvLj23ZW8+OtODGX2Bbt0xjJu/mgN+wvrbky9KDBgSVP6SQUF+0ot3d28zLjiCi/XvbuSz1btQ9fgsfMGcePkXqHHHVad+dtzOPOlhU3KQG/pZudbM4q56I2lLNyZy+er93HJm0s56bn5vDpvF5lFFbXPlG0G++sKSlV4/SxNyeP5Wds575VFjHx8Nrd9vJbPV+8js7gCh1WnV58BeCzh2DU//zs/AadNZ+62bK54axmFZbVnAiql2BLKlDr0vvXXLVn8sDEDi64x/QJz3dE0jQEdzXm3NKGEL+jvU/py/vBO+AzFjf9b06RywCNN1vSnUF4vESecQORJgSCQrtPuvvtA0yj69ju+er/64AVP/mEIdquO1aLzzIXDsFYJCv977q7mZXUeWAPuYnO0tI7Dqj20bHce576yiM9X7+PBbzZx4rPzeX/p3ur70FBfqZYv4avwVbAhZwOGauZxWUUxLHgGXhwKv9wHH14EH13W7KznBsvZTqfPz+JZ2ww+0e6rXLeboTIo1Yble7mB0tpDle/tngcLngK/B3qdAjcthcl3m32ogvMGs65iOpN75hv4lcZFlt94a9BGEpoxcMWxQIJSvzMfbf2I97eYDbpLPCXcNOcm8soP3wgxYB48X/fuSiq8Bif1a8fCu0/iolFd8BuKOz9bz/tL9x7W128KpRTTf9rGO4v3AvCvszpz0oZ7zFKXwRfB6OuqzzDhdkg+3tzhfXMTl4zszH+uGoXTprNgRw5//M+yJl3JbK7KnlINWNUrig8ZqDhs5XutHSApzYZ3z4K1/4N9K+GdM+GHu8Bd/5XOj1ek0VdL55Q9SzB8OvYuSYSPr79ZpnPgYML6JYPSuChtPis2bW9cmn/oak7zsqQqvH4WZ1lRaGB4eXv2KrKL6zhJaAzDMIe4Xf0u+Ft/aGuX21f399EwYNOX8Nrx8PFlZjr1GxNh8zcN/s4ZhuLOz9aRUVRBz8QInrpwKNpB4/RePLoLE/sk4vEZ3PPFhlAW086sEi6bsYwzXlzIWS8vatYoQkopPluZzrmvLGLT/mIMZfZsWp9eyM+bM3l3yV6e+mkbd3y6jstmLGPys/Pp/+DPnPD0XOZuy6p8ov2rzZFfAE5/ssbBOWAepF090xz6uOSAua7kNL7fSWqgv1FTm5yb81bPsnIelCn12vwU3g9cOHjh0mGM72UGEsb2TODO08wSkAe/3VSjv1RDM6V+3ZLFx4GBDc4Z1rzy2UmBbKnfmpkJ8fOmTC6bsZTcUg8DO0bz9U0TGNAxGk3T+MOILsz9+4lcflxytXk6RDtrZNe1ZRnfnNQ5eAwPvWN70zeu76FnoLLv1A97Dl3Ctz69kLP/vYgFO3Jw2nQeP38wVxzfFV2DHzZkcPJz8/nX7B01MmnKivPYlGauL/X2k1IKTdW9HQ9+D9ekFjaprAvgQGE5lwQCPGE2C/+5ajTTxnUnp9TcbifHh/HtLRPo3T6S7BI3V7y1nBdmbW9UGXFLBqXWpBVw6ZtLyS11079DFJeOTibCbmFvXhnP/rKd8U/N4Zp3VvDjxoxQMHhdeiFl+zaaTxBocl5c4WXe9mye/nkbF72+hCEP/8Ll/1nGv+fuYv2+IpSCfklR/HliDz64/jjWPzSF968/HntHs8ff2MgsPvzT8cSE2ViTVshFbyzlQC1ByH0F5RRX+LBZNPq0j6rxeFWlbl8oo/DPE3tWy6wa0NGctzmBJE3TePqioYztGU+p28e176wko6jhI/odaUoXLKB0/nywWkm6/35Sckq58/MNvLJZ57rl5awaZI60eeGij9GrBGLu/3ojpzw/n3NfWcS/ft2Br8o2q6TCxy0frWlUKW41wdK9HpNAr7y48NHyNK58azkFZV76d4iiQ7STjKIK/vntZk58dj7vLQkEp0J9peY3/rXrUewp5qqfruKKH6/gzvl3Uuat2RfwkNylsPAFeGkozHvCzK6P6wG6FXb8BK+Ohd+eA99hPA9JmQtvnYa92NxfdiIH/jslNJBKUzkCF4JavKdUsLdq1CFK8ssLzNH3ABL71D5NTJfK25EdzIt9V34JCZUXEGgX2M9VOZa6f20cz/guA2DU1qfN47PfMQlK/Y7MS5vH0yufBuC6wdeRHJXM/tL93DbvNip81U9Oiyu8fP7LfFY9Nom1j09ky/qaQ7g2xJYDxVz13+W4PH7G90rg9StHEWa38MyFQ7lmfHcA/vntZl6dt6vN+y8FKaV45pftzPjNzCJ78vxBnL/nUXMDltAHznmx2ihrgLmDO/91sIWb6cEr3uTk/kl89OexxIXbWL+viNNfXMgHS/e2ajlfsKeUtb5MKb/PHAXimZ5mymnq0jonDTYt9LZU+V5FMXx7CzzZEX74u/n74Za9Df5zirnxD4uDwRea96/8D7w2DnbV3kg3Pb+M33Zm80/LexTtMhtkxl11XY0ARW1ir7kRgPLdNq73fcq8bQ0vP2lqPynDUGzaX8QbC1K48q3lDHtkFle8s4ZcZR5Mfzl/JeOemstf3l/FvG3ZTWt0W3zADPR8dyt8f7sZ8Nm7qNZJXW4fL8zewY3/W90iI5AVlXu576sNDHroF4574lf+75uNrE4NlIooZY5q8uYks29S3i4IizezzbI2wudXm9/19Z+Y3/96vL4ghfnbc3BYdV69YiSRDmuNaTRNY/oFQ4iwW1iVWsAbv6Xw1E/bOPOlhSzfkw/AruxSLnhtMU//vK3RWVMut487P1vP3V9uCAVRhifH8s61Y3hz2igePW8QN57Yiz+M6MzYnvH0SIwIBW/2FZRz3bureObnbfhcBfD5tWB4YeB5MOZPdb9oVJIZmGo/CEozzcBUI696pgUypbo2I1Pq4M+7aqbU56vSeTYwotw/zx7I2UOrH1zedGJvJvZJrLW/VGWmVN3b489WpfPX/63G7TPo1S6CyX2bVroXNCnQV2rhzqZlzyileGvhbm78cHXoIs9nN4yjw0FN5GPCbXSKqd7E98FvN3PRG0tqnDg3p4zP6zeYvz2bR7/fwher9zWqpDQYWJraY2qDtqFgjtBn0SxsydvCnqLaS2WVUny4PJWL31jK/sJyuieE8/VNE7hybDee+MMQvr/1BI7vEY/bZ/DSnJ2c8vx8vlt/wNxubP4Gx0sDmWO9g0nRWXUHUwvTsbx7OlM23Y6WMrfWSbrHO5kcdYDr+Yb8L/5m7ncaYfOBIv7w2mK2ZZbQLsrBZ38dxykDzFEfs4vNE8t2kQ76d4jmu1smcOnoZJQy+xL98T/L6w1oKKXYk+vi81Xp/LbDDJD+44sNfLg8tcnHYYt25nLlW8sprvAxsmssn/5lHE9fNJQVD5zKsxcN5bju8RgK5m/P4aYP1zD68V/pfu8PXPDqQix5OwF4cKmPs/+9kOGPzOLad1by+vwUVqUW4PUrkqIdnDusE89eNJRl953CL3+bxANnDWRin3aV2YvBkfuytzKqWzyf3zCODtFOdmWXcuHrS9iVXT0wHSzd65sUVa2xdm2en7WdA0UVdI0P5/ZTqp+YBgNUzc1uclgtvHnlaHq3jySzuIJr31nZ8FLf4gyoaJuRPQ9meDxkPWkOdx9z5ZW8muLlzJcW8v2GTHYW66zcW8BzySdTYgujV9EBztxbeX6xI6uUlBwXG/YVMXtLVo3nXpKSx9CHZzHooV84+bn5/OX9VQ2/2BMMJvUyg0s+v8HD323m/q834jMU5wzrxDc3T2DB3Sfy2PmD6RjjJLO4goe+28zkZ+fxUXZXlGYxS7QKWqb9icvr4sZfb2RrvrlvnZM2h6t+uooDpQ3MqPeUweKXzWDUnEegvABfXG8WDHmKayLf4Mlub5GXeBz4ymHuY/D6hMMzguDK/8L/LgJ3ESXtRnGK+1k26APNC/UfXgIr32ryUx+W8j1PWeX6cqgLvsEgUnTnuqsV2g8wm5ef8De4ZSUM+kPN88RgplR+Cvi9zN6SxawtWfxXnUNJjzPQ/B749CpwHd5EkSNZzaNrcUzalLuJu3+7G0MZXNjnQu4YeQfn9z6fK3+8kg05G7h/0f08N/k5dueU8f6SPVjWvMM/tP8RrpkHP56vprJwxbWMmfY4TmfDRqzYlV3CtP+aBymjusXxn6tGhw4edF3joXMGEhNm46U5O3n2l+0Ul3u598z+DTpA9fkNlu7O44cNGczakoXNonHqgCSmDOrAuJ4JhzzAqE1qnsvcSGzOYsVe80TysfMG8UfP55AyB6xhcMl71UtdqkroBVMeM4Mrvz4MvU5hZNe+fH7DOF5+7B02FoXx4Ldu3lq0h7um9OOsIR1bpAlgfQ6ZKZW/B77+K6QvN3/P3Q7vnGFmgp3yEITFVpvcGgpKtUBgbfcCs3yuKFBas/It2PYjnPUc9D90OUeTpMxDfTYNzV2CO7o7Gye/hZbYmxHDp6HPvM0ccex/F8DwK+D0J8ygVcBnq9KZoq1iZMEuUosS0RwOYs4/v0EvG33mmWQ98Tje0jLOy1nM8yuWceaQPzRsmRuRKbW/sJxFO3NYtCuPJbtyyasl8yFTxdFOKyJJy2ez0Z1ZgR1jpxgnl4xJ5pLRyXSKDUMpxcrMlXSL7kZSRFKN5zG2fI/69lYs7gK8uhO/xYkzZ6sZvBh8EUx5HKI74jcUX67ex7Oztoeuxv+yOZOrxnXnzil9iW7kSGYAszZn8uC3m8gKnJwVlHn537I0/rcsjXNjUrjX/hmdSgJX3x3RMP5WGHujmcm1/E1Y/rr5Xf/6rzB/unkgMezyGkP9LtttlowAPHbe4FCZRm26xIVz79QBPPjNJp75eXvo/lMHJHHHqX14a+Fuvll3gNfnp/Drliyeu3gYw5JjD/let2YUc/NHa9id46p2/7r0Qu79cgP/vnwkpw+q+d1QSlFY5uWlOTt5d8leXpu/i0nr/s7YilSI7QbnvFzzoOlgke3g6u/h/fPMYN67Z8PV30HSoEMuN5jbVKiZ7VQfpRSpeWWs2JvPyj35rAxsi4Niwszvy7xt2dz7lfk3vmFyL66d0KPGc+m6xr8uHc7UlxaG+ks9d7GZGRZqnlpLFovXb/DXD1Yzt0rwOCXH7JNzy8m9GdczocGBlKrG9krAqmuk5pWRmudq1OfiNxSPfr+Z95aaJ0NXHN+VR84dVGu/wNWpBbw4xzzRf+aioZRU+Hhh1nbWpJnZQ9PGdmPqkI4M7RKD02aW8f3htSXM3JDBWUMyOHNI3QFwpRRr0gr4dt0BftiQUW0b88GyVB47bxBDu8TW+16yy7JZkbECqOwV1RDxznjGdxrPwv0L+WnPT9w0/KZqj5d7/DzwzUa+WmOOcjplYBLPXTKs2jZmUKcYPvnLWH7alMkTP2xlf2E5t328BtfsX7i89H0sQAetgjd9D6Kl9oXuJ1RfiLRl8OmV6K4cnID69DI49RFzG+PKNbMFUuagpczlPW8O2IDtwK6PYfI9Zlb1IZp5z9uezS0frsHl8dM3KZK3rxlDlzgzQFbh9fNS4G+7v7Act89PuN3K0xcNZXzvBB74ehMr9uZz5ksLee6iYZw6MAm3z8+m/cWsTs1n1d4C1qQVkFtac9/wwNeb+GFDBk9dMLRG2Wx9ft6UyW0fr8XjN5jYJ5E3p40i3G6eXkQ4rFw8OpmLRyezJ9fFF6vTeXVeCiUVZoC4m5aFQ/NSruz8b7uGwgzsdEsI57ju8RzXw/zfNT780OtcMCiVZfao6psUxZc3jeeq/y4nJcfFRW8s5b9Xj2FUN3O/viU9H1CHLN1bl17Iu4F+Rk/8YTBh9uolvMH9wrYMc9S/pmwbgmLCbbxzzRj+8NoStmWWcNOHa3j1ipFEOaw1n9fvhW0zzYDA3oWg26D3KTDoAuh3ZvPL/Zuo4P338aSmYsQl8Cc1lC2B7+tJ/RJJNrIYNWIEry7YzfsDzuDmDV9z9ZafiD79dM48YQAWXUPXNErdPjKLK8gqquDHTRk19n9lHj+7c13sznUxa0sWU4d04K4p/ejZLrL2hXKXQrq5zaHniRSVebn5ozWhUt27pvTl5pN6hz7jaWO7ccnoLny2ah+vz9vFgaIK7v8xlUFhvRnGdrw752A77rraX6uByn3l3Dr3VjbkbCDaHs1do+/ixTUvsr1gO5f/cDkvnvQiI9qPqH1mbzmsegcW/ctspA0UhSXzru0yXsoYhpGhA3nMx84MbudC21L+afuQmLyd5v588EXmMW5z+5Qafpj1f7DsNfP3oZeybsA/SXlvPQ9EPc733T+H9R+b50V5u81zJN1S/3MepDGNznNK3JS6fXSLD6///Cp4XG0LB+chBjkIltslVs/oNQzFrpxS1qUVsja9kIU7zyQx0sHp1hwm9VUMDGQvh8R0AVsEeF2UZ+3k4e/MC85/mtiLqJNmwIyTzIDVl9ebWVa/Q5o6UtJT2lBxcTExMTEUFRURHd02G/H6eL1efvzxR6ZOnYrNVvfBzN5cF4//sJVStxcNLXS+4dVy2GWdjk8rIcoYRE/jVnTNhgaUatvZqT2P0vy4cycTmzOWZ2wzONGyHoDF/kGU4eQ0i5lSuM1I5jnnLdi7jUFDI/AvtOKZtyEtvyw0ZDHAaQOTiHba0ALTE5hOQ+PTg/p9XH5cMrqmhR4PTmsoxco9BaHRlQ6lc2wYJ/VvFxq+O7hswc9GKVi/r7DOq9aJkXYeGJjLeRtuQsdgTr+H2N7x3ND8B78PTQOU4oz1t9Albwk50YOY1edf9Hzv38RuWo2haXzZezIf9D8db+CgdOqQDkzonVjtOYN/t4M/32qvV/U1Q/dr1d4jwOer00ND7b5x5ajK51aKznu/ot+6J7D6XPisEewacS/ReRvptPszANxh7dk16p/kJZ+OpmtoaBwoLOfuLzcA8NGfj6/ls6j5Pqj23jR0XzkdVz5Fuy3vAuCJ6krO0L+SuHEGjkDz/eIeU8k64VGMiA5VPuPgc2oH3Vf5vgvKvGw+UMSG9EI27ErDFhlLcbmPgjIvZ3hm8bj1bWyanxVGP/7iuZNCzACjw6pz2bA4bjI+pv3W99BQGBHtKT/tGXx9z8ZnGJz89C98r92JZZmX4rRwIi64kISHHq7jb8FBf1ON7OnTKfzgAyI7l7NnQlfGnDmNsPa9oNfJtX7/Qn55AJa+AuNvM3foAT6/wfasEtakFrA6tYDVaQWk51e/Oh5htzC2ZwLjeyeyck8+P2/O5C3bs5xqWcv93uv5yH9KjZfTNTihXyT++E/ZULCQCFsEfx95H90cE9mWWcyu/dlM2PUCp1eYjd43Gt253XsLeSqae+2fc6n+KzoK7JGkDrmVW3cfz4aMyjKufklRzApcAW0X5eCBqQM4b3inBh3I55S4efj7zfywobL/zVXjutE+ykH5nhVMSHud8ZoZqChXdn4IO5eK425hypgBtI+qkk1SUWwGQZe+CmWB9T+6s3nCOPIqsIWRU+Jm6ssLySlxc+HILjx3cc2yvarS88t4+LvNzKkSyJgxbRRTqgSMftmcyQNfbyK31I1F17hhck9uO6VPrcP/KqX4eEU6j3y/ucbBWFK0gwiHld05Liy6xt+n9OWGSb3qPAj7fv0B1n35LA/qb+PFyrapnzPkuOrfu3r3M2X5ZkZcxnoz4+yC/0DPyfWeXBeWeRj+qNlkdeujZ9Q4kQvy+Ax2ZZeycm9+KBCVXU8p0doHTyM1v4zLZyyj3OvnghGdef6SYfX+bZbtzuOP/1mGoeC5i4dx0agubNhXyLmvLKZzbBiL7z2ZfJeH+duzmbMtu9r3C8x1Qte0UCnJyK6x3HJyb07q177RJ6CXvrmU5Xvyeey8QUwb171B85R5fNz28Vp+3Wp+t+6f2p8/T+xZ62uXVHiZ+vJC0vPLOXdYJ166bDiappFZVMGjMzfz48bKAUbsFp1hyTGM6R7Pbztz2LS/mIQIO7PvOIH4nBXmSVynEdBjEjvy3Hyzdj/frT/AvoLK7UxipJ2Jfdoxe0sWpW4fmmY24v7HlH7ERdhrfT/vbX6P51Y9x/B2w/lg6geN+PRg5u6Z3LfwPrpFd+P7878PfQZ7c13c8L/VbMssQdfg7jP689dJtX9GQRVeP/+dv5Xkhfdwrm5meH6oTqeP2stx+nazSe2Fb8HAc80Z1v4Pvr8DDC8qaQj7PRF0Kag7i9xnCWOeZwCxdoMx/nXmnR2GwnmvQseh1SfO2ABr3mOhbyDXLk/CZ2ih7PJgIHZ9eiEPfbaYPvnzyVZxLDCGYrPoDOwYzbDkWIZ1iSU23Ma/ft3Bpv2VvZJ2ZpdWG7EPwG7VGdo5hg37i0KPOW06FV6DMJuFe87ox1Xjulffprjy8G6bia3vGWYmJWbPtru/WI+h4MzBHXjxsuH1Dmc+b3s2t3+8luJAUOp0fQVv2l9kvdGT8zyPAxBut/DaFSM5sV8jMxN3L4D3zzXLlm5fF7o72FtsXXohPWz5vDkmk775CzD2LiZPRVGWNIpuw04yWzB0HAY2c19hZkfn8NbCPezJdfGHEZ3516XDa7ys128w6J+/4PEbLLz7JJKbkRkatGFfIZe+aW7jwGydEBduJy7cTg9nMWd7ZzGx+AdifOb+S6GhUeV0zuKAPqfB4Aug7xlgb0AA3FthNp3PWG/+dxebwYu+p9cZSNiRVcKPGzM4dUASgzvH4M3KJuXMM1FlZTw38jLmdB1NuygHj5w7iFP7JfDTTz8xeuIpnPqvRbjdHl6e/xK9ig8Qe+kldHzkkToX7eHvNocCg2BeMB6utrJp8yZe292OdNUOi65x2Zhkbj+lD+2jq2ePsmMWfHQxxHZl1+VL+PMHq9mT6yLcbuGFS4ZzxuC6gzNun5/PV+3jtXm7uMT1P+6wfsVsbTxzBj+N1aJh0TQsuo5FNy+EWPXq94XZrXSKcdIpNoyOsU4SIxz4lJfb5t7G4gOLibRF8taUtxiUOIiM0gxum3cb2/K3YdWtPDTuIc7vfX71v9Ga92Hh82YGM5Cpd+A593l87T8BP+bfaXS3OE4f1IHcUje/bM5kb14Z0bi40/o50yyzsWgKjyWS0gn3ED/5JrBUz1Gp8PrJKXGTU+omu9j8mVNcQbnXT8eYMDrHhdE1wk/vhbdjSwk0Uz/5/2DiXczems2f31/F8ORYvrlpPCx8Duaa6zZ9zzS3qY46goe1+HVLFn96fxXDusTw7S3mRQKlFBlFFWzaX8SmA8Vk791KQuZChntWk6AVs1YfRE7SRKJ6T2BEj/YMS44lomrW9d5F5gXU+J5w29r6FyBwDF4+8s8s7v0P1qYXsC69kA3p5iitdUmMdDCpTyKT+rZjYp9Es1/Um5MhYx1f9n6Kv2/qSpe4MGb/bbJ5fJS1Bd46BbxlMOkfeCfe06Bz/6NBQ+MsEpTi2AlKfbwijfsCV45D9DLCu7+BxZGNv6IjZak3gFE9G8AavZawzp8C8I8cF1eV5lGhbDztu4x3/aej0DhLX84jtndJ1IrxK423/Wfygu8iyjlow39MUETjwoGPHx330U4r4jPfZO72/bVBcyeRzyzH3Wj7DPasbI/d48On6VgDdfNpUe15YcSlbI/vVmPeOIqJ0NzsU4lUhnpaVjzFTLe9xemWVQAsN/rzd++N7FNmaclYfQtPWP9LL908MZvtH8WD3mvIpPnDlI7UdvCc7Q166ubO9H++U3jSdwVlOHHg4Q7rl/zZ8gNWzaBYhTPddzmf+E9CNaPSWMPgbuun3Gj9HoCv/RO4x/sXPNS+Lo3StvOMbUbo/c/0H8/D3mu41DKPv/m/YOd3SWBo3HLiHaTEdqn1OWqTXJLFjDnPgqboOKaQ/B2R2CJ87B7amUfDrmUvnWoNSv5Lf4mz9KU86p3G2/6GZxUARDmt+A1FWZW+KU9Y/8sV1jnM9Q/nKd/l7FDVe8/ozv2Edf4Q3V49Q8VbOJIe2cN5xfImvfQMDKUxw382z/suxlsl6XaQtofHbO8wUjebY+80OvNP3zUsNQbRNykSu1UPnTBVW1aHld5JkWiYV0F3ZJVwqGogHYMBWhq3W79kSiBw7lEWPvKfwqu+88ghrsY8SdFmyYvNouNQFUwq+YEphZ8S5zdTpossccyL+QOvZvRnp+oMaJw6oD1hdmuVoK9JCwQqvl9fd6r9ZWOSA9MCaBSVe6oFBgBGdI1laOeY0Am0y+3j89V1DwJx8aguOG0WPlhWvYTgj8d3JT4wulpoOTWN9qXbuXTDtdiUN/Q9CrdbuGFyL3TNfB+G38/2Hdvp368/FoulWiBYQ8PhK+aMdTfRvtgczc5tjeRAwjj2JU5iX+IEPI6Eaq+5cV8hn60y38MfRnQmo6icrGI3GUXlDRrxDqBTjJPjeybw244c8lweopxW/jKxZ2gUMoCXLx9RZSCH6oFg8x7zPbwyb1foQsn/nTUApeCJHw9djnjl2K6c1D2MCncFrywrqFGi86cTenDmkA7owdc76OLAwcHq1+enMHNDBsnxYfznqtG1XpCo+j5yStz86b1VoYPf+87sz9QqmUyaVv01//bpOpbtzsdu0fnx9olEh1mrXdxZuDOHT1ems2pvQbV+LRoGo7UdnG1ZylTLCtppRaHHSohgln8kP/qPY5ExBGVxcvrgDpw/vBMTeidi1TVySz1M/2lraCCH2HAb95zRn0tHJ9cIll4681K25G3hgeMf4LL+l4Xuzygq58eNmfy4MYO0/DJ6JEbQLymKvh2i6Ns+kr5JUTjsPk787ETKfeV8fNbHDE4czKzNmfz9s/WUuH0kRtr59+UjGderAfur0hz45I+wbwV+dB70XstH/lNw4GHD4E9x7PoJ0ODMZ8xGwcteDc1qdJuAkb4Kq1E9gOpzJrCj0/ks1obx373tyHQpQHFPx/X8pWwGFnchSrdSOuZWckbciq+siPjlz5Cw/ZNQUGGH0ZmVyddy8dW3Y7fbcfv8vD9zLo7VM7hIXxDKYF9v9ORfvouYbwyj6vGCw6rXCGTHR9gZ1S2O0d3iGN09jsGdY3BYLcxdtJgDPz/PJGcKSfGx7CiEjHILLpxERMZwXP9uxMbEkbX1K14wcvg5IpzJZeXcMfSvLOBCHplpliVePKoL0y8YUudIvz6/wfOzd/D6/JRq999m+Yo7bV/wuW8Sj1pvwTAUrsD+6rSBSfzz7IEND/KU5sBzvc3P4v79ZiBGKcjZjmfzt+xf+jk9PDvrfQpDt7EvrB9LPb2Z6+rOGqMPOcQRH2Fn9t8m1dmIeOpLC9mSUczV47rx4NkDW2TE43nbs/nH5xvILXUDiuO1bUyzzuJ0fRU2zfyMclQ0n/hP5iPfKYRrFVzqXMl5tmUkedIqn8gWbgaWBl1gBqpsYeaovpmbKgNQGeshZysYNU+yVUwy2pg/mRdswuMBM2D3r1938PXa/aGxQ84c3IELfv4PXVYtYGtcN/4+6Wb+OLY7d5/Rn5gwW+hcZqmvO5+sNPcNwwr38tT8V0DT6P7554QNrj0L1+X2cfqLv6EK0rjAspDLHYvoZFTuRzOtnZlVMZCFxhDWWoZw+cRB/GVSz9BFaX6+D5a9xoFel3J6yoWUVPjoHGtug6v2BwsGaG0WrUZA2+3zs2D2d0xZfg35KpJR7jeadGxqtygiu36M17kBHTunx/+TkQn96KoyKY3uSbnfx8d7n2VzkRkoHxt/ASfHX0av9K8ZtOdtItzmheZ9KpFXfOfzhX8Sfs3Kcd3jmTqkI6cP6lCtpFspxa7sUn7ZnMmsLVkY+9fyuO1thutmi5Jdlp783PEmlvn7k+kyyC6uCAWN69KZHN6yP8cAPZ0KZeP5iDvZkzSFLnFhrEsvDJVU/njbRGLCbSTsmYlj5s1ofjd0GAKXf2qOaFgPr9+gtMLHT5syuf9r89z2xhN7sWl/ESn7s+lXsZ7Juvm/h16z1BOgVDlZYgxioTGU/YkTaN+1H51jwzjeNZfj1tyNp8t4vNO+J9/lobDMS36Zh8IyD/kuDwVlXgpcHi7d8TcGl62o80JuQw3pHMNT2isMyv2J53yX8orvPN6+ZjQn969SibDhc/jKbKvgu/h//LDLkKDU782xEpTyG4qfNmWwbHceq/YWsD27AGeX/2KN2IPhjaFs700oX800xWhcnNj+JeYlFGNRin9k6LxTfDO7VPUT7lhKeND2ARdazA1lqtGeh/kr4f1OJiHSTpjdQkq2i1+3Vm4c7FYdu0WntIVHnxvaJYaxPRNCJwIKBcrMplqXXsjKvQWNer5op5UzeocxuWwWx+V+QztP9eytx/t9SZG1XeC1zOOccq+PFXvy6RQbRs/EiNBj1opyzv3+KdpvNg9+suLa8djoa+nrK+S6FZ8S6SqqljVlWHRO0tdxqWU+J1vWYsEg15LERucoFqnB/FDSj0xvw0omD+VEfS3P2mbQTivCoyy84LuYGf6zMQ7asTrwcKfzO67nW6z4cRHGu2FX8YH3FDJLzb9lr3YRaJqGUso8lFbgMxSZxRU1r8ri5Q7rl/zV8j0WTZFNPNNtN7NMH4FS5t/P/Al91R7u973OIMyD1+VGf+7z/ond6hDNCGvhwMMLttc4y2Kmbb/ou4AXfRdi0fUqy23UOLBw4OE261f81TITq2ZQoCJx4KVsi42cjdFsi+vK3ybf1uDlsOHjEst8rpr1I0ZJ9dfSdEXsABff9p3Iy+oCXFT/W39qf5Tj9W3c7LmNH4yxjf4MDjZN/4WHjA+wOAw0DbYaXfnWP55v/ePIjduFo/1MNN2P4Yml/MDlWCN2YE+ci6Ypkr0+ns3OJcEdwT3ev+BSDibomxmrmyf3K1R/lhkDWGv05hzLUu6xfkKiZp7Ez/SP5XHvFY0MbiraUUQXLYdkLYcuWnbodrKWQyctF3vg4NyvNL70T+Jl/wWhAGtDOfBwkeU3brB8T7Je2YR6n0pkgX8Y841hLDYGU3YUBuEjKOd7+wP01DOZ7R/Fn7130tSAdxRl3Gf9kNMtq0jQKjNWDaWxXvVijn8E84wRbFbdmvwah4sdL320/QzU9zJQS2Wgnko/LZ1cFcMX/kl86Z9EDrGAGaAZqKWaB7yWDYzSdqCh+NUYxdu+M1mu+tOY96djkEARHbQCOmj5JGkFtNcKCMODHS8OvNg1Hw482PHhwItD82LHhx0vFdgpVJEUEkGRiqRIRVBIJIUqgiIiQ4/lqyiKiWjEsilGaLs427KMqZbldNQqA9EFKpLlxgBG6jtprxWG7i9RYcw1RvCj/zgWGMOooGGjBVkCgSndloOz53MopePZ/SAeT+X2zoGHodpuRus7iNFKWW30ZbkxIPCeKjk7fYwtZj2evAm4s8+p8VrtoxzVgvsHByoBeqpUnvE8QUeVQwkRPOS8m68KK3sF9U508veKVznTV3uPwaAcFY0XK50Cn12OiuZGzx2sUjWH9k6kiEdt7zA1sD862G/+IQzXU4jWzMzSTEtHlvv7EuUv4kR9PboWGEDB6ExnLTcUnFpj9OYF38UsMgZT398+0mFlXK8EbBaNnuWbOSfvbfqV158l4AHej4lmRmw05XrlvsuiFBeWlLIh+1qyfMlcOjCMCH8JEf5Cwv1FhPuKqbBGUWDvwk5fIp/sstR6EfMV28ucbVnGE94/8h//2XUux7UTuhNms1QL9mpATqmH1DwXqXll7C8sZ6XjBtppxdzj/TPdtUym6KtCF5jA3FatVP2Y5R/NXGME8RQzxrqL4exglL6ddlrNCyb7aE92uwlk9ryA3Jgh5veoSvb6gh05Nfof9UiM4LIxycRF2GtkdDsqcokr2ozSbRgWB4bFid/iwLCGYVicGFYnhsUJug2Lz0XSnm/otvtj4lyVAb3t9kF8a5/KD94x5JZXBvJMigFaGmdblnK2voxuemX2rtcSTpkziWjX3uqZVQH5KpJNRg82qR5Y8XOxZQFxmjmirEezsz7mNF5xncSCksrjMYuu4TcUA/P28PzCVzHQuGPybVxz3ZmM7hqHrSwDZ9ZabDmbWLs3j/9m9mKL6kYJ4Vw4sgt/WfQexqyf0AcNwfnG22i6Xrn+aqD7ygnb9SOeVR+QlLc89LoeSzhaYl+s2RurDTrgUzprVW8WGUPoMOJMTjn1TBI+OBVL7tbQcdSAjtG8eeUoKnx+VqcWsCbVLGtNqVImqGtm6ZjDpuOw6titOuEWxVclVxBBOWe5n2Cz6lHjMwx9Lvjpp6Vjw8cm1QM/FjTNwNHxU2wx61GGFWf6hVzn2c4fLXOI1VwUqzAWGkOYawxnTlwJ/naLATi+zMu/sjOJUooDKp7XfOfxmf9ElMXOtLHduXJsV3okRjQoc/dAYTm/bj6Ad+W7XFTwX2I08z2XKztrjd6sUP1Zbgxgs96XqMho2kc7aB/loF2UA6fVgiNrDX/a93/EqQJyVAx/8vyd9ar3IV93tGUnM2zPE08xeXoCj0c/xPzijiRFO4mPsFPq9lFSYf4vdXsPunil6KvtCwWhxujbcWiV55WGZsXVfhT+XqdwwB+LZ8dckguWkkBRtWVIMTrymzGUaM3FhZZFfOMfzx3eW+pd7oX220nWc7jU8yBrtUE1Rh/vYivh8Y6LOKH4B1xaBC+UTeUj94TQxdqOMWbjfICbLN9yt+1TvvZP4Je+j/HGtFE1X/DHu2HFmyhHNL/2epAT/3CtBKV+T46VoBRKmU2ai9JR0V34x44P+SVvNXbsdN07BafbzBpQgV2pUhrjLZu43fo1CnggMYHvoyLQ/Ta6pk3F4a7MMgjNg8aJlnXcZv0m9FiJCuPfvvMpIIoUoxOGWbxTY97qz1Pb41Wnq3ws3GFhfK9EJvVpx/CusdgsVdKI3SWwZ6GZWtx1XKAHUuXzbMks4cVfd5KVk0MHLZ8IKigljPj4RC47YSADu3fCnr3BrMlPP0Qz9/AE6HkS+R0m8P6+JL5YnxP62IN65e3nT6tn0q6sEAUkDijBMcjHuf4ncCsbMYaHv26fy4Dt5oGgJTGM5BFphCXU38wy3WjHQmMwC42hrDH64Als7A712QY/CwceHrB9yPmWJQAcUPHc4bmZzap7Lc9T+XyDrPt42v42vQ2zqWxORF+uz5/GdpWMQsNm0ekUG0ZcuI2sYjeZJe5Qw+zgcw7QUnnB9jp9dbPPx1f+E3jSuAYtLJb4cDsG5qgqseE2vH6DgjIvxWUVXK3/zN+tnxOuuXErK6/4zucN/7nVsnK6JYQzuHMMQzvHMKRLDIM6xYSuyM359mOm5L+LfmC12WvhvFdg2GXmH2z/atj8NWz9Dor2QWQSRHeiIqwDi7PtrMhzkqniSNSK+Zv1CyK1CpQB237oDC7Fq2OvYGaHEfX+zcA8KPmDZRG36V8RnVpKxorKdSq2t4vU4vbEZJsHBLZIH2EjfTyfeAlfGycQjpvuWiZv2Z+no5bPRe5/sob+jOoWx8iucYzoGkefQGZRhdegsNxDmduP02YhzK6Tku3i7i83EEUZvbX9/GO4n66bVlOxYAvebDf2KB9xfVzE9Cij3A4PJ8bzS6R58pfEEO4b+yQb0z3EG/kk77mfJ60ZZFqtWJXir+4wrs/Zh81X+ygxbmVlnerNVqMr4/XNob99GU5WJZ5PZrlOcUkJVsONEw9hmgcngf+aBwceoiink5ZHmFb/iGCGZuVAx1OZ0+F65uXFsj69kIKymuuTFR8Geo0A7MHTnKsv4VzLUsbqW3Bqlc/jURZWGP2ZbwxnvjGMXYEsqqB+7SO5bHAYURUZRJQfYPWGjXTWcumi5TI0phylafh0Bz7diU+349UcuAwbm7I9VGA3/ys7ucSQZrQnVSWRTWwoYHpc93hGdI0NBMUrg7hKwbbMYpakVG+OeULvRNanF/C48RLnWZawXyUw1T2dIirT5ttRwCmWtZyir2G4vou9qgOrjX6sMvqy2uhDAbXvD3UMhmkpnGRZyyn6WgbpqbVOB/CW70ze9J1da9baoTjwMFjbwwh9FyP0nfTWDuDCSYGKwueIw2OPpUSPokSLpliPpkSPJtafR2+vmUlVpMXQ2b+PHr7dJPvTsHLoRqklKgw/OrGaq85pduo9eM+YymcVx4UyLiMpY4S+i0HaXjpo+dUCUO0oxKq1zgAXFcpGloojmziylPk/W8WatzFvR1DBVMtyzrYso4tWWb5erMKYZYxhpn8si4zB+NDQ0Rip7WCqZQVnWFaEgi8AZcrBPGMYP/mPZ4PqSY6KOWT2tD1xFo52c/GV9iMs/UJG69sZpe9gjL6dwdqeUJA5yK80NqqeLDEGsdgYxCqjH77IFMKT38PwReHaeR+NHbPnRH0t/7a9QpRWzh4jiT957yJPRdNeKyRJK2Cotpux+hYmWmo2fi9WYSwzBrLcGMAyYyBbVFcUOl20HP5je54BehoeZeGfvmv5xF9babbiedvroYt7QVd67mORMYQoyrjW8jN32r6oMedi/yBe9Z/HEmMQCRTzV+tMrrLMCm2nVhj9+JfvIpYatWeb6BicpS/j3/ZXGvQ5/Rbm5OmEONICx53DKtxcV1TM15ERzI8ws5fCDYNri4q5qqiE8EOcTmSpWFJVEmkqidTANu7v1s/ppmdzteceFhi1jATaSB/anmCCZXO1+9zKymJjML8YY/jVP5I86uoho0jWshml7WSUvoNR+k76aWlYtMr3tcPozGf+E/nGfwK5dT5PTXEUc4ZlJWfryxirb6n2nHXxKw2FFtp2lCkH3/gn8IH/NLaqmpn2db2nIdoezrEs5SzLMjprlfuJTBXHJqM7m1UPNhnd2WT0IIN4qmXd4eFcyxKutsxisL43dP8qoy/v+abws3EcXqzoyuDF+S/Rp2g/a7v3Yd+oJIbrKQzXU6oFtavaaySxWXVjl6sjk2etxeHz8fzIS/m16xhAMVrbzkWW3zjLspworbJkeLF/EF/4J/GzMYZynERRZq6v+kZO0DeGMvFr87LvfLYY3clU8RxQCeQSU+8xQW3+Y3uO0yxreMp7GW/4zw3d344CRuq7GKHvYri+i6Ha7lDguFBFMNcYyuvtdDJj0kHpTMuI428VG0JZb25lrRZoAfg5IpwHE+Op0HV6erz8OyuHCk8Sa40+fGuMZ5kxsEHL3ynGid2qV2sFggaWslyudX/I6ZaV1S40AfiwsMPSh7X6QGa7erHa6MdkfT3P297AoXnZqXXj4ch/sqE4qt4ytqq6aNm8bXuWvvp+ypSD2703M9sYjYZBO4rorOXSWculU+hnHl0Ct4PB+qAcSxKbw4/jV88gvinqTTkO+mvpRGsu1hm9qMBe4+LSwfvhN31nMd13RZ3L68TNFsd16JpiZMUb5Fc5JuqmZfIXyw9cYvsNm6p+zLlPJfKa7zy+8E8KHSPEh1m4eO9XXJk6mxJPGIuOv4biE07F5wyvli1tMXxctuUGOpVsZL+1KzG3LiAyJr5Bn++RSoJSjXDMBKXWf2I27gX+HRvDjLgYrErxamYO4ysOPfS7B/hrh/asCnPSwefjowOZtGvFkeKOZsoPOZujyNsaCUrDFu6j09hCwtvXfkJdst9BxspY/BUW0BQJ/UpJHFLS2P5/xyxDBa6qN+DArbWU7Hewb2ECFrtB7/Mya/yt/Oi4LZHoug7KwOkzr7i6iy1kroqlLLt6RkGXiXlEdnJTku4ka20MvnLzCaO6lJM0ohhbRMuMNOL3aBTuDid/e2ToNaqxGiwaovH5GCs58XBHfiFXFZfUuN5epGs8kpjA7MDJyLjycp7MySOxjbcRXswRO1oqL8elHGSqeEoIZ7iecugZ6uEHdtptbLfbSfb6GOx2U3uXnUaK62EOuOAuhopiVEVRvcPTg3kCssbowwAttc5U9/psMrqTojphVLlAEdRZy+V4veGji2WpWLYbyWSohGpB9GQthxH6rtCB/O+FoTTc2Cr/KxuewG0PNpx4iNZcxOAiUjv0vrxJy9DleIxeJ7PLV8ZzW9exw5FNgdNFb1scx1m70N/XgcgyJzH5GxlVtggLjV/vFXBWl46k22w8lZ3LWa4mDH2Ouc5P7ppMiUVj4oGRnN9lIJ2i7WTmFZJTUExBcRG6340DL048ODQvYbhJ0IrNXlHN9A/vX3Are+i72zkunOT4cHpEw/jND4em8zji2D78/8h3m2uLJ2MLp2a9Xefzpva4lKiiHcTn1529lJMwhkczjseFk5P7t6d/ZBn9dr1NVFlluZa3TGeH+xS8qRXg83Ogc0eOi/yFxKjSWp9zqd8se+oe4Sa8PJMhjlU8nRDHwnAzi62dz8ff8gs521UWWutXOh28EB/LJocjNM3NBUWcX+qiQo/E5eyA4cqjg9awrPWvej9JjpbIT5vMgELws/VayimPTKMsMg2/tRxHWUfCSpNxlHdAQ6+2HQKNG63fcrbFzKZJMTryizGGef7hlFBZAlj1whtVbg/oGEXHGCdKmTlECg2rP5eoiln0LlvPIHcOHX3Brj2VAap5xnD8gcBA1Qu4MbiYYlnFWfqyGoGSMuXAhx7Iiqz/hL5Cc/Bz2DnMDzuVAr+T1PxyyjxGtfcSfP8131fl+9NRDNVTiKaMLaobOSomNG0YHgbrexiq72aUdQ+D2E0MJWQRz05/R1JUJ2I1FxP0TaHsZzD3l9/4T6DbngwSVhei2wx6nZWN1dm47UPetgiy18WgOQzypibSzZ5FF6161vLXxmQ+853APhWHHp6OJWInmsWFv6wnfldflD+cSMoZrO/lHH0p51iW1ghkHMyrLGQRR6aKJ0PFk6niKVbhlOGkDAdlykE5Dlw4KVcOynByiWU+11l/BmCd0QsHHmI1V7VM06BiFYaBTozm4omEOD6NjsKiFM9m53JamRloW27057++M5lrjGCMvp13bM9UuyC22W7jtqR2ZFutxPj9vJCdy3EVlfvIT3wn8qn/JNaqQOlqkyh6aQc4Xt/GcfpWjte31Xg/htJCx+S/+kdwu/eWGpn9DRFFGa/aXmKSZSOG0tinEumg5de4IHGwCmVjqTGQ34yhLDCGUaQiGKHvYqS+kxHaLobqKUQEB+dSFtap3iw1BrLUGMRaozd2fIzXNzNZX88kywY6kM813ntYZAyp9fV0DE7QN/K+/WnyVSQj3TMAGKLt5gbrd5yprwx9HmuM3rzpO5suWi5/tc4MBWIPqHjeKjuT0t1Oztizgo5l1S8ellvtzOsygpk9JrAnpjL7MIl8Zjrup51WzN5e0+g+rWEXEo5Uv7ug1Guvvcazzz5LRkYGgwYN4sUXX2TixIkNmvdYCUqV/PBPola+xNeREfyznVki82hOHn8orfuK78GKdJ0rOyax125joNvNOxnZh7z69XvnLrJyYFksFQXm6WZM9zKSRhVhsdX/ufndGplrYihONQ+W7NFeOh1feMisqYYwgANWCzvtdvZZrXTy+ejr8dLZ52tGdyaTCjx/a8bPCnWdVJuVA1YrsX4/Pb0+2vv9rVoglLYgHleGk/j+pSQNP/TQz8oPedsiyd0chTI0NItBu8EleMstFOyIJLJTBcmTzJ2+36uRuymK/B0RoMxpEweXktC3FK2JH7TXpZO/I5LClHAMn/lXtzj9xPdxEdO9nJIDDlJTonAWVr6A0dlDt14lRHR01zowmwK+iIrgmfg4KnSdeL+fx3PymFh+eE6UD+YHUmw2NjrsbHA62OCwk2KzEe83GOp2M9TtYajbzSC3h4g22G6VaRobHXbWOB2sczhY73TgqlLy4jAMhro9jKpwM6qigqFuj2xfW5DhB2+pFU+pBYvDwBHlw+Ko+/MNtPlDa377l8NCKfBX6GhWVWN/UqJpbHbY2eRwBH7aqdA0unl99PB66e710j1wO9nrq6ODnrlOb7fbmB0ezpyIMFLsdYdNO/p8nOwq5+SyMkZWuEM5q0pR6/biYBscdq7o1IEww2B+2v5mffcfTYjj8+gozi8p5bHcmieDvydKgbvQSsl+J6X7naFjkYM5Yr1Eda4gqks5jlhfjb9ZmabxZmw078dE49M0rEoxraiEvxYW1bo9NYBfIsJ5KS6W/Tbz29Db4+Fv+YVMLK9o0v7ZALbabSwID2dBuJMtjtrLQyMNg7HlFZxQVs6E8go6+FvmIk6FprHOYWdFmJOVTieb7TaiSzT8FiiMMAdT7OL10c3rpavPRzevj65eL928PpL8/mYfXx2N/B6NlJnt8XssJI0oIr5fw885gpQfdv/SDk+xjfi+pSSNrDzGUsBem5UlYU6WhIWx0umoVkoK5uA9g90eTiiv4ITycga5Pa16jFoXwxaB5nXxQlws78ZGoynFkzl5nN3IgHyORef29u3Y6HRgUYpJZeUMdnsY7PEwyO0hxmjaxUHDp+EptWCOTeNHP8R5S32KVDh5KvqgQHHN4K9F14iwQZK37r6Zh1tuVH9Q4NdtWI0KYsrSavQHbIx90cMD71PDYrjpVLqZigIrBTsjKEoNQ/kDQWsbJPQsxRbupyAlHE9x5Z45LMFDXG8XUV3Lq130Lr56HtE9RjZ52Y4Ev6ug1Keffsq0adN47bXXmDBhAm+++SZvvfUWW7ZsoWvXroec/1gJSu1+ZAiZzmxuSmqHX9P4S0ERtxYW1Tl9kALydZ1Mq4VMq5WVTicfxkSFHu/v9hBr+In2G8QYBtFG4GeV36MNgyjDIMJQRBgGNswDJV+Fjq/MgrfMgqfYirvYitdlwRpmYIvwYwvzY3EYWOxG5U+7gWZX+LVAeYoWXE6tylWf6jTAphQWGn6dwAsUWnTyLBYOWM2Ax36rebvAohPjN0gwDOL9fhJ9fuIMg3CvQbgbnG5wuDWs2Vbc6yLBr6HZDRKOKyKmSzlW6i8o8AFlukaZplOy34F3eTRauY7SFOW9PFii/NgdfpwOP+EOP1F2H2FOA91ac3Ut1HV22s0T9VVOJ6udDsr0ul89ym8wpqKC0RVu+ns89PV4a+zQ3Brst1rZZ7WSbjN/Bm/vt1qp0HXshsKpDMKUIsxQOFXwv4HTUIQpRbhSge+JnxjDICbwnQnejjbM+TXMTJw0q400m5U0m5VUm429Niub6zgoDers9dHX46Gfx0tfj4eeXi8WBVYCy2MoHErVeVLWEO4SC7t/MJsRJp6TQ3mMoljXzf8WnRJdo1jXKdF1SnWddgd0Rsy3EVVg/h0Ku/g4MKEcLcogolCj6xfRKE3huqiQsDA/4cog3FBYC3RKVkZTkWO+Z3u0lw6jiohIqr+EraqKAit52yIpTgsLrTz2aC8J/UuJ7mbu7FyaxiOJ8fwUEc6QvYqLV/jpt7ty1EYj2k9F/wpK+3iw24LruCLKMIg0DFJtVv7RPpGdgRPYaUXF3JFfWC0LyIcZ5C6y6BToFgotOgUWnXJNx6IUVirXWatS5v/g7cBjpbrODruNnTYbO+x29tgb9lfUlaKX12sGqSrMYFUPr7faQaoXKNF1sgLrfIbVygGrhQyrlQJdR2ngD2xz/BoYVW4rzMfKdI0sq7XWZQiKMAz6eTzstdnIt1Q/TLYqxcBAkGp0RQXD3W6i6+jurgKfqVfTQkVowe+1hpnp6tJ1XLqGS9Mp0zVcuo5H0wgzDMKVItxQoe9amFL4Ap9BsW5O7whME1Flmtq2JCrw+VXoGm5No0LTcGs6bk2jvMp9PkBpGgbmyaYKfI5G4DmMwO9+MOcJzBv8X6FpeILPr2v40Yj3+UkuMeiSp2ifD9EFGs4iHa3Ygs9lqdxhBGh2A2VR5mtpWuAnGAqcLg1Dh9JYRUWsgTfGj4rxo0f7sUd5ibQoIpX5nXca5mehAxoKXRH6XVfBw1Hz++HHXO6q78Vz0Htya1Cu61QYGoZLRy+2YinVsRfrhBVrRBRpRBVr2Hzm+ykNgwNxkBWrkR0LmXEaWXEaWbFQGGl+zodbeIWiUx50zlN0ylcMzvbTPVdhK9bRrcrcp0f4zJ/h/sDv5n0Wu+LphDg+jIliaqmLp3PyDv2C9VjtcHBNpyQiDYP5afuoJ/ZYLwV4NCgPrDNlmo6Gwq4ULl2nQNcpsFjIDGwbMi3mzwyrBa+mkeTz09Hvo6PPTwefj05ePx3dPjpUGCRUGFh8GsrQsNjMYxzdpmoP+KvAwmgNC/ApA1w5dnL3h1F2wIlWWuXiAopdnTVW9NXxWmD0TsXANIWlymfkjjRwd/UQnuwmKsHNmnAHr8TFkBPYnk0oK+ee/AJ6eA9dluMBPomO4tW4mNCxR2evj9NdLhL8Bgl+f+C/QZzhJ8owqv29yjSNZWFOfgsPY0FYGLm1jN43yO2mnc/PGqeDYkvNxzt5fZxaVsbksnJGVLhD+3tzWw0+TcMb/GmAx2vB79HRLAapTiubw+1s9zsoKbXTIQ+65Co65yq65IEzcJ2wzAEH4uFAvMaBBM28naCREQdem4bDMKplDgePWA9uUKFhbvvb+f108PlJ8vnp4PeZP31+kvw+ooyDT+1bngKKdY18i4V83UK+RTdvB46LyzUtdLwf4zeIDd32E20owpSBTUHBqijKd0Rgi/bS84wc6jn8rPH65ZpGqa5TqmuUZTiw/BqD0hRbL3Qxu7ODxeFN76d6XHkFZ5e6OLGsnLhagjYG4NXAg4ZXC/43HzO364G/mQLNi3keU2bFU2bBV2bBiiLc7ifM4cdp92N1GFic5jlM1aDCa7ExvB5nlno+lJvHRSWND9qBGTB9ODGeHyLrHknRbiiS/D7a+f2Uazo2pUgq95NcoOhYoIgu1HAW6ziLzP2M01X9j+UON6iIVrhjDNzR5j7RG23gj/ajWc2L0XrguM0S/En14xOvpuEL9gQLfIaaAs0PFo+G1ath8YDu0dA9GlargdVh4HAYOO0+wvTKc4owZR6/17YuHHyOGfxp+DVsYX6sYeZ+yBpmYA33HzJRoC4+zO9pua5TrpnHfeWaTrmuUXbQ/Q6fostuC/Fb7FiyKo9XbRE+oruX4+hcQYXS8SsItxmoAiul6U5KDzhDxy4Wu0FMjzLieruwR/nxXfoJ1gGNG+ToSPO7Ckodf/zxjBw5ktdffz1034ABAzj//POZPn36Iec/VoJSL1w/ijMXNy0dXgghhBBCCCGEEG1v1RXHMe3B99p6MZqloXGW+i/xHgU8Hg+rV6/m3nvvrXb/lClTWLJkSa3zuN1u3O7KNL3iYjNN1Ov14vU2v3SqpQWX6VDLJgEpIYQQQgghhBDi6Dbo8xV47z3yYhON0dDYylEflMrNzcXv95OUlFTt/qSkJDIzax+BYfr06TzyyCM17p81axbh4eG1zHFkmD17dr2PW6ZdQq8PPmulpRFCCCGEEEIIIURdKqoUOlXtMhB2iO4cu66/kvQffzw8C9VKysoaljRz1AelgrSDivCVUjXuC7rvvvu48847Q78XFxeTnJzMlClTjtjyvdmzZ3PaaafVP/re1Klw9/+13oIJcYRq8DojhABknRGiMWR9EaJxZJ0RouGC68vZx8D6EqxIO5SjPiiVmJiIxWKpkRWVnZ1dI3sqyOFw4KilebLNZjui//BH+vIJcaSRdUaIxpF1RoiGk/VFiMaRdUaIhjsW1peGLv9RP3qp3W5n1KhRNUrbZs+ezfjx49toqYQQQgghhBBCCCFEfY76TCmAO++8k2nTpjF69GjGjRvHjBkzSEtL44YbbmjrRRNCCCGEEEIIIYQQtTgmglKXXnopeXl5PProo2RkZDB48GB+/PFHunXr1taLJoQQQgghhBBCCCFqcUwEpQBuuukmbrrpprZeDCGEEEIIIYQQQgjRAEd9TykhhBBCCCGEEEIIcfSRoJQQQgghhBBCCCGEaHUSlBJCCCGEEEIIIYQQrU6CUkIIIYQQQgghhBCi1UlQSgghhBBCCCGEEEK0OglKCSGEEEIIIYQQQohWJ0EpIYQQQgghhBBCCNHqJCglhBBCCCGEEEIIIVqdBKWEEEIIIYQQQgghRKuToJQQQgghhBBCCCGEaHUSlBJCCCGEEEIIIYQQrU6CUkIIIYQQQgghhBCi1UlQSgghhBBCCCGEEEK0OglKCSGEEEIIIYQQqDFY/gAADlNJREFUQohWJ0EpIYQQQgghhBBCCNHqrG29AEcCpRQAxcXFbbwktfN6vZSVlVFcXIzNZmvrxRHiiCfrjBCNI+uMEA0n64sQjSPrjBANdyytL8H4SjDeUhcJSgElJSUAJCcnt/GSCCGEEEIIIYQQQhwbSkpKiImJqfNxTR0qbPU7YBgGBw4cICoqCk3T2npxaiguLiY5OZn09HSio6PbenGEOOLJOiNE48g6I0TDyfoiROPIOiNEwx1L64tSipKSEjp16oSu1905SjKlAF3X6dKlS1svxiFFR0cf9V9MIVqTrDNCNI6sM0I0nKwvQjSOrDNCNNyxsr7UlyEVJI3OhRBCCCGEEEIIIUSrk6CUEEIIIYQQQgghhGh1EpQ6CjgcDh566CEcDkdbL4oQRwVZZ4RoHFlnhGg4WV+EaBxZZ4RouN/j+iKNzoUQQgghhBBCCCFEq5NMKSGEEEIIIYQQQgjR6iQoJYQQQgghhBBCCCFanQSlhBBCCCGEEEIIIUSrk6DUUeC1116jR48eOJ1ORo0axcKFC9t6kYRoc9OnT2fMmDFERUXRvn17zj//fLZv315tGqUUDz/8MJ06dSIsLIwTTzyRzZs3t9ESC3HkmD59Opqmcccdd4Tuk/VFiOr279/PlVdeSUJCAuHh4QwfPpzVq1eHHpd1RohKPp+P//u//6NHjx6EhYXRs2dPHn30UQzDCE0j64z4Pfvtt98455xz6NSpE5qm8c0331R7vCHrh9vt5tZbbyUxMZGIiAjOPfdc9u3b14rv4vCQoNQR7tNPP+WOO+7ggQceYO3atUycOJEzzzyTtLS0tl40IdrUggULuPnmm1m2bBmzZ8/G5/MxZcoUXC5XaJpnnnmGF154gVdeeYWVK1fSoUMHTjvtNEpKStpwyYVoWytXrmTGjBkMHTq02v2yvghRqaCggAkTJmCz2fjpp5/YsmULzz//PLGxsaFpZJ0RotLTTz/NG2+8wSuvvMLWrVt55plnePbZZ/n3v/8dmkbWGfF75nK5GDZsGK+88kqtjzdk/bjjjjv4+uuv+eSTT1i0aBGlpaWcffbZ+P3+1nobh4cSR7TjjjtO3XDDDdXu69+/v7r33nvbaImEODJlZ2crQC1YsEAppZRhGKpDhw7qqaeeCk1TUVGhYmJi1BtvvNFWiylEmyopKVF9+vRRs2fPVpMnT1a33367UkrWFyEOds8996gTTjihzsdlnRGiurPOOktdd9111e674IIL1JVXXqmUknVGiKoA9fXXX4d+b8j6UVhYqGw2m/rkk09C0+zfv1/puq5+/vnnVlv2w0EypY5gHo+H1atXM2XKlGr3T5kyhSVLlrTRUglxZCoqKgIgPj4egD179pCZmVlt/XE4HEyePFnWH/G7dfPNN3PWWWdx6qmnVrtf1hchqvvuu+8YPXo0F198Me3bt2fEiBH85z//CT0u64wQ1Z1wwgnMmTOHHTt2ALB+/XoWLVrE1KlTAVlnhKhPQ9aP1atX4/V6q03TqVMnBg8efNSvQ9a2XgBRt9zcXPx+P0lJSdXuT0pKIjMzs42WSogjj1KKO++8kxNOOIHBgwcDhNaR2taf1NTUVl9GIdraJ598wpo1a1i5cmWNx2R9EaK63bt38/rrr3PnnXdy//33s2LFCm677TYcDgdXXXWVrDNCHOSee+6hqKiI/v37Y7FY8Pv9PPHEE1x++eWA7GeEqE9D1o/MzEzsdjtxcXE1pjnaYwMSlDoKaJpW7XelVI37hPg9u+WWW9iwYQOLFi2q8ZisP0JAeno6t99+O7NmzcLpdNY5nawvQpgMw2D06NE8+eSTAIwYMYLNmzfz+uuvc9VVV4Wmk3VGCNOnn37K//73Pz766CMGDRrEunXruOOOO+jUqRNXX311aDpZZ4SoW1PWj2NhHZLyvSNYYmIiFoulRuQzOzu7RhRViN+rW2+9le+++4558+bRpUuX0P0dOnQAkPVHCMyU7+zsbEaNGoXVasVqtbJgwQJefvllrFZraJ2Q9UUIU8eOHRk4cGC1+wYMGBAaaEb2MUJU949//IN7772Xyy67jCFDhjBt2jT+9re/MX36dEDWGSHq05D1o0OHDng8HgoKCuqc5mglQakjmN1uZ9SoUcyePbva/bNnz2b8+PFttFRCHBmUUtxyyy189dVXzJ07lx49elR7vEePHnTo0KHa+uPxeFiwYIGsP+J355RTTmHjxo2sW7cu9H/06NFcccUVrFu3jp49e8r6IkQVEyZMYPv27dXu27FjB926dQNkHyPEwcrKytD16qeWFosFwzAAWWeEqE9D1o9Ro0Zhs9mqTZORkcGmTZuO+nVIyveOcHfeeSfTpk1j9OjRjBs3jhkzZpCWlsYNN9zQ1osmRJu6+eab+eijj/j222+JiooKXVmIiYkhLCwMTdO44447ePLJJ+nTpw99+vThySefJDw8nD/+8Y9tvPRCtK6oqKhQv7WgiIgIEhISQvfL+iJEpb/97W+MHz+eJ598kksuuYQVK1YwY8YMZsyYASD7GCEOcs455/DEE0/QtWtXBg0axNq1a3nhhRe47rrrAFlnhCgtLWXXrl2h3/fs2cO6deuIj4+na9euh1w/YmJiuP766/n73/9OQkIC8fHx3HXXXQwZMqTGADZHnTYb90802Kuvvqq6deum7Ha7GjlyZGjIeyF+z4Ba/7/zzjuhaQzDUA899JDq0KGDcjgcatKkSWrjxo1tt9BCHEEmT56sbr/99tDvsr4IUd3333+vBg8erBwOh+rfv7+aMWNGtcdlnRGiUnFxsbr99ttV165dldPpVD179lQPPPCAcrvdoWlknRG/Z/Pmzav13OXqq69WSjVs/SgvL1e33HKLio+PV2FhYerss89WaWlpbfBuWpamlFJtFA8TQgghhBBCCCGEEL9T0lNKCCGEEEIIIYQQQrQ6CUoJIYQQQgghhBBCiFYnQSkhhBBCCCGEEEII0eokKCWEEEIIIYQQQgghWp0EpYQQQgghhBBCCCFEq5OglBBCCCGEEEIIIYRodRKUEkIIIYQQQgghhBCtToJSQgghhBBCCCGEEKLVSVBKCCGEEOIY0717d1588cW2XgwhhBBCiHpJUEoIIYQQohmuueYazj//fABOPPFE7rjjjlZ77XfffZfY2Nga969cuZK//OUvrbYcQgghhBBNYW3rBRBCCCGEENV5PB7sdnuT52/Xrl0LLo0QQgghxOEhmVJCCCGEEC3gmmuuYcGCBbz00ktomoamaezduxeALVu2MHXqVCIjI0lKSmLatGnk5uaG5j3xxBO55ZZbuPPOO0lMTOS0004D4IUXXmDIkCFERESQnJzMTTfdRGlpKQDz58/n2muvpaioKPR6Dz/8MFCzfC8tLY3zzjuPyMhIoqOjueSSS8jKygo9/vDDDzN8+HA++OADunfvTkxMDJdddhklJSWH90MTQgghxO+aBKWEEEIIIVrASy+9xLhx4/jzn/9MRkYGGRkZJCcnk5GRweTJkxk+fDirVq3i559/Jisri0suuaTa/O+99x5Wq5XFixfz5ptvAqDrOi+//DKbNm3ivffeY+7cudx9990AjB8/nhdffJHo6OjQ69111101lkspxfnnn09+fj4LFixg9uzZpKSkcOmll1abLiUlhW+++YaZM2cyc+ZMFixYwFNPPXWYPi0hhBBCCCnfE0IIIYRoETExMdjtdsLDw+nQoUPo/tdff52RI0fy5JNPhu57++23SU5OZseOHfTt2xeA3r1788wzz1R7zqr9qXr06MFjjz3GjTfeyGuvvYbdbicmJgZN06q93sF+/fVXNmzYwJ49e0hOTgbggw8+YNCgQaxcuZIxY8YAYBgG7777LlFRUQBMmzaNOXPm8MQTTzTvgxFCCCGEqINkSgkhhBBCHEarV69m3rx5REZGhv73798fMLOTgkaPHl1j3nnz5nHaaafRuXNnoqKiuOqqq8jLy8PlcjX49bdu3UpycnIoIAUwcOBAYmNj2bp1a+i+7t27hwJSAB07diQ7O7tR71UIIYQQojEkU0oIIYQQ4jAyDINzzjmHp59+usZjHTt2DN2OiIio9lhqaipTp07lhhtu4LHHHiM+Pp5FixZx/fXX4/V6G/z6Sik0TTvk/TabrdrjmqZhGEaDX0cIIYQQorEkKCWEEEII0ULsdjt+v7/afSNHjuTLL7+ke/fuWK0NP/RatWoVPp+P559/Hl03k9s/++yzQ77ewQYOHEhaWhrp6emhbKktW7ZQVFTEgAEDGrw8QgghhBAtTcr3hBBCCCFaSPfu3Vm+fDl79+4lNzcXwzC4+eabyc/P5/LLL2fFihXs3r2bWbNmcd1119UbUOrVqxc+n49///vf7N69mw8++IA33nijxuuVlpYyZ84ccnNzKSsrq/E8p556KkOHDuWKK65gzZo1rFixgquuuorJkyfXWjIohBBCCNFaJCglhBBCCNFC7rrrLiwWCwMHDqRdu3akpaXRqVMnFi9ejN/v5/TTT2fw4MHcfvvtxMTEhDKgajN8+HBeeOEFnn76aQYPHsyHH37I9OnTq00zfvx4brjhBi699FLatWtXo1E6mGV433zzDXFxcUyaNIlTTz2Vnj178umnn7b4+xdCCCGEaAxNKaXaeiGEEEIIIYQQQgghxO+LZEoJIYQQQgghhBBCiFYnQSkhhBBCCCGEEEII0eokKCWEEEIIIYQQQgghWp0EpYQQQgghhBBCCCFEq5OglBBCCCGEEEIIIYRodRKUEkIIIYQQQgghhBCtToJSQgghhBBCCCGEEKLVSVBKCCGEEEIIIYQQQrQ6CUoJIYQQQgghhBBCiFYnQSkhhBBCCCGEEEII0eokKCWEEEIIIYQQQgghWp0EpYQQQgghhBBCCCFEq/t/OdRgrlXrHjQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/n51_7s_n09dfndljqk4rv2zr0000gn/T/ipykernel_32335/3401261458.py:28: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar='sd'` for the same effect.\n",
      "\n",
      "  sns.barplot(data=results_df, x='Sample_Size', y='MAPE', estimator=np.mean, ci='sd')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. MAPE across Different Data Types and Iterations\n",
    "plt.figure(figsize=(12, 6))\n",
    "for dtype in results_df['Data_Type'].unique():\n",
    "    subset = results_df[results_df['Data_Type'] == dtype]\n",
    "    plt.plot(subset['Iteration'], subset['MAPE'], label=dtype)\n",
    "\n",
    "plt.title('MAPE across Different Data Types and Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MAPE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Distribution of Causal Effects\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=results_df, x='Data_Type', y='Causal_Effect')\n",
    "plt.title('Distribution of Causal Effects across Different Data Types')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Average MAPE for Each Sample Size\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=results_df, x='Sample_Size', y='MAPE', estimator=np.mean, ci='sd')\n",
    "plt.title('Average MAPE for Each Sample Size')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
