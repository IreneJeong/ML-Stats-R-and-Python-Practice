{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-10 01:51:49.919958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from tensorflow.keras.initializers import RandomNormal, Constant\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import cifar10, cifar100\n",
    "\n",
    "# importing of service libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/0x/n51_7s_n09dfndljqk4rv2zr0000gn/T/ipykernel_73180/3435464487.py:17: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    '''\n",
    "    Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1)\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_X_train shape:  (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(input_X_train, output_y_train),(input_X_test, output_y_test)=cifar10.load_data()\n",
    "\n",
    "print('input_X_train shape: ', input_X_train.shape)\n",
    "print(input_X_train.shape[0], 'train samples')\n",
    "print(input_X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMAGE_SIZE = input_X_train.shape[1]\n",
    "N_CLASSES =len(np.unique(output_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data one-hot encoding \n",
    "output_y_train=utils.to_categorical(output_y_train, N_CLASSES)\n",
    "output_y_test=utils.to_categorical(output_y_test, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize the value in between 0 and 1 (there are 255 kinds)\n",
    "input_X_train=input_X_train.astype('float32')\n",
    "input_X_test=input_X_test.astype('float32')\n",
    "\n",
    "input_X_train /=255\n",
    "input_X_test /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function for plotting the history of the training of the model\n",
    "def plot_history(history):\n",
    "    val_loss = history.history['val_loss' ]\n",
    "    loss =     history.history['loss' ]\n",
    "    acc =      history.history['accuracy' ]\n",
    "    val_acc =  history.history['val_accuracy' ]\n",
    "\n",
    "    epochs    = range(1,len(acc)+1,1)\n",
    "\n",
    "    plt.plot  ( epochs,     acc, 'r--', label='Training acc'  )\n",
    "    plt.plot  ( epochs, val_acc,  'b', label='Validation acc')\n",
    "    plt.title ('Training and validation accuracy')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot  ( epochs,     loss, 'r--', label='Training loss' )\n",
    "    plt.plot  ( epochs, val_loss ,  'b', label='Validation loss' )\n",
    "    plt.title ('Training and validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'epochs': [20, 30, 40, 50],\n",
    "    'learning_rate': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'batch_size': [128, 256, 512],\n",
    "    'optimizer': [RMSprop(), Adam(), SGD()],\n",
    "    'validation_split': [0.2, 0.3, 0.4, 0.5],\n",
    "    'model': ['Simple CNN', 'Complex CNN', 'CNN with BN'],\n",
    "    'kernel_size': [(3,3), (5,5)],\n",
    "    'data_augmentation': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the Keras model\n",
    "def create_model(optimizer, kernel_size='kernel_size', model='model', batch_size='batch_size', learning_rate=\"learning_rate\", epochs='epochs', validation_split='validation_split'):\n",
    "    if model == 'Simple CNN':\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, IMG_CHANNELS)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(N_CLASSES))\n",
    "        model.add(Activation('softmax'))\n",
    "    elif model == 'Complex CNN':\n",
    "        # Define the architecture of the Complex CNN model\n",
    "        # Complex DNN model definition\n",
    "        model = Sequential()\n",
    "\n",
    "        # hidden 1 : conv + conv + pool + dropout \n",
    "        model.add(Conv2D(32, kernel_size, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, IMG_CHANNELS)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(32, kernel_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        # hidden 2 : conv + conv + pool + dropout \n",
    "        model.add(Conv2D(64, kernel_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, 3, 3))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        # hidden 3 : flatten + droupout \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # output \n",
    "        model.add(Dense(N_CLASSES))\n",
    "        model.add(Activation('softmax'))\n",
    "        pass\n",
    "    elif model == 'CNN with BN':\n",
    "        # Define the architecture of the CNN with BN model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(256,kernel_size,padding='same',input_shape=(IMAGE_SIZE, IMAGE_SIZE, IMG_CHANNELS)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(256,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(512,kernel_size,padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(BatchNormalization(momentum=0.95, \n",
    "                epsilon=0.005,\n",
    "                beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n",
    "                gamma_initializer=Constant(value=0.9)))\n",
    "        model.add(Dense(100,activation='softmax'))\n",
    "        pass\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer(learning_rate='learning_rate'), metrics=['accuracy'])\n",
    "    history=model.fit(input_X_train, output_y_train, batch_size='batch_size', \n",
    "                  epochs='epochs', validation_split='validation_split', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(input_X_train, output_y_train, test_size=0.2)\n",
    "\n",
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size='batch_size',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow(\n",
    "    x=X_val,\n",
    "    y=y_val,\n",
    "    batch_size='batch_size',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    x=input_X_train,\n",
    "    y=output_y_train,\n",
    "    batch_size='batch_size',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/n51_7s_n09dfndljqk4rv2zr0000gn/T/ipykernel_73180/2803159475.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_clf = KerasClassifier(build_fn=create_model)\n"
     ]
    }
   ],
   "source": [
    "# Wrap the Keras model with KerasClassifier from sklearn\n",
    "keras_clf = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Create a GridSearchCV object to tune the hyperparameters\n",
    "grid_search = GridSearchCV(estimator=keras_clf, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Train the model with GridSearchCV\n",
    "# grid_search.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "grid_search.fit(X=input_X_train, y=output_y_train, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
