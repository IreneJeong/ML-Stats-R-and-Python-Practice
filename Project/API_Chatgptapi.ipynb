{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple ChatGPT API usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai # pip install openai\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip() # ChatGPT API sotred in key.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"\\n\\nThe circumference of the moon is approximately 10,917 kilometers.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1678825166,\n",
      "  \"id\": \"chatcmpl-6u5PC6RhL9kV8sxNmJkyEMfgnxeGN\",\n",
      "  \"model\": \"gpt-3.5-turbo-0301\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 15,\n",
      "    \"prompt_tokens\": 17,\n",
      "    \"total_tokens\": 32\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\":\"assistant\", \"content\": \"what is the circumference of the moon in km?\"}] # role of chatGPT\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The circumference of the moon is approximately 10,917 kilometers.\n"
     ]
    }
   ],
   "source": [
    "reply_content = completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was hi\n"
     ]
    }
   ],
   "source": [
    "message_history=[]\n",
    "user_input = input(\">: \")\n",
    "print(\"User's input was\", user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Hello! How may I assist you?\n"
     ]
    }
   ],
   "source": [
    "completion=openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    messages=message_history,\n",
    ")\n",
    "\n",
    "reply_content=completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history.append({\"role\":\"assistant\", \"content\": reply_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was How far is the moon?\n",
      "\n",
      "The moon is approximately 238,855 miles or 384,400 kilometers away from Earth.\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\">: \")\n",
    "print(\"User's input was\", user_input)\n",
    "print()\n",
    "message_history.append({\"role\":\"user\", \"content\": user_input})\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message_history\n",
    ")\n",
    "\n",
    "reply_content=completion.choices[0].message.content\n",
    "print(reply_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'hi'}, {'role': 'assistant', 'content': '\\n\\nHello! How may I assist you?'}, {'role': 'user', 'content': 'How far is the moon?'}]\n"
     ]
    }
   ],
   "source": [
    "print(message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was Where is the warmest contury in the world?\n",
      "\n",
      "\n",
      "\n",
      "As an AI language model, I do not have knowledge of the current temperature and weather conditions. However, the warmest country in the world by average temperature is Libya.\n",
      "\n",
      "User's input was Do I need a visa for visiting?\n",
      "\n",
      "It depends on your nationality and the purpose and length of your visit. Each country has its own visa requirements and regulations, so it's important to check with the embassy or consulate of the country you plan to visit or consult with a travel agent for the latest requirements.\n",
      "\n",
      "You may also check online visa applications and requirements on official government websites. It is important to check the visa requirements well in advance of your trip to avoid any delays or complications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_history=[]\n",
    "\n",
    "def chat(inp, role='user'):\n",
    "    message_history.append({\"role\": role, \"content\": inp})\n",
    "    \n",
    "    completion=openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=message_history,\n",
    "    )\n",
    "    \n",
    "    reply_content=completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": reply_content})\n",
    "    return reply_content\n",
    "\n",
    "for i in range(2): # to test if the response returned the same context 2 questions. \n",
    "    user_input=input(\">: \")\n",
    "    print(\"User's input was\", user_input)\n",
    "    print()\n",
    "    chat(user_input)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # pip install gradio\n",
    "\n",
    "import openai # pip install openai\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip() # ChatGPT API sotred in key.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongdahye/opt/anaconda3/lib/python3.8/site-packages/gradio/components.py:153: UserWarning: Unknown style parameter: contrainer\n",
      "  warnings.warn(f\"Unknown style parameter: {key}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI language model, I cannot determine your schedule for today, but here’s a joke to make your day better: Why don't scientists trust atoms? Because they make up everything.\n",
      "There are several steps you can take to become a data scientist working with AI and Neural networks:\n",
      "\n",
      "1. Learn programming languages like Python and R that are widely used in data science.\n",
      "\n",
      "2. Gain knowledge of machine learning algorithms and how they work.\n",
      "\n",
      "3. Familiarize yourself with popular AI tools like TensorFlow and Keras.\n",
      "\n",
      "4. Experiment with different types of neural networks, like Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN).\n",
      "\n",
      "5. Work on projects that involve data analysis and modeling to build a portfolio.\n",
      "\n",
      "Remember, patience is key when learning new skills — nobody becomes an expert overnight. Good luck!\n"
     ]
    }
   ],
   "source": [
    "#message_history=[{\"role\": \"user\", \"content\": f\"you're a joke bot I will specify the subject matter in my messages and you will reply with a joke that includes the subjects I message mentioned in my messages reply only with jokes to further input if you understand say okay\"},\n",
    "#                 {\"role\":\"assistant\", \"content\":f\"OK\"}]\n",
    "\n",
    "\n",
    "def predict(input):\n",
    "    global message_history\n",
    "    message_history.append({\"role\": \"user\", \"content\": input})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages=message_history\n",
    "    )\n",
    "    \n",
    "    reply_content=completion.choices[0].message.content\n",
    "    print(reply_content)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": reply_content})\n",
    "    #response = [(message_history[i]['content'], message_history[i+1]['content']) for i in range(2, len(message_history)-1, 2)] # satisfy gradio chat, make it tuple\n",
    "    response = [(message_history[i]['content'], message_history[i+1]['content']) for i in range(0, len(message_history)-1, 2)] \n",
    "    return response\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot=gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label=False, placeholder=\"Type your message here\").style(contrainer=False)\n",
    "        txt.submit(predict, txt, chatbot) # run predict class, passing txt to chatbot instance\n",
    "        # txt.submit(lambda: \"\", None, txt) # Empty the text box in python way\n",
    "        txt.submit(None, None, txt, _js=\"()=>{''}\") # in Java script way, but this is a bit faster\n",
    "        \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
