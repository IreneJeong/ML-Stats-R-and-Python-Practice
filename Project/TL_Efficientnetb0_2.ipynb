{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport keras\nimport keras.backend as K\nfrom keras.datasets import cifar100\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\nimport albumentations as albu\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"ff877682-03f1-4688-9e6a-083492fa5ebe","_cell_guid":"776d9b50-a71b-472a-a17b-9d6bfa8a3176","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parameters for data\nheight = 224\nwidth = 224\nchannels = 3\ninput_shape = (height, width, channels)\nn_classes = 100\n\n# parameters for optimizers\nlr = 1e-3\n\n# Parameters for training\nepochs = 25\nbatch_size = 8\n\n# parameters for callback functions\nes_patience = 10\nrlrop_patience = 5\ndecay_rate = 0.5","metadata":{"_uuid":"945d4297-0aec-4f22-969f-bef0e90d0d19","_cell_guid":"4a2dd57b-67f7-4803-a356-2a32bc976562","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CIFAR-100 dataset\n- In order to download `cifar-100` datasets from `keras.datasets`, one should make `Internet` setting  be **on**.\n- `cifar-100` contains 50,000 training data and 10,000 testing data each of which is 32 x 32 x 3 images with 1 class out of 100 classes.<br/>\n- I could find the label names from [this sites](https://github.com/keras-team/keras/issues/2653)","metadata":{"_uuid":"3d36e591-fc02-419f-86dd-56886af99a43","_cell_guid":"74409b01-c66b-4644-8713-04ea2a4f5ea2","trusted":true}},{"cell_type":"code","source":"(X, y), (X_test, y_test) = cifar100.load_data()\n\nprint(\"The shape of X_train : \", X.shape)\nprint(\"The shape of X_test : \", X_test.shape)\n\nfine_label_list =  ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', \n                    'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', \n                    'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', \n                    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', \n                    'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', \n                    'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', \n                    'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', \n                    'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', \n                    'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']","metadata":{"_uuid":"83228042-d304-4f0e-8cd0-8316cd05fdd5","_cell_guid":"51b6a055-d05f-47ef-ad3d-46cf55644404","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Plotting some sampled images from randomly chosen 5 classes","metadata":{"_uuid":"14fdac58-9d52-4710-9383-6d24fee97695","_cell_guid":"11924bbc-1283-4764-95a6-9f71ada3a015","trusted":true}},{"cell_type":"code","source":"class_plotted = np.random.choice(range(n_classes), 5, replace = False)\nfor i in range(len(class_plotted)):\n    image_samples = X[y.reshape(-1) == class_plotted[i]][:5]\n    fig, ax = plt.subplots(nrows = 1, ncols = 5,figsize = (8,8))\n    fig.suptitle(\"label : %d, class : %s\" % (class_plotted[i], fine_label_list[class_plotted[i]]), y = .6)\n    for j in range(5):\n        ax[j].imshow(image_samples[j])\n        ax[j].axis('off')  \n    fig.tight_layout()\nplt.show()","metadata":{"_uuid":"4ffea7cf-0140-4262-87f3-db9d7afa17dc","_cell_guid":"5e531f44-ac12-4834-b379-d3b138b9d7da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation\n- I decided to make the testing data be unknown so I splited the training data into a training data and a validation data.\n- Because the number of images for each class in the training data is quite small (500), I used `StratifiedShuffleSplit` method to keep the number of images for each class.","metadata":{"_uuid":"d722a9eb-3a8c-4b65-9e12-eace0873da0c","_cell_guid":"342df8a2-12a0-4231-a032-9ca60ac03fb0","trusted":true}},{"cell_type":"code","source":"# Spliting the training data into a training data and a validation data.\nst = StratifiedShuffleSplit(n_splits = 2, test_size = 0.2, random_state = 1)\nfor train_index, val_index in st.split(X, y):\n    X_train, X_val, y_train, y_val = X[train_index], X[val_index], y[train_index], y[val_index]\n    \nprint(\"The number of training data : \", X_train.shape[0])\nprint(\"The number of validation data : \", X_val.shape[0])\n\ndel X, y","metadata":{"_uuid":"7f24a8ed-de7e-46fd-a16a-5be7c6f3a675","_cell_guid":"8c30b6f1-5141-4706-878a-dfca825c4314","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The paper `EfficientNet` says balancing model's depth, model's width and resolution of input images is important for model scaling.\n- So original images should be resized to the specified size, which is (224, 224) in the case of `EfficientNetB0`. \n    - When I used the original size (32,32,3), the model's performance was less than 40% (accuracy).\n- The bicubic method is a good choice interpolation when upscaling images and it can be implemented by `cv2.INTER_CUBIC`.\n- To do this, I used a custom `DataGenerator` that contains the part of resizing a image.","metadata":{}},{"cell_type":"code","source":"def np_resize(img, shape):\n    return cv2.resize(img, (shape[1], shape[0]), interpolation = cv2.INTER_CUBIC)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for keras'\n    def __init__(self, images , labels = None, mode = 'fit', batch_size = batch_size,\n                 dim = (height, width), channels = channels, n_classes = n_classes,\n                 shuffle = True, augment = False):\n        self.images = images\n        self.labels = labels\n        self.mode = mode\n        self.batch_size = batch_size\n        self.dim = dim\n        self.channels = channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.augment = augment\n        \n        self.on_epoch_end()\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(self.images.shape[0])\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.images) / self.batch_size))\n        \n    def __getitem__(self, index):\n        'Generate one batch of data'\n        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # =========================================================== #\n        # Generate mini-batch of X\n        # =========================================================== #\n        X = np.empty((self.batch_size, *self.dim, self.channels))\n        for i, ID in enumerate(batch_indexes):\n            # Generate a preprocessed image\n            img = self.images[ID]\n            img = img.astype(np.float32) / 255.\n            img = np_resize(img, self.dim)\n            X[i] = img\n            \n        \n        # =========================================================== #\n        # Generate mini-batch of y\n        # =========================================================== #\n        if self.mode == 'fit':\n            y = self.labels[batch_indexes]\n            y = to_categorical(y, n_classes)\n            '''\n            y = np.zeros((self.batch_size, self.n_classes), dtype = np.uint8)\n            for i, ID in enumerate(batch_indexes):\n                # one hot encoded label\n                y[i, self.labels[ID]] = 1\n            '''\n            # Augmentation should only be implemented in the training part.\n            if self.augment == True:\n                X = self.__augment_batch(X)                \n            \n            return X,y\n        \n        elif self.mode == 'predict':\n            return X       \n        \n        else:\n            raise AttributeError('The mode parameters should be set to \"fit\" or \"predict\"')\n            \n    def __random_transform(self, img):\n        composition = albu.Compose([albu.HorizontalFlip(p = 0.5),\n                                    albu.VerticalFlip(p = 0.5),\n                                    albu.GridDistortion(p = 0.2),\n                                    albu.ElasticTransform(p = 0.2)])\n        \n        return composition(image = img)['image']\n        \n    \n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            img_batch[i] = self.__random_transform(img_batch[i])\n            \n        return img_batch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = DataGenerator(X_train, y_train, augment = True)\nvalid_generator = DataGenerator(X_val, y_val, augment = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using a pretrained EfficientNetB0","metadata":{"_uuid":"283cd97c-2923-4a61-a567-6f299ab14478","_cell_guid":"8fdbf00a-2dfc-4125-9394-ed4ac39620c7","trusted":true}},{"cell_type":"markdown","source":"One can easily use EfficientNet models pretrained on `ImageNet` for transfer learnings (or fine tunings) just like other pretrained models.<br/>\nThe manual to use EfficientNet is well documented at [this site](https://github.com/qubvel/efficientnet).<br/>\nTo do this I refered to [this site](https://www.dlology.com/blog/transfer-learning-with-efficientnet/).","metadata":{"_uuid":"ee431cd8-511f-4298-b957-4ac5ddf3d653","_cell_guid":"e706e76f-79da-4bfb-983d-b30d000173e9","trusted":true}},{"cell_type":"code","source":"!pip install -U efficientnet","metadata":{"_uuid":"4ea63862-263f-4a5e-b2d6-1e46502dd10a","_cell_guid":"3f38f26c-bead-41eb-be78-496245ec2ca8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.keras as efn \n\nefnb0 = efn.EfficientNetB0(weights = 'imagenet', include_top = False, classes = n_classes, input_shape = input_shape)\n\nmodel = Sequential()\nmodel.add(efnb0)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(n_classes, activation = 'softmax'))\n\nmodel.summary()","metadata":{"_uuid":"1bde2e68-b561-46b0-a6c9-8998edfb3aa8","_cell_guid":"88aef3bd-9223-4bdf-ad97-b60e81472bb2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One can train only fully connected layers by adding the following code\n~~~python\nefnb0.trainable = False\n~~~","metadata":{"_uuid":"1c48f0fa-853a-4dfc-badc-b7821a4dc2fa","_cell_guid":"81f28bc5-0458-456b-b0db-ef2a7f76d410","trusted":true}},{"cell_type":"code","source":"sgd = SGD(lr = lr, momentum = 0.9, nesterov = True)\nes = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = es_patience, restore_best_weights = True, verbose = 1)\nrlrop = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = rlrop_patience, \n                        factor = decay_rate, min_lr = 1e-6, verbose = 1)","metadata":{"_uuid":"499a653c-2118-4251-9ee2-cf479299680f","_cell_guid":"64405bde-3cde-40fb-b6f6-afa4923b168c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['acc'])","metadata":{"_uuid":"6cff985f-c88f-4156-953a-49a6fe5072eb","_cell_guid":"ca2937fc-14ac-455b-aca9-a87f65784038","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit_generator(train_generator,validation_data = valid_generator, \n                           epochs = epochs, verbose = 1, callbacks = [es, rlrop])\n\nmodel.save_weights(\"best_weight.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, loss_ax = plt.subplots()\n\nacc_ax = loss_ax.twinx()\n\nloss_ax.plot(hist.history['loss'], 'y', label='train loss')\nloss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n\nacc_ax.plot(hist.history['acc'], 'b', label='train acc')\nacc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n\nloss_ax.set_xlabel('epoch')\nloss_ax.set_ylabel('loss')\nacc_ax.set_ylabel('accuray')\n\nloss_ax.legend(loc='upper left')\nacc_ax.legend(loc='lower left')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n- For your quick experiment, I have uploaded the best weight for the model.\n- To load the fine-tuned weight, follow a few steps\n    - click `Add Data`\n    - click `Kernel output files`\n    - find this kernel\n    - click `Add`","metadata":{}},{"cell_type":"code","source":"# model.load_weights(\"../input/%s/best_weight.h5\" % (os.listdir('../input')[0]))\nprint(\"The Accuracy on the validation data : {:.2f}%\".format(100 * model.evaluate_generator(valid_generator, verbose = 1)[-1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Before inference, make sure to set `shuffle=False` in test generator. \n    - If not, predictions cannot be compared  with true labels because test generator predicts output in the shuffled order.","metadata":{}},{"cell_type":"code","source":"# Make sure to set shuffle be False.\ntest_generator = DataGenerator(X_test, mode = 'predict', augment = False, shuffle = False)\ny_pred = model.predict_generator(test_generator,verbose = 1)\ny_pred = np.argmax(y_pred, axis = 1)\n\nprint(\"The accuracy on the testing data : {:.2f}%\".format(100 * accuracy_score(y_test, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}